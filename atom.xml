<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Qinng</title>
  <icon>https://www.gravatar.com/avatar/b0015a53e4c7f5def73fd76d56ecadf9</icon>
  <subtitle>Qinng</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://qingwave.github.io/"/>
  <updated>2021-03-27T12:04:30.976Z</updated>
  <id>https://qingwave.github.io/</id>
  
  <author>
    <name>Qinng</name>
    <email>isguory@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>也谈苏东坡</title>
    <link href="https://qingwave.github.io/sudongpo/"/>
    <id>https://qingwave.github.io/sudongpo/</id>
    <published>2021-03-25T13:30:25.000Z</published>
    <updated>2021-03-27T12:04:30.976Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>何夜无月，何夜无竹柏，但少闲人如吾两人尔</p></blockquote><p>李一冰的《苏东坡新传》在微信读书里躺了一年有余，偶尔想起翻开几页，不过大多时候是想不起的。年纪越大越发的浮躁，少了上学时的心平气和，工作之后阅读的功利心重了许多，总想通过几段文字掌握多少知识，开阔些许眼界，对于这些“不务正业”的书难有闲心了。<br>&nbsp;</p><blockquote><p>春江水暖鸭先知</p></blockquote><p>对于苏东坡，上学前就会背他的《赤壁怀古》，记得小学时老师问谁会背词，便大东江东去了一番，引得不少目光。但对东坡其人知之甚少，后来开始慢慢接触他的诗与杂文，读了林语堂的《苏东坡传》，被他的乐观旷达所吸引。遇到不如意的，“一蓑烟雨任平生”；</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;何夜无月，何夜无竹柏，但少闲人如吾两人尔&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="杂记" scheme="https://qingwave.github.io/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
      <category term="杂记" scheme="https://qingwave.github.io/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>golang zk大量disconnected event</title>
    <link href="https://qingwave.github.io/golang-zk-statedisconnected/"/>
    <id>https://qingwave.github.io/golang-zk-statedisconnected/</id>
    <published>2021-03-02T09:16:23.000Z</published>
    <updated>2021-03-22T12:57:19.216Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在容器平台上我们提供了<code>zk</code>做白名单功能，<code>Pod</code>启动时 sidecar会自动注册<code>zk</code>。昨天遇到<code>zk server</code>抖动，<code>sidecar</code>容器输出大量<code>StateDisconnected</code>事件，zk正常后仍无法恢复，由于大量日志造成<code>sidecar</code>容器 cpu占用过高，进而引发<code>dockerd</code>cpu占用过高，严重时影响dockerd正常调用。</p><h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><h3 id="问题复现"><a href="#问题复现" class="headerlink" title="问题复现"></a>问题复现</h3><p>正常情况下，<code>sidecar</code>启动后会去注册<code>zk</code>：<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker logs -f 01a1a4a74785</span></span><br><span class="line">I0302 15:04:05.476463       1 manager.go:116] start run plugin zk</span><br><span class="line">2021/03/02 15:04:05 Connected to 10.38.161.60:11000</span><br><span class="line">I0302 15:04:05.488006       1 zk.go:152] zookeeper connect succeed: zk.srv:11000</span><br><span class="line">2021/03/02 15:04:05 authenticated: id=33746806328105493, timeout=30000</span><br><span class="line">2021/03/02 15:04:05 re-submitting `0` credentials after reconnect</span><br><span class="line">I0302 15:04:05.516446       1 zk.go:220] watching zk node:[/tasks/cluster.xxx_default_deployment.htool/10.46.12.72] <span class="keyword">in</span> cluster[xxx] <span class="comment">#注册成功，开始watch</span></span><br></pre></td></tr></tbody></table></figure><p></p><p>通过<code>iptable</code>s来模拟异常，首先进入到容器<code>network namesapce</code><br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pod=htool-6875bcb898-w7llc</span><br><span class="line">containerid=$(docker ps |grep <span class="variable">$pod</span>|awk <span class="string">'{print $1}'</span>|head -n 1)</span><br><span class="line">pid=$(docker inspect -f {{.State.Pid}} <span class="variable">$containerid</span>)</span><br><span class="line">nsenter -n --target <span class="variable">$pid</span></span><br></pre></td></tr></tbody></table></figure><p></p><p>使用<code>iptables</code> <code>drop</code>掉发往<code>zk</code>的请求(11000为zk server端口)<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -A OUTPUT -p tcp -m tcp --dport 11000 -j DROP</span><br></pre></td></tr></tbody></table></figure><p></p><p>zk client自动重试（1s一次），日志显示<code>Failed to connect to 10.38.161.54:11000: dial tcp 10.38.161.54:11000: i/o timeout</code><br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">I0302 15:04:05.516446       1 zk.go:220] watching zk node:[/tasks/cluster.xxx_default_deployment.htool/10.46.12.72] <span class="keyword">in</span> cluster[xxx]</span><br><span class="line">2021/03/02 15:08:55 recv loop terminated: err=failed to <span class="built_in">read</span> from connection: <span class="built_in">read</span> tcp 10.46.12.72:36884-&gt;10.38.161.60:11000: i/o timeout</span><br><span class="line">2021/03/02 15:08:55 send loop terminated: err=&lt;nil&gt;</span><br><span class="line">2021/03/02 15:08:56 Failed to connect to 10.38.161.54:11000: dial tcp 10.38.161.54:11000: i/o timeout</span><br></pre></td></tr></tbody></table></figure><p></p><p>网络恢复，删除<code>iptables</code><br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -D OUTPUT -p tcp -m tcp --dport 11000 -j DROP</span><br></pre></td></tr></tbody></table></figure><p></p><p>出现大量<code>StateDisconnected</code>日志<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">I0302 15:09:50.951897       1 zk.go:232] Unknown zk event[StateDisconnected] <span class="keyword">for</span> znode:[/tasks/cluster.xxx_default_deployment.htool/10.46.12.72]</span><br><span class="line">I0302 15:09:50.951893       1 zk.go:232] Unknown zk event[StateDisconnected] <span class="keyword">for</span> znode:[/tasks/cluster.xxx_default_deployment.htool/10.46.12.72]</span><br><span class="line">...</span><br></pre></td></tr></tbody></table></figure><p></p><h3 id="问题分析-1"><a href="#问题分析-1" class="headerlink" title="问题分析"></a>问题分析</h3><p><code>sidecar</code>中zk watch代码如下：<br></p><figure class="highlight golang"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">exist, _, eventCh, err := conn.ExistsW(node) <span class="comment">//监听zk事件</span></span><br><span class="line">watcher:</span><br><span class="line">        <span class="keyword">for</span> {</span><br><span class="line">                <span class="keyword">select</span> {</span><br><span class="line">                <span class="keyword">case</span> e := &lt;-eventCh:</span><br><span class="line">                        <span class="keyword">switch</span> e.State {</span><br><span class="line">                        <span class="keyword">case</span> zk.StateExpired:</span><br><span class="line">                                <span class="keyword">return</span> fmt.Errorf(<span class="string">"node[%v] expired"</span>, node)</span><br><span class="line">                        <span class="keyword">case</span> zk.StateConnected, zk.StateHasSession:</span><br><span class="line">                                <span class="keyword">return</span> fmt.Errorf(<span class="string">"Get zk event: %v "</span>, e.State)</span><br><span class="line">                        <span class="keyword">default</span>:</span><br><span class="line">                                klog.Infof(<span class="string">"Get zk event[%v] for znode:[%v]"</span>, e.State, node) <span class="comment">// 出错位置</span></span><br><span class="line">                        }</span><br><span class="line">                <span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">                        <span class="comment">// we close the conn in caller</span></span><br><span class="line">                        <span class="keyword">break</span> watcher</span><br><span class="line">                }</span><br><span class="line">        }</span><br></pre></td></tr></tbody></table></figure><p></p><p><code>ExistsW</code>函数由<code>github.com/samuel/go-zookeeper/zk</code>库提供，监听zk给定目录的事件<br></p><figure class="highlight golang"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Conn)</span> <span class="title">ExistsW</span><span class="params">(path <span class="keyword">string</span>)</span> <span class="params">(<span class="keyword">bool</span>, *Stat, &lt;-<span class="keyword">chan</span> Event, error)</span></span> {</span><br><span class="line">    <span class="keyword">var</span> ech &lt;-<span class="keyword">chan</span> Event</span><br><span class="line">    ...</span><br><span class="line">    ech = c.addWatcher(path, watchTypeData)</span><br><span class="line">    <span class="keyword">return</span> exists, &amp;res.Stat, ech, err</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>当zk异常恢复后，<code>c.addWatcher</code>中的<code>channel</code>被<code>close</code>，即<code>sidecar</code>中<code>eventCh</code>关闭，进入死循环。</p><h3 id="修复验证"><a href="#修复验证" class="headerlink" title="修复验证"></a>修复验证</h3><p>知道了原因，修复很简单，判断下eventCh状态即可<br></p><figure class="highlight golang"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> {</span><br><span class="line">    <span class="keyword">select</span> {</span><br><span class="line">    <span class="keyword">case</span> e, ok := &lt;-eventCh:</span><br><span class="line">        <span class="keyword">if</span> !ok {</span><br><span class="line">            <span class="keyword">return</span> fmt.Errorf(<span class="string">"event channel closed"</span>)</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">if</span> e.Err != <span class="literal">nil</span> {</span><br><span class="line">            <span class="keyword">return</span> fmt.Errorf(<span class="string">"Get zk event: %v, err: %v"</span>, e.State, e.Err)</span><br><span class="line">        }</span><br><span class="line">        <span class="keyword">switch</span> e.State {</span><br><span class="line">        <span class="keyword">case</span> zk.StateExpired:</span><br><span class="line">            <span class="keyword">return</span> fmt.Errorf(<span class="string">"node[%v] expired"</span>, node)</span><br><span class="line">        <span class="keyword">case</span> zk.StateConnected, zk.StateHasSession:</span><br><span class="line">            <span class="keyword">return</span> fmt.Errorf(<span class="string">"Get zk event: %v "</span>, e.State)</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            klog.Infof(<span class="string">"Get zk event[%v] for znode:[%v]"</span>, e.State, node)</span><br><span class="line">        }</span><br><span class="line">    }</span><br></pre></td></tr></tbody></table></figure><p></p><p>在修复代码后，再次验证可正常注册<br></p><figure class="highlight golang"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2021</span>/<span class="number">03</span>/<span class="number">02</span> <span class="number">15</span>:<span class="number">13</span>:<span class="number">40</span> Failed to connect to <span class="number">10.38</span><span class="number">.161</span><span class="number">.60</span>:<span class="number">11000</span>: dial tcp <span class="number">10.38</span><span class="number">.161</span><span class="number">.60</span>:<span class="number">11000</span>: i/o timeout</span><br><span class="line"><span class="number">2021</span>/<span class="number">03</span>/<span class="number">02</span> <span class="number">15</span>:<span class="number">13</span>:<span class="number">40</span> Connected to <span class="number">10.38</span><span class="number">.161</span><span class="number">.55</span>:<span class="number">11000</span></span><br><span class="line"><span class="number">2021</span>/<span class="number">03</span>/<span class="number">02</span> <span class="number">15</span>:<span class="number">13</span>:<span class="number">40</span> authentication failed: zk: session has been expired by the server</span><br><span class="line">W0302 <span class="number">15</span>:<span class="number">13</span>:<span class="number">40.222923</span>       <span class="number">1</span> zk.<span class="keyword">go</span>:<span class="number">300</span>] meet error when watching node path: Get zk event: StateDisconnected, err: zk: session has been expired by the server</span><br><span class="line"><span class="number">2021</span>/<span class="number">03</span>/<span class="number">02</span> <span class="number">15</span>:<span class="number">13</span>:<span class="number">40</span> Connected to <span class="number">10.38</span><span class="number">.161</span><span class="number">.54</span>:<span class="number">11000</span></span><br><span class="line"><span class="number">2021</span>/<span class="number">03</span>/<span class="number">02</span> <span class="number">15</span>:<span class="number">13</span>:<span class="number">40</span> authenticated: id=<span class="number">177861994644216038</span>, timeout=<span class="number">30000</span></span><br><span class="line"><span class="number">2021</span>/<span class="number">03</span>/<span class="number">02</span> <span class="number">15</span>:<span class="number">13</span>:<span class="number">40</span> re-submitting <span class="string">`1`</span> credentials after reconnect</span><br><span class="line">I0302 <span class="number">15</span>:<span class="number">13</span>:<span class="number">41.238524</span>       <span class="number">1</span> zk.<span class="keyword">go</span>:<span class="number">220</span>] watching zk node:[/tasks/cluster.xxx_default_deployment.htool/<span class="number">10.46</span><span class="number">.12</span><span class="number">.72</span>] in cluster[xxx]</span><br></pre></td></tr></tbody></table></figure><p></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这个问题其实与<code>zk</code>没关系，是由于没有判断<code>channel</code>状态，陷入死循环。通常情况下大部分应用只有退出时才会关闭<code>channel</code>，不需要特殊处理。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在容器平台上我们提供了&lt;code&gt;zk&lt;/code&gt;做白名单功能，&lt;code&gt;Pod&lt;/code&gt;启动时 sidecar会自动注册&lt;code&gt;zk&lt;/code&gt;。昨天遇到&lt;code&gt;zk server&lt;/code&gt;抖动，&lt;code&gt;sidecar&lt;/code&gt;容器输出大量&lt;code&gt;StateDisconnected&lt;/code&gt;事件，zk正常后仍无法恢复，由于大量日志造成&lt;code&gt;sidecar&lt;/code&gt;容器 cpu占用过高，进而引发&lt;code&gt;dockerd&lt;/code&gt;cpu占用过高，严重时影响dockerd正常调用。&lt;/p&gt;
    
    </summary>
    
      <category term="coding" scheme="https://qingwave.github.io/categories/coding/"/>
    
    
      <category term="golang" scheme="https://qingwave.github.io/tags/golang/"/>
    
      <category term="zk" scheme="https://qingwave.github.io/tags/zk/"/>
    
  </entry>
  
  <entry>
    <title>k8s中shell脚本启动如何传递信号</title>
    <link href="https://qingwave.github.io/docker-shell-signal/"/>
    <id>https://qingwave.github.io/docker-shell-signal/</id>
    <published>2021-02-03T07:13:10.000Z</published>
    <updated>2021-02-04T07:39:19.543Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在k8s或docker中，有时候我们需要通过shell来启动程序，但是默认shell不会传递信号（sigterm）给子进程，当在pod终止时应用无法优雅退出，直到最大时间时间后强制退出（<code>kill -9</code>）。</p><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>普通情况下，大多业务的启动命令如下<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">command</span>: [<span class="string">"binary"</span>, <span class="string">"-flags"</span>, ...]</span><br></pre></td></tr></tbody></table></figure><p></p><p>主进程做为1号进程会收到<code>sigterm</code>信号，优雅退出(需要程序捕获信号); 而通过脚本启动时，<code>shell</code>作为1号进程，不会显示传递信号给子进程，造成子进程无法优雅退出，直到最大退出时间后强制终止。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="exec"><a href="#exec" class="headerlink" title="exec"></a>exec</h3><p>如何只需一个进程收到信号，可通过<code>exec</code>，<code>exec</code>会替换当前shell进程，即<code>pid</code>不变<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"><span class="comment"># do something</span></span><br><span class="line"><span class="built_in">exec</span> binay -flags ...</span><br></pre></td></tr></tbody></table></figure><p></p><p>正常情况测试命令如下，使用sleep来模拟应用<code>sh -c 'echo "start"; sleep 100'</code>：<br><code>pstree</code>展示如下，<code>sleep</code>进程会生成一个子进程<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash(28701)───sh(24588)───sleep(24589)</span><br></pre></td></tr></tbody></table></figure><p></p><p>通过<code>exec</code>运行后，命令<code>sh -c 'echo "start"; exec sleep 100'</code><br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash(28701)───sleep(24664)</span><br></pre></td></tr></tbody></table></figure><p></p><p>加入<code>exec</code>后，<code>sleep</code>进程替换了shell进程，没有生成子进程</p><p>此种方式可以收到信号，但只适用于一个子进程的情况</p><h3 id="trap"><a href="#trap" class="headerlink" title="trap"></a>trap</h3><p>在shell中可以显示通过<code>trap</code>捕捉信号传递给子进程<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"start"</span></span><br><span class="line">binary -flags... &amp;</span><br><span class="line">pid=<span class="string">"$!"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">_kill</span></span>() {</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"receive sigterm"</span></span><br><span class="line">  <span class="built_in">kill</span> <span class="variable">$pid</span> <span class="comment">#传递给子进程</span></span><br><span class="line">  <span class="built_in">wait</span> <span class="variable">$pid</span></span><br><span class="line">  <span class="built_in">exit</span> 0</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="built_in">trap</span> _kill SIGTERM <span class="comment">#捕获信号</span></span><br><span class="line"><span class="built_in">wait</span> <span class="comment">#等待子进程退出</span></span><br></pre></td></tr></tbody></table></figure><p></p><p>此种方式需要改动启动脚本，显示传递信号给子进程</p><h2 id="docker-init"><a href="#docker-init" class="headerlink" title="docker-init"></a>docker-init</h2><p><a href="https://docs.docker.com/engine/reference/run/#specify-an-init-process" target="_blank" rel="noopener">docker-init</a>即在docker启动时加入<code>--init</code>参数，docker-int会作为一号进程，会向子进程传递信号并且会回收僵尸进程。</p><p>遗憾的是k8s并不支持<code>--init</code>参数，用户可在镜像中声明init进程，更多可参考<a href="./container-init.md">container-init</a><br></p><figure class="highlight dockerfile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> wget -O /usr/bin/dumb-init https://github.com/Yelp/dumb-init/releases/download/v1.2.2/dumb-init_1.2.2_amd64</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> chmod +x /usr/bin/dumb-init</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">"/usr/bin/dumb-init"</span>, <span class="string">"-v"</span>, <span class="string">"--"</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"nginx"</span>, <span class="string">"-g"</span>, <span class="string">"daemon off;"</span>]</span></span><br></pre></td></tr></tbody></table></figure><p></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在k8s或docker中，有时候我们需要通过shell来启动程序，但是默认shell不会传递信号（sigterm）给子进程，当在pod终止时应用无法优雅退出，直到最大时间时间后强制退出（&lt;code&gt;kill -9&lt;/code&gt;）。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="docker" scheme="https://qingwave.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>优化Kubernetes集群内DNS</title>
    <link href="https://qingwave.github.io/k8s-dns-optimize/"/>
    <id>https://qingwave.github.io/k8s-dns-optimize/</id>
    <published>2021-02-01T02:17:40.000Z</published>
    <updated>2021-02-03T07:13:09.478Z</updated>
    
    <content type="html"><![CDATA[<p>kubernetes集群内置的dns插件<code>kubedns/coredns</code>在高并发情况下可能遇到性能瓶颈，以下从配置与本地缓存方面说明如何减少dns查询失败率，提高性能。</p><h2 id="配置优化"><a href="#配置优化" class="headerlink" title="配置优化"></a>配置优化</h2><h3 id="dnsPolicy"><a href="#dnsPolicy" class="headerlink" title="dnsPolicy"></a>dnsPolicy</h3><p>k8s 默认的 <code>dnsPolicy</code> 是<code>ClusterFirst</code>，因为 <code>ndots</code> 和 <code>serach domain</code> 在访问外部 dns 会有额外的查询次数。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># cat /etc/resolv.conf </span></span><br><span class="line">nameserver 10.254.0.2</span><br><span class="line">search default.svc.cluster.local svc.cluster.local cluster.local</span><br><span class="line">options ndots:5</span><br><span class="line">/ <span class="comment"># </span></span><br><span class="line">/ <span class="comment"># </span></span><br><span class="line">/ <span class="comment">#  host -v mi.com</span></span><br><span class="line">Trying <span class="string">"mi.com.default.svc.cluster.local"</span></span><br><span class="line">Trying <span class="string">"mi.com.svc.cluster.local"</span></span><br><span class="line">Trying <span class="string">"mi.com.cluster.local"</span></span><br><span class="line">Trying <span class="string">"mi.com"</span></span><br><span class="line">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 38967</span><br><span class="line">;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0</span><br><span class="line"></span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;mi.com.                                IN        A</span><br><span class="line"></span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">mi.com.                        30        IN        A        58.83.160.156</span><br></pre></td></tr></tbody></table></figure><p>如果不访问service，调整<code>dnsPolicy</code>为<code>Default</code>，直接走宿主机的dns</p><h3 id="ndots"><a href="#ndots" class="headerlink" title="ndots"></a>ndots</h3><p>如需访问service，尽量减少<code>ndots</code>（默认5）即域名中点的个数小于<code>ndots</code>会按照search域（mi.com.default.svc.cluster.local）依次查询，若查询不到再查询原始域名，总共进行8次dns查询（4次ipv4, 4次ipv6）</p><p>设置<code>ndots</code>为1后，只有两次查询（1次ipv4, ipv6）<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment">#  host -v mi.com</span></span><br><span class="line">Trying <span class="string">"mi.com"</span></span><br><span class="line">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 23894</span><br><span class="line">;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0</span><br><span class="line"></span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;mi.com.                                IN        A</span><br><span class="line"></span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">mi.com.                        30        IN        A        58.83.160.156</span><br></pre></td></tr></tbody></table></figure><p></p><p>但此种方式service域名分割大于等于<code>ndots</code>，则解析不到，需要业务自行判断合适的<code>ndots</code>值<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment">#  host -v prometheus.kube-system</span></span><br><span class="line">Trying <span class="string">"prometheus.kube-system"</span></span><br><span class="line">Host prometheus.kube-system not found: 3(NXDOMAIN)</span><br><span class="line">Received 115 bytes from 10.254.0.2<span class="comment">#53 in 8 ms</span></span><br><span class="line">Received 115 bytes from 10.254.0.2<span class="comment">#53 in 8 ms</span></span><br></pre></td></tr></tbody></table></figure><p></p><h3 id="coredns优化"><a href="#coredns优化" class="headerlink" title="coredns优化"></a>coredns优化</h3><p>调整合理的副本数，阿里建议<code>coredns:node=1:8</code>，启动<code>AutoPath</code>插件减少查询次数，见<a href="2">DNS性能优化</a></p><h2 id="DNS缓存"><a href="#DNS缓存" class="headerlink" title="DNS缓存"></a>DNS缓存</h2><h3 id="NodeLocalDNS"><a href="#NodeLocalDNS" class="headerlink" title="NodeLocalDNS"></a>NodeLocalDNS</h3><p>NodeLocal DNSCache 通过在集群节点上作为 DaemonSet 运行 dns 缓存代理来提高集群 DNS 性能，<br>借助这种新架构，Pods 将可以访问在同一节点上运行的 dns 缓存代理，从而避免了 iptables DNAT 规则和连接跟踪。</p><p>架构如下:<br><img src="https://d33wubrfki0l68.cloudfront.net/bf8e5eaac697bac89c5b36a0edb8855c860bfb45/6944f/images/docs/nodelocaldns.svg" alt="local-dns"></p><p>NodeLocalDNS的设计提案见（<a href="3">nodelocal-dns-cache</a>）</p><h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><p>官方安装方式见<a href="https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dns/nodelocaldns" target="_blank" rel="noopener">nodelocaldns</a>，需要自行替换变量</p><p>可通过如下脚本，一键安装（注意设置kubedns svc ClusterIP）<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/addons/dns/nodelocaldns/nodelocaldns.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># registery</span></span><br><span class="line">docker_registery=k8s.gcr.io/dns/k8s-dns-node-cache</span><br><span class="line"><span class="comment"># kube-dns svc clusterip</span></span><br><span class="line">kubedns_svc=10.254.0.2</span><br><span class="line"><span class="comment"># nodelocaldns ip</span></span><br><span class="line">nodelocaldns_ip=169.254.20.10</span><br><span class="line"><span class="comment"># kube-proxy mode, iptables or ipvs</span></span><br><span class="line">kubeproxy_mode=iptables</span><br><span class="line">result=result.yaml</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">${kubeproxy_mode}</span> == <span class="string">"ipvs"</span> ]; <span class="keyword">then</span></span><br><span class="line">    sed -e <span class="string">"s|k8s.gcr.io/dns/k8s-dns-node-cache|<span class="variable">$docker_registery</span>|g"</span> \</span><br><span class="line">        -e <span class="string">"s/__PILLAR__CLUSTER__DNS__/<span class="variable">$kubedns_svc</span>/g"</span> \</span><br><span class="line">        -e <span class="string">"s/__PILLAR__LOCAL__DNS__/<span class="variable">$nodelocaldns_ip</span>/g"</span> \</span><br><span class="line">        -e <span class="string">'s/[ |,]__PILLAR__DNS__SERVER__//g'</span> \</span><br><span class="line">        -e <span class="string">"s/__PILLAR__DNS__DOMAIN__/cluster.local/g"</span> nodelocaldns.yaml &gt;<span class="variable">$result</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    sed -e <span class="string">"s|k8s.gcr.io/dns/k8s-dns-node-cache|<span class="variable">$docker_registery</span>|g"</span> \</span><br><span class="line">        -e <span class="string">"s/__PILLAR__DNS__SERVER__/<span class="variable">$kubedns_svc</span>/g"</span> \</span><br><span class="line">        -e <span class="string">"s/__PILLAR__LOCAL__DNS__/<span class="variable">$nodelocaldns_ip</span>/g"</span> \</span><br><span class="line">        -e <span class="string">"s/__PILLAR__DNS__DOMAIN__/cluster.local/g"</span> nodelocaldns.yaml &gt;<span class="variable">$result</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">kubectl apply -f <span class="variable">$result</span></span><br></pre></td></tr></tbody></table></figure><p></p><p>创建完成后，每个节点运行一个pod，查看pod(个别节点ingress-nginx占用8080端口，导致nodelocaldns启动失败)<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl  get po -n kube-system -l k8s-app=node-local-dns -o wide</span></span><br><span class="line">NAME                   READY   STATUS             RESTARTS   AGE    IP              NODE                            NOMINATED NODE   READINESS GATES</span><br><span class="line">node-local-dns-2fvxb   0/1     CrashLoopBackOff   4          103s   10.38.200.195   node04          &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-local-dns-4zmcd   1/1     Running            0          54d    10.38.201.55    node06   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-local-dns-55tzg   1/1     Running            0          60d    10.38.200.186   node02          &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-local-dns-cctg7   1/1     Running            0          54d    10.38.200.242   node07   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-local-dns-khgmm   1/1     Running            0          54d    10.38.201.36    node08   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-local-dns-mbr64   1/1     Running            0          60d    10.38.200.187   node05          &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-local-dns-t67vw   1/1     Running            0          60d    10.38.200.188   node03          &lt;none&gt;           &lt;none&gt;</span><br><span class="line">node-local-dns-tmm92   1/1     Running            14         54d    10.38.200.57    node09   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></tbody></table></figure><p></p><p>默认配置如下：<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">cluster.local:53 {</span><br><span class="line">    errors</span><br><span class="line">    cache {</span><br><span class="line">            success 9984 30 <span class="comment"># 默认成功缓存30s</span></span><br><span class="line">            denial 9984 5 <span class="comment">#失败缓存5s</span></span><br><span class="line">    }</span><br><span class="line">    reload</span><br><span class="line">    loop</span><br><span class="line">    <span class="built_in">bind</span> 169.254.20.10 10.254.0.2 <span class="comment">#本地监听ip</span></span><br><span class="line">    forward . 10.254.132.95 { <span class="comment">#转发到kubedns-upstream</span></span><br><span class="line">            force_tcp</span><br><span class="line">    }</span><br><span class="line">    prometheus :9253 <span class="comment">#监控接口</span></span><br><span class="line">    health 169.254.20.10:8080 <span class="comment">#健康检测端口</span></span><br><span class="line">    }</span><br><span class="line"><span class="keyword">in</span>-addr.arpa:53 {</span><br><span class="line">    errors</span><br><span class="line">    cache 30</span><br><span class="line">    reload</span><br><span class="line">    loop</span><br><span class="line">    <span class="built_in">bind</span> 169.254.20.10 10.254.0.2</span><br><span class="line">    forward . 10.254.132.95 {</span><br><span class="line">            force_tcp</span><br><span class="line">    }</span><br><span class="line">    prometheus :9253</span><br><span class="line">    }</span><br><span class="line">ip6.arpa:53 {</span><br><span class="line">    errors</span><br><span class="line">    cache 30</span><br><span class="line">    reload</span><br><span class="line">    loop</span><br><span class="line">    <span class="built_in">bind</span> 169.254.20.10 10.254.0.2</span><br><span class="line">    forward . 10.254.132.95 {</span><br><span class="line">            force_tcp</span><br><span class="line">    }</span><br><span class="line">    prometheus :9253</span><br><span class="line">    }</span><br><span class="line">.:53 {</span><br><span class="line">    errors</span><br><span class="line">    cache 30</span><br><span class="line">    reload</span><br><span class="line">    loop</span><br><span class="line">    <span class="built_in">bind</span> 169.254.20.10 10.254.0.2</span><br><span class="line">    forward . /etc/resolv.conf</span><br><span class="line">    prometheus :9253</span><br><span class="line">    }</span><br></pre></td></tr></tbody></table></figure><p></p><p>节点上查看localdns的网卡，本地将监听<code>169.254.20.10</code>与<code>10.254.0.2</code>两个地址，拦截kubedns((默认<code>10.254.0.2</code>)的请求，命中后直接返回，若未命中转发到kubedns(对应service <code>kube-dns-upstream</code>，kube-dns-upstream由localdns创建绑定kubedns pod)<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ip addr show nodelocaldns</span></span><br><span class="line">182232: nodelocaldns: &lt;BROADCAST,NOARP&gt; mtu 1500 qdisc noop state DOWN </span><br><span class="line">    link/ether 4e:62:1c:fd:56:12 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 169.254.20.10/32 brd 169.254.20.10 scope global nodelocaldns</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 10.254.0.2/32 brd 10.254.0.2 scope global nodelocaldns</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></tbody></table></figure><p></p><p>iptables规则，使用<code>NOTRACK</code>跳过其它表处理<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">iptables-save | egrep <span class="string">"10.254.0.2|169.254.20.10"</span></span><br><span class="line">-A PREROUTING -d 10.254.0.2/32 -p udp -m udp --dport 53 -j NOTRACK</span><br><span class="line">-A PREROUTING -d 10.254.0.2/32 -p tcp -m tcp --dport 53 -j NOTRACK</span><br><span class="line">-A PREROUTING -d 169.254.20.10/32 -p udp -m udp --dport 53 -j NOTRACK</span><br><span class="line">-A PREROUTING -d 169.254.20.10/32 -p tcp -m tcp --dport 53 -j NOTRACK</span><br><span class="line"></span><br><span class="line">-A OUTPUT -d 10.254.0.2/32 -p udp -m udp --dport 53 -j NOTRACK</span><br><span class="line">-A OUTPUT -d 10.254.0.2/32 -p tcp -m tcp --dport 53 -j NOTRACK</span><br><span class="line"></span><br><span class="line">-A INPUT -d 10.254.0.2/32 -p udp -m udp --dport 53 -j ACCEPT</span><br><span class="line">-A INPUT -d 10.254.0.2/32 -p tcp -m tcp --dport 53 -j ACCEPT</span><br><span class="line">-A OUTPUT -s 10.254.0.2/32 -p udp -m udp --sport 53 -j ACCEPT</span><br><span class="line">-A OUTPUT -s 10.254.0.2/32 -p tcp -m tcp --sport 53 -j ACCEPT</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">-A KUBE-SERVICES -d 10.254.0.2/32 -p tcp -m comment --comment <span class="string">"kube-system/kube-dns:dns-tcp cluster IP"</span> -m tcp --dport 53 -j KUBE-SVC-ERIFXISQEP7F7OF4</span><br><span class="line">-A KUBE-SERVICES -d 10.254.0.2/32 -p tcp -m comment --comment <span class="string">"kube-system/kube-dns:metrics cluster IP"</span> -m tcp --dport 9153 -j KUBE-SVC-JD5MR3NA4I4DYORP</span><br><span class="line">-A KUBE-SERVICES -d 10.254.0.2/32 -p udp -m comment --comment <span class="string">"kube-system/kube-dns:dns cluster IP"</span> -m udp --dport 53 -j KUBE-SVC-TCOU7JCQXEZGVUNU</span><br></pre></td></tr></tbody></table></figure><p></p><p>在pod通过localdns解析域名<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl  exec -it dns-perf-client-64cfb49f9-9c5hg sh</span></span><br><span class="line">/ <span class="comment"># nslookup kubernetes 169.254.20.10</span></span><br><span class="line">Server:                169.254.20.10</span><br><span class="line">Address:        169.254.20.10<span class="comment">#53</span></span><br><span class="line"></span><br><span class="line">Name:        kubernetes.default.svc.cluster.local</span><br><span class="line">Address: 10.254.0.1</span><br></pre></td></tr></tbody></table></figure><p></p><h4 id="压测"><a href="#压测" class="headerlink" title="压测"></a>压测</h4><p>通过<code>dnsperf</code>进行压测</p><p>测试域名列表如下<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat records.txt </span></span><br><span class="line">mi.com A</span><br><span class="line">github.com A</span><br><span class="line">www.microsoft.com A</span><br><span class="line">www.aliyun.com A</span><br><span class="line">kubernetes.io A</span><br><span class="line">nginx A</span><br><span class="line">nginx.default A</span><br><span class="line">kubernetes A</span><br><span class="line">kubernetes.default.svc.cluster.local A</span><br><span class="line">kube-dns.kube-system.svc.cluster.local A</span><br></pre></td></tr></tbody></table></figure><p></p><p>测试命令<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dnsperf -l 120 -s 10.254.0.2 -d records.txt</span><br></pre></td></tr></tbody></table></figure><p></p><p>结果如下<br>| |client number|qps|avg-lantency(ms)|stddev(ms)|lost| |<br>|:—-|:—-|:—-|:—-|:—-|:—-|:—-|<br>|kubedns(1 pod)|1|53910|1.83|6.07|0%| |<br>|kubedns(2 pod)|2|110000|1.83|1.94|9%| |<br>|kubedns(4 pod)|4|120000|3.2|0.8|24%| |<br>|nodelocaldns|1|71494|1.39|1.66|0%| |<br>|nodelocaldns|2|142000|1.37|1.55|0%| |</p><p>相比<code>nodelocaldns</code>，<code>localdns</code>查询性能提高了33%，而且延时相对更小，由于<code>localdns</code>是分布式的整体qps相对kubedns有较大优势。当前测试相对简单，大部分请求会命中缓存，完整的测试结果待进一步验证。</p><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><p>优点：</p><ul><li>大幅减少dns查询延时</li><li>提高dns qps</li><li>不经过<code>iptables</code>与<code>conntrack</code></li><li>默认使用tcp查询dns，避免 dns 5秒延时</li></ul><p>缺点：</p><ul><li>单点故障（OOM/Evicted/Config Error/Upgrade），社区通过起一个探测daemonset监听localdns状态，如果localdns异常将去掉iptables规则</li><li><code>hostnetwork</code>, 占用多个端口（8080, 9253等）</li><li>ipvs模式下，需要改动kubelet默认dns配置（<code>NOTRACK</code>将对<code>ipvs</code>无效，除非service后端实例为0）</li></ul><p>注意事项</p><ul><li>低版本dns存在tcp请求内存泄露</li><li>安装时<code>iptables</code>与<code>ipvs</code>配置不同</li></ul><h4 id="HA"><a href="#HA" class="headerlink" title="HA"></a>HA</h4><ul><li>社区提案将<code>iptables</code>写入规则从<code>nodelocaldns</code>拆分为单独的daemonset，通过监听<code>localdns</code>地址来判断是否写入或删除<code>iptables</code>规则（ipvs默认下无效）</li><li>在<code>/etc/resolv.conf</code>配置多个<code>nameservers</code>(不推荐，不同基础库表现不同，如<code>glibc 2.16+</code>查询dns时会向多个<code>nameservers</code>发送请求，反而造成了请求激增)</li></ul><h4 id="灰度方式"><a href="#灰度方式" class="headerlink" title="灰度方式"></a>灰度方式</h4><ul><li>通过<code>dnsConfi</code>g配置Pod级别dns（需要配置启动参数localip）</li><li>通过设置<code>nodeselector</code>灰度Node级别dns策略</li></ul><h3 id="本地DNS缓存"><a href="#本地DNS缓存" class="headerlink" title="本地DNS缓存"></a>本地DNS缓存</h3><p>除了nodelocaldns，用户还可以在容器内或者添加sidecar来启用dns缓存</p><ol><li><p>通过在镜像中加入nscd进程，缓存dns，如下：</p> <figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y nscd &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line">CMD service nscd start; bash -c <span class="string">"sleep 3600"</span></span><br></pre></td></tr></tbody></table></figure><p> 此种方式需要用户改动镜像，或者加入额外脚本配置<code>nscd</code></p></li><li><p>另外可以配置可配置dns缓存 sidecar（如<code>coredns</code>, <code>dnsmasq</code>）来提高性能，此种方式灵活性高，但需要改动pod配置，而且较<code>nodelocaldns</code>浪费资源</p></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] <a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/nodelocaldns/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/tasks/administer-cluster/nodelocaldns/</a><br>[2] <a href="https://help.aliyun.com/document_detail/172339.html" target="_blank" rel="noopener">https://help.aliyun.com/document_detail/172339.html</a><br>[3] <a href="https://github.com/kubernetes/enhancements/blob/master/keps/sig-network/0030-nodelocal-dns-cache.md" target="_blank" rel="noopener">https://github.com/kubernetes/enhancements/blob/master/keps/sig-network/0030-nodelocal-dns-cache.md</a><br>[4] <a href="https://github.com/kubernetes/enhancements/blob/master/keps/sig-network/1024-nodelocal-cache-dns/README.md" target="_blank" rel="noopener">https://github.com/kubernetes/enhancements/blob/master/keps/sig-network/1024-nodelocal-cache-dns/README.md</a><br>[5] <a href="https://lework.github.io/2020/11/09/node-local-dns/" target="_blank" rel="noopener">https://lework.github.io/2020/11/09/node-local-dns/</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;kubernetes集群内置的dns插件&lt;code&gt;kubedns/coredns&lt;/code&gt;在高并发情况下可能遇到性能瓶颈，以下从配置与本地缓存方面说明如何减少dns查询失败率，提高性能。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="dns" scheme="https://qingwave.github.io/tags/dns/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes apiserver限流方案</title>
    <link href="https://qingwave.github.io/k8s-rate-limit/"/>
    <id>https://qingwave.github.io/k8s-rate-limit/</id>
    <published>2020-11-11T05:17:00.000Z</published>
    <updated>2020-11-11T06:23:53.575Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>为了防止突发流量影响apiserver可用性，k8s支持多种限流配置，包括：</p><ul><li>MaxInFlightLimit，server级别整体限流</li><li>Client限流</li><li>EventRateLimit, 限制event</li><li>APF，更细力度的限制配置</li></ul><h3 id="MaxInFlightLimit"><a href="#MaxInFlightLimit" class="headerlink" title="MaxInFlightLimit"></a>MaxInFlightLimit</h3><p>MaxInFlightLimit限流，apiserver默认可设置最大并发量（集群级别，区分只读与修改操作），通过参数<code>--max-requests-inflight</code>和 <code>--max-mutating-requests-inflight</code>， 可以简单实现限流。</p><h3 id="Client限流"><a href="#Client限流" class="headerlink" title="Client限流"></a>Client限流</h3><p>例如client-go默认的qps为5，但是只支持客户端限流，集群管理员无法控制用户行为。</p><h3 id="EventRateLimit"><a href="#EventRateLimit" class="headerlink" title="EventRateLimit"></a>EventRateLimit</h3><p>EventRateLimit在1.13之后支持，只限制event请求，集成在apiserver内部webhoook中，可配置某个用户、namespace、server等event操作限制，通过webhook形式实现。</p><p>具体原理可以参考<a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/admission-controllers/#eventratelimit" target="_blank" rel="noopener">提案</a>，每个eventratelimit 配置使用一个单独的令牌桶限速器，每次event操作，遍历每个匹配的限速器检查是否能获取令牌，如果可以允许请求，否则返回<code>429</code>。</p><p><strong>优点</strong></p><ul><li>实现简单，允许一定量的并发</li><li>可支持server/namespace/user等级别的限流</li></ul><p><strong>缺点</strong></p><ul><li>仅支持event，通过webhook实现只能拦截修改类请求</li><li>所有namespace的限流相同，没有优先级</li></ul><h3 id="API-优先级和公平性"><a href="#API-优先级和公平性" class="headerlink" title="API 优先级和公平性"></a>API 优先级和公平性</h3><p>apiserver默认的限流方式太过简单，一个错误的客户端发送大量请求可能造成其他客户端请求异常，也不支持突发流量。</p><p>API 优先级和公平性（APF）是MaxInFlightLimit限流的一种替代方案，设计文档见<a href="https://github.com/kubernetes/enhancements/tree/master/keps/sig-api-machinery/1040-priority-and-fairness" target="_blank" rel="noopener">提案</a>。</p><p>API 优先级和公平性（1.15以上，alpha版本）， 以更细粒度（byUser，byNamespace）对请求进行分类和隔离。 支持突发流量，通过使用公平排队技术从队列中分发请求从而避免饥饿。</p><p>APF限流通过两种资源，<code>PriorityLevelConfigurations</code>定义隔离类型和可处理的并发预算量，还可以调整排队行为。 <code>FlowSchemas</code>用于对每个入站请求进行分类，并与一个 <code>PriorityLevelConfigurations</code>相匹配。</p><p>可对用户或用户组或全局进行某些资源某些请求的限制，如限制default namespace写services put/patch请求。</p><p><strong>优点</strong></p><ul><li>考虑情况较全面，支持优先级，白名单等</li><li>可支持server/namespace/user/resource等细粒度级别的限流</li></ul><p><strong>缺点</strong></p><ul><li>配置复杂，不直观，需要对APF原理深入了解</li><li>功能较新，缺少生产环境验证</li></ul><p><strong>APF测试</strong><br>开启APF，需要在apiserver配置<code>--feature-gates=APIPriorityAndFairness=true --runtime-config=flowcontrol.apiserver.k8s.io/v1alpha1=true</code></p><p>开启后，获取默认的FlowSchemas</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get flowschemas.flowcontrol.apiserver.k8s.io </span><br><span class="line">NAME                           PRIORITYLEVEL     MATCHINGPRECEDENCE   DISTINGUISHERMETHOD   AGE    MISSINGPL</span><br><span class="line">system-leader-election         leader-election   100                  ByUser                152m   False</span><br><span class="line">workload-leader-election       leader-election   200                  ByUser                152m   False</span><br><span class="line">system-nodes                   system            500                  ByUser                152m   False</span><br><span class="line">kube-controller-manager        workload-high     800                  ByNamespace           152m   False</span><br><span class="line">kube-scheduler                 workload-high     800                  ByNamespace           152m   False</span><br><span class="line">kube-system-service-accounts   workload-high     900                  ByNamespace           152m   False</span><br><span class="line">health-for-strangers           exempt            1000                 &lt;none&gt;                151m   False</span><br><span class="line">service-accounts               workload-low      9000                 ByUser                152m   False</span><br><span class="line">global-default                 global-default    9900                 ByUser                152m   False</span><br><span class="line">catch-all                      catch-all         10000                ByUser                152m   False</span><br></pre></td></tr></tbody></table></figure><p>FlowShema配置<br></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">flowcontrol.apiserver.k8s.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">FlowSchema</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">health-for-strangers</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  matchingPrecedence:</span> <span class="number">1000</span> <span class="comment">#匹配优先级，1~1000，越小优先级越高</span></span><br><span class="line"><span class="attr">  priorityLevelConfiguration:</span> <span class="comment">#关联的PriorityLevelConfigurations</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">exempt</span> <span class="comment">#排除rules，即不限制当前flowshema的rules</span></span><br><span class="line"><span class="attr">  rules:</span> <span class="comment">#请求规则</span></span><br><span class="line"><span class="attr">  - nonResourceRules:</span> <span class="comment">#非资源</span></span><br><span class="line"><span class="attr">    - nonResourceURLs:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"/healthz"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"/livez"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"/readyz"</span></span><br><span class="line"><span class="attr">      verbs:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"*"</span></span><br><span class="line"><span class="attr">    subjects:</span> <span class="comment">#对应的用户或用户组</span></span><br><span class="line"><span class="attr">    - kind:</span> <span class="string">Group</span></span><br><span class="line"><span class="attr">      group:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="attr">system:unauthenticated</span></span><br></pre></td></tr></tbody></table></figure><p></p><p>PriorityLevelConfiguration配置<br></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">flowcontrol.apiserver.k8s.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PriorityLevelConfiguration</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">leader-election</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  limited:</span> <span class="comment">#限制策略</span></span><br><span class="line"><span class="attr">    assuredConcurrencyShares:</span> <span class="number">10</span> </span><br><span class="line"><span class="attr">    limitResponse:</span> <span class="comment">#如何处理被限制的请求</span></span><br><span class="line"><span class="attr">      queuing:</span> <span class="comment">#类型为Queue时，列队的设置</span></span><br><span class="line"><span class="attr">        handSize:</span> <span class="number">4</span> <span class="comment">#队列</span></span><br><span class="line"><span class="attr">        queueLengthLimit:</span> <span class="number">50</span> <span class="comment">#队列长度</span></span><br><span class="line"><span class="attr">        queues:</span> <span class="number">16</span> <span class="comment">#队列数</span></span><br><span class="line"><span class="attr">      type:</span> <span class="string">Queue</span> <span class="comment">#Queue或者Reject，Reject直接返回429，Queue将请求加入队列</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">Limited</span> <span class="comment">#类型，Limited或Exempt， Exempt即不限制</span></span><br></pre></td></tr></tbody></table></figure><p></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上是k8s相关的限流策略，通过多种策略来保证集群的稳定性。</p><p>目前MaxInFlightLimit可以轻松开启，但是限制策略不精细，而APF功能较新，实现较复杂，在充分验证后，可通过APF对全集群进行限流。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;为了防止突发流量影响apiserver可用性，k8s支持多种限流配置，包括：&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="apiserver" scheme="https://qingwave.github.io/tags/apiserver/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes中Sidecar生命周期管理</title>
    <link href="https://qingwave.github.io/k8s-sideccar-lifecycle/"/>
    <id>https://qingwave.github.io/k8s-sideccar-lifecycle/</id>
    <published>2020-09-21T03:45:00.000Z</published>
    <updated>2020-09-21T06:30:50.643Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在多个容器的Pod中，通常业务容器需要依赖sidecar。启动时sidecar需要先启动，退出时sidecar需要在业务容器退出后再退出。k8s目前对于sidecar的生命周期比较有争议，见<a href="https://github.com/kubernetes/enhancements/issues/753" target="_blank" rel="noopener">issue</a>、<a href="https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/0753-sidecarcontainers.md" target="_blank" rel="noopener">sidecarcontainers</a>。</p><p>Kubernetes Pod 内有两种容器: 初始化容器(init container)和应用容器(app container)。</p><p>其中初始化容器的执行先于应用容器，按顺序启动，执行成功启动下一个：<br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> container := podContainerChanges.NextInitContainerToStart; container != <span class="literal">nil</span> {</span><br><span class="line">    <span class="comment">// Start the next init container.</span></span><br><span class="line">    <span class="keyword">if</span> err := start(<span class="string">"init container"</span>, containerStartSpec(container)); err != <span class="literal">nil</span> {</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Successfully started the container; clear the entry in the failure</span></span><br><span class="line">    klog.V(<span class="number">4</span>).Infof(<span class="string">"Completed init container %q for pod %q"</span>, container.Name, format.Pod(pod))</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>而对于应用容器，无法保证容器ready顺序，启动代码如下:<br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Step 7: start containers in podContainerChanges.ContainersToStart.</span></span><br><span class="line"><span class="keyword">for</span> _, idx := <span class="keyword">range</span> podContainerChanges.ContainersToStart {</span><br><span class="line">    <span class="comment">// start函数向docker发请求启动容器，这里没有检测函数返回而且不确定ENTRYPOINT是否成功</span></span><br><span class="line">    start(<span class="string">"container"</span>, containerStartSpec(&amp;pod.Spec.Containers[idx]))</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>在删除时，同样无法保证删除顺序，代码如下<br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _, container := <span class="keyword">range</span> runningPod.Containers {</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(container *kubecontainer.Container)</span></span> {</span><br><span class="line">        killContainerResult := kubecontainer.NewSyncResult(kubecontainer.KillContainer, container.Name)</span><br><span class="line">        <span class="comment">// 每一个容器起goroutine执行删除</span></span><br><span class="line">        <span class="keyword">if</span> err := m.killContainer(pod, container.ID, container.Name, <span class="string">""</span>, gracePeriodOverride); err != <span class="literal">nil</span> {</span><br><span class="line">           ...</span><br><span class="line">        }</span><br><span class="line">        containerResults &lt;- killContainerResult</span><br><span class="line">    }(container)</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><h2 id="启动顺序"><a href="#启动顺序" class="headerlink" title="启动顺序"></a>启动顺序</h2><p>k8s原生方式，对于pod中一个容器依赖另一个容器，目前需要业务进程判断依赖服务是否启动或者sleep 10s，这种方式可以工作，但不太优雅。需要业务更改启动脚本。</p><p>那么，有没有其他的解决办法？</p><h3 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h3><p>在启动时，start函数调用startContainer来创建容器，主要代码如下：<br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *kubeGenericRuntimeManager)</span> <span class="title">startContainer</span><span class="params">(podSandboxID <span class="keyword">string</span>, podSandboxConfig *runtimeapi.PodSandboxConfig, spec *startSpec, pod *v1.Pod, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, podIP <span class="keyword">string</span>, podIPs []<span class="keyword">string</span>)</span> <span class="params">(<span class="keyword">string</span>, error)</span></span> {</span><br><span class="line">    container := spec.container</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Step 1: 拉镜像.</span></span><br><span class="line">    imageRef, msg, err := m.imagePuller.EnsureImageExists(pod, container, pullSecrets, podSandboxConfig)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">        ...</span><br><span class="line">     }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Step 2: 调用cri创建容器</span></span><br><span class="line">    <span class="comment">// For a new container, the RestartCount should be 0</span></span><br><span class="line">    containerID, err := m.runtimeService.CreateContainer(podSandboxID, containerConfig, podSandboxConfig)</span><br><span class="line">   ...</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Step 3: 启动容器</span></span><br><span class="line">    err = m.runtimeService.StartContainer(containerID)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Step 4: 执行 post start hook.</span></span><br><span class="line">    <span class="keyword">if</span> container.Lifecycle != <span class="literal">nil</span> &amp;&amp; container.Lifecycle.PostStart != <span class="literal">nil</span> {</span><br><span class="line">        kubeContainerID := kubecontainer.ContainerID{</span><br><span class="line">            Type: m.runtimeName,</span><br><span class="line">            ID:   containerID,</span><br><span class="line">        }</span><br><span class="line">        <span class="comment">// 调用Run来执行hook</span></span><br><span class="line">        msg, handlerErr := m.runner.Run(kubeContainerID, pod, container, container.Lifecycle.PostStart)</span><br><span class="line">        ...</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">""</span>, <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>步骤如下：</p><ol><li>拉取镜像</li><li>创建容器</li><li>启动容器</li><li>执行hook</li></ol><p>一个Pod中容器的启动是有顺序的，排在前面容器的先启动。同时第一个容器执行完ENTRYPOINT和PostStart之后（异步执行，无法确定顺序），k8s才会创建第二个容器（这样的话就可以保证第一个容器创建多长时间后再启动第二个容器）</p><p>如果我们PostStart阶段去检测容器是否ready，那么只有在ready后才去执行下一个容器。</p><p><img src="/img/blogImg/sidecar-lifecycle.png" alt="sidecar-lifecycle"></p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>配置如下，sidecar模拟需要依赖的容器，main为业务容器<br></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-start</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">sidecar</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">["/bin/sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"sleep 3600"</span><span class="string">]</span></span><br><span class="line"><span class="attr">    lifecycle:</span></span><br><span class="line"><span class="attr">      postStart:</span></span><br><span class="line"><span class="attr">        exec:</span></span><br><span class="line"><span class="attr">          command:</span> <span class="string">["/bin/sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"sleep 20"</span><span class="string">]</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">main</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">["/bin/sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"sleep 3600"</span><span class="string">]</span></span><br></pre></td></tr></tbody></table></figure><p></p><p>得到结果如下，可以看到sidecar启动21s后才开始启动main容器，满足需求<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Events:</span><br><span class="line">  Type    Reason     Age   From                                          Message</span><br><span class="line">  ----    ------     ----  ----                                          -------</span><br><span class="line">  Normal  Scheduled  54s   default-scheduler                             Successfully assigned default/<span class="built_in">test</span>-start to tj1-staging-k8s-slave95-202008.kscn</span><br><span class="line">  Normal  Pulling    53s   kubelet, tj1-staging-k8s-slave95-202008.kscn  Pulling image <span class="string">"busybox"</span></span><br><span class="line">  Normal  Pulled     44s   kubelet, tj1-staging-k8s-slave95-202008.kscn  Successfully pulled image <span class="string">"busybox"</span></span><br><span class="line">  Normal  Created    44s   kubelet, tj1-staging-k8s-slave95-202008.kscn  Created container sidecar</span><br><span class="line">  Normal  Started    44s   kubelet, tj1-staging-k8s-slave95-202008.kscn  Started container sidecar</span><br><span class="line">  Normal  Pulling    23s   kubelet, tj1-staging-k8s-slave95-202008.kscn  Pulling image <span class="string">"busybox"</span></span><br><span class="line">  Normal  Pulled     19s   kubelet, tj1-staging-k8s-slave95-202008.kscn  Successfully pulled image <span class="string">"busybox"</span></span><br><span class="line">  Normal  Created    18s   kubelet, tj1-staging-k8s-slave95-202008.kscn  Created container main</span><br><span class="line">  Normal  Started    18s   kubelet, tj1-staging-k8s-slave95-202008.kscn  Started container main</span><br></pre></td></tr></tbody></table></figure><p></p><p>此方案可能存在的缺点：</p><ol><li>如果sidecar启动失败或者hook失败，其他容器会立即启动</li></ol><h2 id="退出顺序"><a href="#退出顺序" class="headerlink" title="退出顺序"></a>退出顺序</h2><p>容器启动顺序比较好解决，退出顺序则是按照相反的顺序，业务容器先退出，之后sidecar再退出。</p><p>目前，在kubelet删除pod步骤如下;</p><ol><li>遍历容器，每个容器起一个goroutine删除</li><li>删除时，先执行pre stop hook，得到gracePeriod=DeletionGracePeriodSeconds-period(stophook)</li><li>再调用cri删除接口m.runtimeService.StopContainer(containerID.ID, gracePeriod)</li></ol><p>如果在sidecar的pre stop hook检测业务容器状态，那么可以延迟退出。</p><h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><p>业务容器main退出时，创建文件；sidecar通过post-stop检测到文件后，执行退出<br></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-stop</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">sidecar</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> </span><br><span class="line"><span class="bullet">    -</span> <span class="string">"/bin/sh"</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"-c"</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">|</span></span><br><span class="line"><span class="string">      trap "touch /lifecycle/sidecar-terminated" 15</span></span><br><span class="line"><span class="string">      until [ -f "/lifecycle/sidecar-terminated" ];do</span></span><br><span class="line"><span class="string">        date</span></span><br><span class="line"><span class="string">        sleep 1</span></span><br><span class="line"><span class="string">      done</span></span><br><span class="line"><span class="string">      sleep 5</span></span><br><span class="line"><span class="string">      cat /lifecycle/main-terminated</span></span><br><span class="line"><span class="string">      t=$(date)</span></span><br><span class="line"><span class="string">      echo "sidecar exit at $t"</span></span><br><span class="line"><span class="string"></span><span class="attr">    lifecycle:</span></span><br><span class="line"><span class="attr">      preStop:</span></span><br><span class="line"><span class="attr">        exec:</span></span><br><span class="line"><span class="attr">          command:</span></span><br><span class="line"><span class="bullet">          -</span> <span class="string">"/bin/sh"</span></span><br><span class="line"><span class="bullet">          -</span> <span class="string">"-c"</span></span><br><span class="line"><span class="bullet">          -</span> <span class="string">|</span></span><br><span class="line"><span class="string">            until [ -f "/lifecycle/main-terminated" ];do</span></span><br><span class="line"><span class="string">              sleep 1</span></span><br><span class="line"><span class="string">            done</span></span><br><span class="line"><span class="string">            t=$(date)</span></span><br><span class="line"><span class="string">            echo "main exit at $t" &gt; /lifecycle/main-terminated</span></span><br><span class="line"><span class="string"></span><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">lifecycle</span></span><br><span class="line"><span class="attr">      mountPath:</span> <span class="string">/lifecycle</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">main</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> </span><br><span class="line"><span class="bullet">    -</span> <span class="string">"/bin/sh"</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"-c"</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">|</span></span><br><span class="line"><span class="string">      trap "touch /lifecycle/main-terminated" 15</span></span><br><span class="line"><span class="string">      until [ -f "/lifecycle/main-terminated" ];do</span></span><br><span class="line"><span class="string">        date</span></span><br><span class="line"><span class="string">        sleep 1</span></span><br><span class="line"><span class="string">      done</span></span><br><span class="line"><span class="string"></span><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">lifecycle</span></span><br><span class="line"><span class="attr">      mountPath:</span> <span class="string">/lifecycle</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">lifecycle</span></span><br><span class="line"><span class="attr">    emptyDir:</span> <span class="string">{}</span></span><br></pre></td></tr></tbody></table></figure><p></p><p>在日志中看到，main容器先结束，sidecar检测到main-terminated文件后，执行完post-stop-hook，sidecar主进程开始退出<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl  logs -f <span class="built_in">test</span>-stop main</span><br><span class="line">...</span><br><span class="line">Tue Sep  8 03:14:20 UTC 2020</span><br><span class="line">Tue Sep  8 03:14:21 UTC 2020</span><br><span class="line">Tue Sep  8 03:14:22 UTC 2020</span><br><span class="line"></span><br><span class="line">$ kubectl  logs -f <span class="built_in">test</span>-stop sidecar</span><br><span class="line">Tue Sep  8 03:14:22 UTC 2020</span><br><span class="line">Tue Sep  8 03:14:23 UTC 2020</span><br><span class="line"><span class="comment"># post stop hook 检测到main容器退出，记录日志</span></span><br><span class="line">main <span class="built_in">exit</span> at Tue Sep  8 03:14:23 UTC 2020</span><br><span class="line"><span class="comment"># sidecar主进程退出</span></span><br><span class="line">sidecar <span class="built_in">exit</span> at Tue Sep  8 03:14:29 UTC 2020</span><br></pre></td></tr></tbody></table></figure><p></p><p>通过测试，使用postStopHook可以达到sidecar延迟退出的目的，但这种方式也有一些缺点</p><ol><li>配置复杂，多个sidecar都需要配置postStop监听业务容器状态</li><li>业务容器需要有可观察性（提供特定形式的健康检测）</li><li>poststop执行异常，会等到最大优雅退出时间（默认30s）后才终止</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>目前对于sidecar生命周期的支持方案对比如下：</p><table><thead><tr><th>方案</th><th>启动顺序</th><th>退出顺序</th><th>job sidecar</th><th>是否需要用户修改代码</th><th>是否需要修改k8s代码</th><th>缺点</th><th>备注</th></tr></thead><tbody><tr><td>用户控制</td><td>支持</td><td>不支持</td><td>不支持</td><td>需要</td><td>不需要</td><td>需要用户更改启动脚本;退出支持难度大，需要同时修改业务容器与sidecar启动脚本；大部分情况不支持</td><td>启动时需要检测sidecar服务状态</td></tr><tr><td>Lifecycle Hooks</td><td>支持</td><td>支持</td><td>不支持</td><td>不需要</td><td>不需要</td><td>配置hook复杂度高;在hook执行异常情况下不能确保顺序</td><td></td></tr><tr><td>富容器</td><td>支持</td><td>部分支持</td><td>部分支持</td><td>不需要</td><td>需要（更改镜像或启动命令）</td><td>所有功能集成在一个容器中，对于外部sidecar如istio envoy等，不可控;</td><td></td></tr><tr><td>修改源码</td><td>支持</td><td>支持</td><td>支持</td><td>不需要</td><td>需要</td><td>需要满足各种情况，实现难度较大</td><td>社区有计划支持</td></tr></tbody></table><p>在k8s提供此类功能前，目前没有完善的方案。Lifecycle Hooks不需要更改用户启动代码以及k8s相关代码，相对于其他方式不失为一种解决思路。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在多个容器的Pod中，通常业务容器需要依赖sidecar。启动时sidecar需要先启动，退出时sidecar需要在业务容器退出后再退出。k8s目前对于sidecar的生命周期比较有争议，见&lt;a href=&quot;https://github.com/kubernetes/enhancements/issues/753&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;issue&lt;/a&gt;、&lt;a href=&quot;https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/0753-sidecarcontainers.md&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;sidecarcontainers&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="container" scheme="https://qingwave.github.io/tags/container/"/>
    
  </entry>
  
  <entry>
    <title>开启shareProcessNamespace后容器异常</title>
    <link href="https://qingwave.github.io/cotainer-init/"/>
    <id>https://qingwave.github.io/cotainer-init/</id>
    <published>2020-07-28T09:35:49.000Z</published>
    <updated>2020-08-03T15:16:27.546Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>目前k8s不支持容器启动顺序，部分业务通过开启<code>shareProcessNamespace</code>监控某些进程状态。当开启共享pid后，有用户反馈某个容器主进程退出，但是容器并没有重启，执行<code>exec</code>会卡住，现象参考<a href="3">issue</a></p><h2 id="复现"><a href="#复现" class="headerlink" title="复现"></a>复现</h2><ol><li><p>创建deployment</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      shareProcessNamespace:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - image:</span> <span class="attr">nginx:alpine</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">nginx</span></span><br></pre></td></tr></tbody></table></figure></li><li><p>查看进程信息<br>由于开启了<code>shareProcessNamespace</code>, <code>pause</code>变为<code>pid 1</code>, <code>nginx daemon</code>pid为<code>6</code>, ppid为<code>containerd-shim</code></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看容器内进程</span></span><br><span class="line">/ <span class="comment"># ps -efo "pid,ppid,comm,args"</span></span><br><span class="line">PID   PPID  COMMAND          COMMAND</span><br><span class="line">    1     0 pause            /pause</span><br><span class="line">    6     0 nginx            nginx: master process nginx -g daemon off;</span><br><span class="line">   11     6 nginx            nginx: worker process</span><br><span class="line">   12     6 nginx            nginx: worker process</span><br><span class="line">   13     6 nginx            nginx: worker process</span><br><span class="line">   14     6 nginx            nginx: worker process</span><br><span class="line">   15     0 sh               sh</span><br><span class="line">   47    15 ps               ps -efo pid,ppid,comm,args</span><br></pre></td></tr></tbody></table></figure></li><li><p>删除主进程<br>子进程被<code>pid 1</code>回收, 有时也会被<code>containerd-shim</code>回收</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># kill -9 6</span></span><br><span class="line">/ <span class="comment"># </span></span><br><span class="line">/ <span class="comment"># ps -efo "pid,ppid,comm,args"</span></span><br><span class="line">PID   PPID  COMMAND          COMMAND</span><br><span class="line">    1     0 pause            /pause</span><br><span class="line">   11     1 nginx            nginx: worker process</span><br><span class="line">   12     1 nginx            nginx: worker process</span><br><span class="line">   13     1 nginx            nginx: worker process</span><br><span class="line">   14     1 nginx            nginx: worker process</span><br><span class="line">   15     0 sh               sh</span><br><span class="line">   48    15 ps               ps -efo pid,ppid,comm,args</span><br></pre></td></tr></tbody></table></figure></li><li><p>docker hang<br>此时对此容器执行docker命令(<code>inspect, logs, exec</code>)将卡住， 同样通过<code>kubectl</code>执行会超时。</p></li></ol><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>在未开启<code>shareProcessNamespace</code>的容器中，主进程退出<code>pid 1</code>, 此pid namespace销毁，系统会<code>kill</code>其下的所有进程。开启后，<code>pid 1</code>为<code>pause</code>进程，容器主进程退出，由于共享pid namespace，其他进程没有退出变成孤儿进程。此时调用docker相关接口去操作容器，docker首先去找主进程，但主进程已经不存在了，导致异常(待确认)。</p><p>清理掉这些孤儿进程容器便会正常退出，可以<code>kill</code>掉这些进程或者<code>kill</code>pause进程，即可恢复。</p><h2 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h2><p>有没有优雅的方式解决此种问题，如果主进程退出子进程也一起退出便符合预期，这就需要进程管理工具来实现，在宿主机中有<code>systemd</code>、<code>god</code>，容器中也有类似的工具即<code>init进程</code>(传递信息，回收子进程)，常见的有</p><ol><li><code>docker init</code>, docker自带的init进程(即<code>tini</code>)</li><li><a href="https://github.com/krallin/tini" target="_blank" rel="noopener"><code>tini</code></a>, 可回收孤儿进程/僵尸进程，<code>kill</code>进程组等</li><li><a href="https://github.com/Yelp/dumb-init" target="_blank" rel="noopener"><code>dumb-init</code></a>, 可管理进程，重写信号等</li></ol><p>经过测试，<code>tini</code>进程只能回收前台程序，对于后台程序则无能为力(例如<code>nohup</code>, <code>&amp;</code>启动的程序)，<code>dumb-init</code>在主进程退出时，会传递信号给子进程，符合预期。</p><p>开启<code>dumb-init</code>进程的<code>dockerfile</code>如下，<code>tini</code>也类似<br></p><figure class="highlight dockerfile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> nginx:alpine</span><br><span class="line"></span><br><span class="line"><span class="comment"># tini</span></span><br><span class="line"><span class="comment"># RUN apk add --no-cache tini</span></span><br><span class="line"><span class="comment"># ENTRYPOINT ["/sbin/tini", "-s", "-g", "--"]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dumb-init</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> wget -O /usr/bin/dumb-init https://github.com/Yelp/dumb-init/releases/download/v1.2.2/dumb-init_1.2.2_amd64</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> chmod +x /usr/bin/dumb-init</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">"/usr/bin/dumb-init"</span>, <span class="string">"-v"</span>, <span class="string">"--"</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"nginx"</span>, <span class="string">"-g"</span>, <span class="string">"daemon off;"</span>]</span></span><br></pre></td></tr></tbody></table></figure><p></p><p>init方式对于此问题是一种临时的解决方案，需要docker从根本上解决此种情况。容器推荐单进程运行，但某些情况必须要运行多进程，如果不想处理处理传递回收进程等，可以通过<code>init</code>进程，无需更改代码即可实现。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] <a href="https://github.com/Yelp/dumb-init" target="_blank" rel="noopener">https://github.com/Yelp/dumb-init</a><br>[2] <a href="https://github.com/krallin/tini" target="_blank" rel="noopener">https://github.com/krallin/tini</a><br>[3] <a href="https://github.com/kubernetes/kubernetes/issues/92214" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/issues/92214</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;目前k8s不支持容器启动顺序，部分业务通过开启&lt;code&gt;shareProcessNamespace&lt;/code&gt;监控某些进程状态。当开启共享pid后，有用户反馈某个容器主进程退出，但是容器并没有重启，执行&lt;code&gt;exec&lt;/code&gt;会卡住，现象参考&lt;a href=&quot;3&quot;&gt;issue&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="docker" scheme="https://qingwave.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Prometheus最佳实践-聚合函数</title>
    <link href="https://qingwave.github.io/prometheus-best-practice-operation/"/>
    <id>https://qingwave.github.io/prometheus-best-practice-operation/</id>
    <published>2020-07-16T07:28:39.000Z</published>
    <updated>2020-08-03T15:21:47.826Z</updated>
    
    <content type="html"><![CDATA[<h2 id="rate"><a href="#rate" class="headerlink" title="rate"></a>rate</h2><p>prometheus中<code>rate</code>只能用于<code>counter</code>类型，对于需要聚合的数据需要先<code>rate</code>再<code>sum</code>，而不是<code>rate(sum)</code></p><h2 id="数据准确性"><a href="#数据准确性" class="headerlink" title="数据准确性"></a>数据准确性</h2><p><code>rate/increase/delta</code>等操作对于原始值进行了外推（类似线性插件），得到的不是准确值</p><p>如<code>rate(http_requests_total[2m])</code>指两分钟内每秒平均请求量，通过<code>2m</code>内首尾两个数据外推得到差值，比120s得到；<br>同理<code>increase(http_requests_total[2m])</code>指的不是首尾两个值的增长量，而是外推后计算出<code>2m</code>内的增长量。</p><h2 id="absent"><a href="#absent" class="headerlink" title="absent"></a>absent</h2><p>通常报警中，我们需要对某个对象是不是有数据进行监控（即<code>nodata</code>监控），<code>absent</code>用来验证指标是不是有数据很有用</p><h2 id="predict-linear"><a href="#predict-linear" class="headerlink" title="predict_linear"></a>predict_linear</h2><p>线性回归预测，适合线性数据的预测，如预测etcd的未来4小时文件描述符使用量<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_linear(cluster:etcd:fd_utilization[1h], 3600 * 4)</span><br></pre></td></tr></tbody></table></figure><p></p><h2 id="quantile-over-time"><a href="#quantile-over-time" class="headerlink" title="quantile_over_time"></a>quantile_over_time</h2><p>一段时间内统计分位数<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">quantile_over_time(0.9, http_requests_total[1d]) # 一天内请求量的90分位</span><br></pre></td></tr></tbody></table></figure><p></p><h2 id="bool"><a href="#bool" class="headerlink" title="bool"></a>bool</h2><p>某些情况的需要比较两个标量（通常用来报警），可以使用bool<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http_requests_total &gt; bool 100</span><br></pre></td></tr></tbody></table></figure><p></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;prometheus中&lt;code&gt;rate&lt;/code&gt;只能用于&lt;code&gt;counter&lt;/code&gt;类型，对于需要聚合的数据需要先&lt;code&gt;rate&lt;/code&gt;再&lt;code&gt;sum&lt;/code&gt;，而不是&lt;code&gt;rate(sum)&lt;/code&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="prometheus" scheme="https://qingwave.github.io/tags/prometheus/"/>
    
      <category term="monitor" scheme="https://qingwave.github.io/tags/monitor/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes相关开源项目</title>
    <link href="https://qingwave.github.io/kubernetes-opensource-project/"/>
    <id>https://qingwave.github.io/kubernetes-opensource-project/</id>
    <published>2020-07-14T03:12:20.000Z</published>
    <updated>2020-07-14T06:26:46.358Z</updated>
    
    <content type="html"><![CDATA[<p>总结下项目中可参考k8s相关开源项目，不断更新中…</p><h2 id="cncf"><a href="#cncf" class="headerlink" title="cncf"></a>cncf</h2><ul><li><a href="https://www.cncf.io/projects/" target="_blank" rel="noopener">project</a></li><li><a href="https://www.cncf.io/sandbox-projects/" target="_blank" rel="noopener">sandbox</a></li></ul><h2 id="阿里"><a href="#阿里" class="headerlink" title="阿里"></a>阿里</h2><ul><li><a href="https://github.com/openkruise/kruise" target="_blank" rel="noopener">kruise</a>: 各种自定义app，包括增强deployment/statefulset等</li><li><a href="https://github.com/AliyunContainerService/kubernetes-cronhpa-controller" target="_blank" rel="noopener">kubernetes-cronhpa-controller</a>: 定时扩缩</li><li><a href="https://github.com/AliyunContainerService/kube-eventer" target="_blank" rel="noopener">kube-eventer</a>: event收集</li><li><a href="https://github.com/AliyunContainerService/gpushare-scheduler-extender" target="_blank" rel="noopener">gpushare-scheduler-extender</a>: 共享GPU</li><li><a href="https://github.com/AliyunContainerService/log-pilot" target="_blank" rel="noopener">log-pilot</a>: docker日志收集工具</li></ul><h2 id="腾讯"><a href="#腾讯" class="headerlink" title="腾讯"></a>腾讯</h2><ul><li><a href="https://github.com/tkestack/tapp" target="_blank" rel="noopener">tapp</a>: 增强版deployment/statefulset</li><li><a href="https://github.com/tkestack/cron-hpa" target="_blank" rel="noopener">cron-hpa</a>: 定时扩缩</li><li><a href="https://github.com/tkestack/lb-controlling-framework" target="_blank" rel="noopener">lb-controlling-framework</a>: lb扩展，可自定义接口</li><li><a href="https://github.com/Tencent/tke-kms-plugin" target="_blank" rel="noopener">tke-kms-plugin</a>: 实现kms,可参考</li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li><a href="https://github.com/stakater" target="_blank" rel="noopener">stakater</a>: 提供多种controller, 白名单、reloader等工具</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结下项目中可参考k8s相关开源项目，不断更新中…&lt;/p&gt;
    
    </summary>
    
      <category term="k8s" scheme="https://qingwave.github.io/categories/k8s/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="crd" scheme="https://qingwave.github.io/tags/crd/"/>
    
  </entry>
  
  <entry>
    <title>k8s如何优雅升级应用</title>
    <link href="https://qingwave.github.io/k8s-graceful-update-app/"/>
    <id>https://qingwave.github.io/k8s-graceful-update-app/</id>
    <published>2020-06-19T10:28:50.000Z</published>
    <updated>2020-07-20T05:30:15.365Z</updated>
    
    <content type="html"><![CDATA[<p>在k8s中通常用户通过<code>ingress</code>接入流量，转发到后端实例(<code>ingress → pod</code>)，在后端应用更新过程中，<code>ingress</code>是否能做到优雅升级，本文将通过分析升级流程与实验验证，说明在k8s中如何实现优化升级。</p><h2 id="Ingress原理"><a href="#Ingress原理" class="headerlink" title="Ingress原理"></a>Ingress原理</h2><p>用户创建ingress资源后，<code>ingress-nginx</code>通过<code>service</code>获取到对应的<code>endpoint</code>，监听到<code>endpoint</code>变化后将动态更新<code>upstream</code>。</p><p><code>endpoint</code>每次变化后会通过<code>selector</code>匹配的<code>pod</code>列表中<code>ready pod</code>（不包括待删除的<code>pod</code>, 及<code>DeletionTimestamp</code>不为空）<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pod ready = 所有container ready(启动成功,&nbsp;健康检查通过) + 所有rediness gateway执行成功</span><br></pre></td></tr></tbody></table></figure><p></p><p>那么<code>endpoint</code>在什么状况下会发生变化：</p><ul><li>service变化（一般不会）</li><li>扩缩容</li><li>升级</li><li>删除pod</li></ul><p>不管是什么操作，可归结于启动、删除、退出</p><ul><li><strong>启动</strong>，只要确保<code>pod ready</code>时能服务能正常接受流量，不会影响影响服务</li><li><strong>退出</strong>, 如果是应用异常退出，不能处理已接受的流量，此种状况是应用本身行为，不在讨论范围</li><li><strong>删除</strong>, 由于k8s所有组件都采用监听机制，无法保证<code>pod</code>删除时<code>ingress-nginx</code>的后端已经更新</li></ul><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 大约在2s内</span></span><br><span class="line">ingress-nginx 生效时间 = endpoint 生效时间 + upstream更新时间</span><br></pre></td></tr></tbody></table></figure><p>如果要保证pod删除时不丢流量，需要做到</p><ul><li>已接受的请求需要处理完，可监听TERM信号，处理完再退出， 可参考<a href="https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods</a></li><li>删除时不接受新的请求，这部分无法保证，只能保证#1</li></ul><h2 id="ingress-nginx-重试机制"><a href="#ingress-nginx-重试机制" class="headerlink" title="ingress-nginx 重试机制"></a>ingress-nginx 重试机制</h2><p>ingress-nginx默认开启了proxy_next_upstream，配置如下<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># In case of errors try the next upstream server before returning an error</span></span><br><span class="line">proxy_next_upstream error timeout;</span><br><span class="line">proxy_next_upstream_timeout 0;</span><br><span class="line">proxy_next_upstream_tries 3;</span><br></pre></td></tr></tbody></table></figure><p></p><p>如果一次请求中，<code>upstream server</code> 出错或超时将通过rr算法重试下一个server，最多尝试三次。如果后端大于三个实例，一个实例异常不会影响服务。</p><h2 id="升级策略"><a href="#升级策略" class="headerlink" title="升级策略"></a>升级策略</h2><p>对于<code>Deployment</code>有两种升级策略， <code>Recreate</code>与<code>RollingUpdate</code></p><ul><li><strong>Recreate</strong>, 先将旧版缩到0再将新版扩到期望值，不建议使用</li><li><strong>RollingUpdate</strong>，默认策略，滚动更新</li></ul><p>在滚动升级时主要依据<code>maxSurge</code>与<code>maxUnavailable</code>对新旧版本进行扩缩</p><ul><li><strong>maxSurge</strong>， 升级中最多有多少pod超过期望值</li><li><strong>maxUnavailable</strong>， 此值用来计算升级中最小可用的实例数，最大不可用的实例数表示不准确</li></ul><p>举个例子，比如10个副本的Deployment， 采用默认值<code>maxSurge</code>与<code>maxUnavaiable</code>都为25%<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// 向上取整为 3 </span><br><span class="line">maxSurge = replicas * deployment.spec.strategy.rollingUpdate.maxSurge(25%)= 2.5</span><br><span class="line"> </span><br><span class="line">// 向下取整为 2 </span><br><span class="line">maxUnavailable = replicas * deployment.spec.strategy.rollingUpdate.maxUnavailable(25%)= 2.5</span><br><span class="line"> </span><br><span class="line">maxAvailable = replicas(10) + MaxSurge（3） = 13</span><br><span class="line"> </span><br><span class="line">minAvailable := *(deployment.Spec.Replicas)（10） - maxUnavailable（2）= 8</span><br></pre></td></tr></tbody></table></figure><p></p><p>在升级过程中，首先创建 newRS，然后为其设定 replicas，此时计算出 replicas 结果为 3。等到下一个 syncLoop 时，所有 rs 的 replicas 已经达到最大值 10 + 3 = 13，此时需要 scale down oldRSs 了，scale down 的数量是通过以下公式得到的：<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// 13 = 10 + 3 </span><br><span class="line">allPodsCount := newRS(10) + oldRS(3)</span><br><span class="line"> </span><br><span class="line">// ??? </span><br><span class="line">newRSUnavailablePodCount := *(newRS.Spec.Replicas) - newRS.Status.AvailableReplicas</span><br><span class="line"> </span><br><span class="line">// 13 - 8 - ??? </span><br><span class="line">maxScaledDown := allPodsCount - minAvailable - newRSUnavailablePodCount</span><br><span class="line">newRSUnavailablePodCount 此时不确定，但是值在 [0,3] 中，此时假设 newRS 的三个 pod 还处于 containerCreating 状态，则newRSUnavailablePodCount 为 3，根据以上公式计算所知 maxScaledDown 为 2。如果有个新版本pod已经ready，则maxScaledDown 为 4。</span><br></pre></td></tr></tbody></table></figure><p></p><p>特殊情况，当只有一个副本，<code>maxSurge</code>与<code>maxUnavaiable</code>都为1时，按照以上公式，先扩容1个新版pod，再缩一个旧版的，如果旧版已经删除了而新版还没有起来可能会丟流量，可以将<code>maxUnavaiable</code>设置为0可避免以上情况。</p><h2 id="实验验证"><a href="#实验验证" class="headerlink" title="实验验证"></a>实验验证</h2><p>滚动升级终于也是通过扩缩新旧版本来实现的，我们只需要分析扩缩容过程中会不会丢流量即可。</p><h3 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h3><p>image: nginx<br>tool:  <code>wrk -c 2 -d 120 -H "Connection:Close" http://my.nginx.svc</code></p><h3 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h3><p>1) 从1扩到10个</p><p>不丢流量，nginx启动很快不需要额外的初始化工作，正常情况需要配置健康检查</p><h3 id="缩容"><a href="#缩容" class="headerlink" title="缩容"></a>缩容</h3><p><strong>1) 10 → 1</strong></p><p>缩容时会有502错误<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Running 2m <span class="built_in">test</span> @ http://my.nginx.svc</span><br><span class="line">  2 threads and 2 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency    11.73ms   27.02ms 229.17ms   95.14%</span><br><span class="line">    Req/Sec   162.91     45.77   232.00     74.13%</span><br><span class="line">  8969 requests <span class="keyword">in</span> 28.24s, 2.40MB <span class="built_in">read</span></span><br><span class="line">  Non-2xx or 3xx responses: 366</span><br><span class="line">Requests/sec:    317.62</span><br><span class="line">Transfer/sec:     86.93KB</span><br></pre></td></tr></tbody></table></figure><p></p><p>查看ingress日志<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2020/06/19 08:12:28 [error] 9533<span class="comment">#9533: *197916788 connect() failed (111: Connection refused) while connecting to upstream, client: 10.232.41.102, server: my.nginx.svc, request: "GET / HTTP/1.1", upstream: "http://10.126.110.3:80/", host: "my.nginx.svc"</span></span><br><span class="line">2020/06/19 08:12:33 [error] 8935<span class="comment">#8935: *197916707 upstream timed out (110: Operation timed out) while connecting to upstream, client: 10.232.41.102, server: my.nginx.svc, request: "GET / HTTP/1.1", upstream: "http://10.126.69.136:80/", host: "my.nginx.svc"</span></span><br><span class="line">2020/06/19 08:12:33 [error] 9533<span class="comment">#9533: *197916788 upstream timed out (110: Operation timed out) while connecting to upstream, client: 10.232.41.102, server: my.nginx.svc, request: "GET / HTTP/1.1", upstream: "http://10.126.69.136:80/", host: "my.nginx.svc</span></span><br><span class="line">10.232.41.102 - - [18/Jun/2020:09:14:35 +0000] <span class="string">"GET / HTTP/1.1"</span> 502 157 <span class="string">"-"</span> <span class="string">"-"</span> 38 0.001 [default-my-nginx-80] [] 10.46.12.80:80, 10.46.12.79:80, 10.46.12.80:80 0, 0, 0 0.000, 0.000, 0.000 502, 502, 502 5cfc063dbe7daf1db953a0e16891f100</span><br></pre></td></tr></tbody></table></figure><p></p><p><strong>2) 4→1</strong></p><p>会丟流量</p><p><strong>3）3→1</strong></p><p>测试多次，偶现过丢流量的情况，这与ingress重试算法有关系</p><p><strong>4） 10→1</strong>, 忽略term信号, 不丢流量<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Running 2m <span class="built_in">test</span> @ http://my.nginx.svc</span><br><span class="line">  2 threads and 2 connections</span><br><span class="line">Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency    12.12ms   16.66ms 214.89ms   88.39%</span><br><span class="line">    Req/Sec   129.75     74.05   250.00     62.35%</span><br><span class="line">  8811 requests <span class="keyword">in</span> 34.24s, 2.35MB <span class="built_in">read</span></span><br><span class="line">Requests/sec:    257.35</span><br><span class="line">Transfer/sec:     70.41KB</span><br></pre></td></tr></tbody></table></figure><p></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过分析及实验，在pod启动时可配置健康检查避免请求异常；同一时刻大于2个pod终止可能会丢失流量，通过监听退出信号可避免此种情况。综上，应用的优化升级需要做到以下几点：</p><ul><li>健康检测，<code>pod ready</code>时能够正常接受流量</li><li>优雅停止，保证处理完请求再退出，在这段时间内实例ip可从ingress后端摘除</li><li>滚动升级配置，若只有1个实例需设置maxsurge=0，更建议副本数设置多个</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在k8s中通常用户通过&lt;code&gt;ingress&lt;/code&gt;接入流量，转发到后端实例(&lt;code&gt;ingress → pod&lt;/code&gt;)，在后端应用更新过程中，&lt;code&gt;ingress&lt;/code&gt;是否能做到优雅升级，本文将通过分析升级流程与实验验证，说明在k8s中如何实现优化升级。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="ingress" scheme="https://qingwave.github.io/tags/ingress/"/>
    
      <category term="nginx" scheme="https://qingwave.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>Ingress获取真实IP</title>
    <link href="https://qingwave.github.io/ingress-real-ip/"/>
    <id>https://qingwave.github.io/ingress-real-ip/</id>
    <published>2020-06-05T06:40:08.000Z</published>
    <updated>2020-07-20T05:39:48.878Z</updated>
    
    <content type="html"><![CDATA[<p>一般情况下，经过ingress的请求会携带header<code>X-Real-IP</code>，用户可根据header解析出真实访问IP。</p><p>特殊情况，用户请求可能经过多个nginx才达到ingress, 通过上述方法得到的并不是用户的真实IP。</p><blockquote><p>request -&gt; nginx -&gt; … -&gt; ingress-nginx -&gt; backend</p></blockquote><h2 id="方案1-use-forwarded-headers"><a href="#方案1-use-forwarded-headers" class="headerlink" title="方案1 use-forwarded-headers"></a>方案1 use-forwarded-headers</h2><p>nginx-ingress官方的建议是开启<a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#forwarded-for-header" target="_blank" rel="noopener">use-forwarded-headers</a>, 配置如下：</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-configuration</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line"><span class="attr">  compute-full-forwarded-for:</span> <span class="string">'true'</span></span><br><span class="line"><span class="attr">  use-forwarded-headers:</span> <span class="string">'true'</span></span><br></pre></td></tr></tbody></table></figure><h2 id="方案2-real-ip-header"><a href="#方案2-real-ip-header" class="headerlink" title="方案2 real_ip_header"></a>方案2 real_ip_header</h2><p>这种方式确实可以起作用，但是有用户反馈开启后访问ingres后端服务一直报<code>308</code>，检查了ingress的代码开启<code>use-forwarded-headers</code>后会同时开启<code>ssl-redirect</code>导致308。</p><p>那么我们只需要开启nginx配置中的相关real-ip的配置，如下在<code>http-snippet</code>添加<code>real_ip_header X-Forwarded-For;</code></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-configuration</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line"><span class="attr">  http-snippet:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    real_ip_header X-Forwarded-For;</span></span><br></pre></td></tr></tbody></table></figure><h2 id="golang中获取真实ip"><a href="#golang中获取真实ip" class="headerlink" title="golang中获取真实ip"></a>golang中获取真实ip</h2><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">RemoteIP</span><span class="params">(r *http.Request)</span> <span class="title">string</span></span> {</span><br><span class="line">  <span class="comment">// ingress 行为，将真实ip放到header `X-Original-Forwarded-For`, 普通nginx可去掉此条</span></span><br><span class="line">ip := strings.TrimSpace(strings.Split(r.Header.Get(<span class="string">"X-Original-Forwarded-For"</span>), <span class="string">","</span>)[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">if</span> ip != <span class="string">""</span> {</span><br><span class="line"><span class="keyword">return</span> ip</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">ip = strings.TrimSpace(strings.Split(r.Header.Get(<span class="string">"X-Forwarded-For"</span>), <span class="string">","</span>)[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">if</span> ip != <span class="string">""</span> {</span><br><span class="line"><span class="keyword">return</span> ip</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">ip = strings.TrimSpace(r.Header.Get(<span class="string">"X-Real-Ip"</span>))</span><br><span class="line"><span class="keyword">if</span> ip != <span class="string">""</span> {</span><br><span class="line"><span class="keyword">return</span> ip</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> ip, _, err := net.SplitHostPort(strings.TrimSpace(r.RemoteAddr)); err == <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> ip</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="string">""</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>nginx-ingress configmap中的配置会是全局生效的，上线前需要严格测试。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一般情况下，经过ingress的请求会携带header&lt;code&gt;X-Real-IP&lt;/code&gt;，用户可根据header解析出真实访问IP。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="ingress" scheme="https://qingwave.github.io/tags/ingress/"/>
    
      <category term="nginx" scheme="https://qingwave.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>Ingress Header Too Large</title>
    <link href="https://qingwave.github.io/ingress-header-too-large/"/>
    <id>https://qingwave.github.io/ingress-header-too-large/</id>
    <published>2020-06-05T06:17:08.000Z</published>
    <updated>2020-06-05T06:36:20.704Z</updated>
    
    <content type="html"><![CDATA[<p>线上遇到多次由ingress header过大引起的请求失败, 可能返回502/400，解决方案如下。</p><h2 id="502-–-too-big-header"><a href="#502-–-too-big-header" class="headerlink" title="502 – too big header"></a>502 – too big header</h2><p>502错误一般是后端服务不可用，但这里是nginx-ingress返回的，在nginx-ingress可看到如下日志：<br><code>upstream sent too big header while reading response header from upstream, client...</code></p><p>需要在ingress配置如下参数<br></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/proxy-buffer-size:</span> <span class="number">128</span><span class="string">k</span> <span class="comment">#根据实际情况配置</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/proxy-buffering:</span> <span class="string">"on"</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/server-snippet:</span> <span class="string">|</span></span><br><span class="line"><span class="string">      large_client_header_buffers 16 128K;</span></span><br><span class="line"><span class="string">      client_header_buffer_size 128k;</span></span><br></pre></td></tr></tbody></table></figure><p></p><h2 id="431-400-–-too-big-header"><a href="#431-400-–-too-big-header" class="headerlink" title="431/400 – too big header"></a>431/400 – too big header</h2><p>http header过大也有可能返回400/431, 可按照上述调整，如果还是有问题需要检查后端服务的header设置，比如golang http header默认是<code>1M</code>;<br>springboot应用需要在<code>application.properties</code>加上<code>server.max-http-header-size=32KB</code>等</p><h2 id="413-–-too-large-body"><a href="#413-–-too-large-body" class="headerlink" title="413 – too large body"></a>413 – too large body</h2><p>如果返回413，则超过了body size的限制（默认<code>1M</code>）, 可在ingress annotation添加<br><code>nginx.ingress.kubernetes.io/proxy-body-size: 8m</code></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;线上遇到多次由ingress header过大引起的请求失败, 可能返回502/400，解决方案如下。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="ingress" scheme="https://qingwave.github.io/tags/ingress/"/>
    
      <category term="nginx" scheme="https://qingwave.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>ingress nginx benchmark</title>
    <link href="https://qingwave.github.io/ingress-benchmark/"/>
    <id>https://qingwave.github.io/ingress-benchmark/</id>
    <published>2020-05-21T11:16:04.000Z</published>
    <updated>2020-05-22T12:53:21.669Z</updated>
    
    <content type="html"><![CDATA[<p>Ingress是目前Kubernetes集群流量接入的重要入口，了解其性能指标有助于用户选用合适的网络方案。</p><h2 id="测试方案"><a href="#测试方案" class="headerlink" title="测试方案"></a>测试方案</h2><p>通过wrk压测后端nginx服务，对比ingress-nginx, 原生nginx，以及直连后端性能的差异，如下图:<br><img src="/img/blogImg/ingress-benchmark1.png" alt=""></p><ul><li>方案1，经过ingress</li><li>方案2，经过nginx</li><li>方案3，直连ip</li></ul><h3 id="硬件环境"><a href="#硬件环境" class="headerlink" title="硬件环境"></a>硬件环境</h3><ul><li>CPU： 2x  Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz, 32 cores</li><li>Network： 10-Gigabit</li><li>Memory： 128 GB</li></ul><h3 id="测试工具"><a href="#测试工具" class="headerlink" title="测试工具"></a>测试工具</h3><ul><li>wrk, 4.1.0, 在k8s master测试，减少网络影响</li><li>ingress-nginx, 0.30.0, <a href="https://github.com/kubernetes/ingress-nginx" target="_blank" rel="noopener">https://github.com/kubernetes/ingress-nginx</a></li><li>nginx, 1.13.5 </li><li>k8s, v1.14.9 </li><li>centos, 7.3.1611(Linux 4.9.2)</li></ul><h3 id="测试方法"><a href="#测试方法" class="headerlink" title="测试方法"></a>测试方法</h3><p>ingress-nginx主要工作是转发请求到后端pod, 我们着重对其RPS（每秒请求量）进行测试</p><p>通过以下命令<br></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">wrk</span> <span class="bullet">-t4</span> <span class="bullet">-c1000</span> <span class="bullet">-d120s</span> <span class="bullet">--latency</span> <span class="attr">http://my.nginx.svc/1kb.bin</span></span><br></pre></td></tr></tbody></table></figure><p></p><h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><h3 id="不同cpu下的性能"><a href="#不同cpu下的性能" class="headerlink" title="不同cpu下的性能"></a>不同cpu下的性能</h3><p>对比不同ingress-nginx启动不同worker数量的性能差异，以下测试ingress-nginx开启了keepalive等特性</p><table><thead><tr><th>CPU</th><th>RPS</th></tr></thead><tbody><tr><td>1</td><td>5534</td></tr><tr><td>2</td><td>11203</td></tr><tr><td>4</td><td>22890</td></tr><tr><td>8</td><td>47025</td></tr><tr><td>16</td><td>93644</td></tr><tr><td>24</td><td>125990</td></tr><tr><td>32</td><td>153473</td></tr></tbody></table><p><img src="/img/blogImg/ingress-benchmark2.png" alt=""></p><p>如图所示，不同cpu下，ingress的rps与cpu成正比，cpu在16核之后增长趋势放缓。</p><h3 id="不同方案的性能对比"><a href="#不同方案的性能对比" class="headerlink" title="不同方案的性能对比"></a>不同方案的性能对比</h3><table><thead><tr><th>方案</th><th>RPS</th><th>备注</th></tr></thead><tbody><tr><td>ingress-nginx(原始)</td><td>69171</td><td></td></tr><tr><td>ingress-nginx(配置优化)</td><td>153473</td><td>调整worker，access-log, keepalive等</td></tr><tr><td>nginx</td><td>336769</td><td>开启keepalive, 关闭log</td></tr><tr><td>直连ip</td><td>340748</td><td>测试中的pod ip为真实ip</td></tr></tbody></table><p>通过实验可以看到，使用nginx代理和直连ip，rps相差不大；原始ingress-nginx rps很低，优化后rps提升一倍，但对比nginx还是有较大的性能差异。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>默认ingress-nginx性能较差，配置优化后也只有15w RPS，对比原生nginx（33W) 差距较大。经过分析主要瓶颈在于ingress-nginx的lua过滤脚本，具体原因需要进一步分析。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#upstream-keepalive-connections" target="_blank" rel="noopener">https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#upstream-keepalive-connections</a></li><li><a href="https://www.nginx.com/blog/testing-performance-nginx-ingress-controller-kubernetes/" target="_blank" rel="noopener">https://www.nginx.com/blog/testing-performance-nginx-ingress-controller-kubernetes/</a></li></ol><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><p>本测试所有配置见<a href="https://github.com/qingwave/ingress-nginx-benchmark" target="_blank" rel="noopener">qingwave/ingress-nginx-benchmark</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Ingress是目前Kubernetes集群流量接入的重要入口，了解其性能指标有助于用户选用合适的网络方案。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="ingress" scheme="https://qingwave.github.io/tags/ingress/"/>
    
      <category term="nginx" scheme="https://qingwave.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>可能是史上最全的Kubernetes证书解析</title>
    <link href="https://qingwave.github.io/k8s-tls/"/>
    <id>https://qingwave.github.io/k8s-tls/</id>
    <published>2020-04-25T00:53:03.000Z</published>
    <updated>2020-06-05T10:49:19.967Z</updated>
    
    <content type="html"><![CDATA[<p>为了避免广告法，题目还是加个可能吧。</p><p>想要安全就必须复杂起来，证书是少不了的。在Kubernetes中提供了非常丰富的证书类型，满足各种不同场景的需求，今天我们就来看一看Kubernetes中的证书。</p><h2 id="k8s证书分类"><a href="#k8s证书分类" class="headerlink" title="k8s证书分类"></a>k8s证书分类</h2><p>在说证书之前，先想想作为集群的入口apiserver需要提供那些服务，与那些组件通信，通信的两方可能需要配置证书。<br>与apiserver通信的组件大体可以分为以下几类：</p><ul><li>client(kubectl，restapi等)：普通用户与apiserver之间的通信，对各类资源进行操作</li><li>kubelet，kubeproxy：master与node之间的通信</li><li>etcd：k8s的存储库</li><li>webhook：这里指apiserver提供的admission-webhook，在数据持久化前调用webhook</li><li>aggregation layer：扩展apiserver, 需要将自定义的api注册到k8s中，相比CRD性能更新</li><li>pod: 在pod中调用apiserver(一般调用为10.254.0.1:433)</li></ul><p>居然有这么多种，除了在pod中通过serviceacount认证（当然pod需要认证apiserver的证书），其他几种都需要配置证书。</p><p>其他集群内组件与apiserver通信的，kubelet/etcd/kube-proxy对应的也可以配置证书。</p><h2 id="apiserver证书"><a href="#apiserver证书" class="headerlink" title="apiserver证书"></a>apiserver证书</h2><p>简单列举下apiserver证书相关的启动参数<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">--cert-dir string                           The directory where the TLS certs are located. If --tls-cert-file and --tls-private-key-file are provided, this flag will be ignored. (default "/var/run/kubernetes")</span><br><span class="line">--client-ca-file string                     If set, any request presenting a client certificate signed by one of the authorities in the client-ca-file is authenticated with an identity corresponding to the CommonName of the client certificate.</span><br><span class="line">--etcd-certfile string                      SSL certification file used to secure etcd communication.</span><br><span class="line">--etcd-keyfile string                       SSL key file used to secure etcd communication.</span><br><span class="line">--kubelet-certificate-authority string      Path to a cert file for the certificate authority.</span><br><span class="line">--kubelet-client-certificate string         Path to a client cert file for TLS.</span><br><span class="line">--kubelet-client-key string                 Path to a client key file for TLS.</span><br><span class="line">--proxy-client-cert-file string             Client certificate used to prove the identity of the aggregator or kube-apiserver when it must call out during a request. This includes proxying requests to a user api-server and calling out to webhook admission plugins. It is expected that this cert includes a signature from the CA in the --requestheader-client-ca-file flag. That CA is published in the 'extension-apiserver-authentication' configmap in the kube-system namespace. Components recieving calls from kube-aggregator should use that CA to perform their half of the mutual TLS verification.</span><br><span class="line">--proxy-client-key-file string              Private key for the client certificate used to prove the identity of the aggregator or kube-apiserver when it must call out during a request. This includes proxying requests to a user api-server and calling out to webhook admission plugins.</span><br><span class="line">--requestheader-allowed-names stringSlice   List of client certificate common names to allow to provide usernames in headers specified by --requestheader-username-headers. If empty, any client certificate validated by the authorities in --requestheader-client-ca-file is allowed.</span><br><span class="line">--requestheader-client-ca-file string       Root certificate bundle to use to verify client certificates on incoming requests before trusting usernames in headers specified by --requestheader-username-headers</span><br><span class="line">--service-account-key-file stringArray      File containing PEM-encoded x509 RSA or ECDSA private or public keys, used to verify ServiceAccount tokens. If unspecified, --tls-private-key-file is used. The specified file can contain multiple keys, and the flag can be specified multiple times with different files.</span><br><span class="line">--ssh-keyfile string                        If non-empty, use secure SSH proxy to the nodes, using this user keyfile</span><br><span class="line">--tls-ca-file string                        If set, this certificate authority will used for secure access from Admission Controllers. This must be a valid PEM-encoded CA bundle. Alternatively, the certificate authority can be appended to the certificate provided by --tls-cert-file.</span><br><span class="line">--tls-cert-file string                      File containing the default x509 Certificate for HTTPS. (CA cert, if any, concatenated after server cert). If HTTPS serving is enabled, and --tls-cert-file and --tls-private-key-file are not provided, a self-signed certificate and key are generated for the public address and saved to /var/run/kubernetes.</span><br><span class="line">--tls-private-key-file string               File containing the default x509 private key matching --tls-cert-file.</span><br><span class="line">--tls-sni-cert-key namedCertKey             A pair of x509 certificate and private key file paths, optionally suffixed with a list of domain patterns which are fully qualified domain names, possibly with prefixed wildcard segments. If no domain patterns are provided, the names of the certificate are extracted. Non-wildcard matches trump over wildcard matches, explicit domain patterns trump over extracted names. For multiple key/certificate pairs, use the --tls-sni-cert-key multiple times. Examples: "example.crt,example.key" or "foo.crt,foo.key:*.foo.com,foo.com". (default [])</span><br><span class="line">--oidc-ca-file string                       If set, the OpenID server's certificate will be verified by one of the authorities in the oidc-ca-file, otherwise the host's root CA set will be used.</span><br><span class="line">--tls-sni-cert-key namedCertKey             A pair of x509 certificate and private key file paths, optionally suffixed with a list of domain patterns which are fully qualified domain names, possibly with prefixed wildcard segments. If no domain patterns are provided, the names of the certificate are extracted. Non-wildcard matches trump over wildcard matches, explicit domain patterns trump over extracted names. For multiple key/certificate pairs, use the --tls-sni-cert-key multiple times. Examples: "example.crt,example.key" or "foo.crt,foo.key:*.foo.com,foo.com". (default [])</span><br></pre></td></tr></tbody></table></figure><p></p><p>不要害怕，咱们一个个看。</p><h3 id="tls证书"><a href="#tls证书" class="headerlink" title="tls证书"></a>tls证书</h3><p>首先，apiserver本身是一个http服务器，需要tls证书<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--tls-cert-file string</span><br><span class="line">    File containing the default x509 Certificate for HTTPS. (CA cert, if any, concatenated after server cert). If HTTPS serving is enabled, and --tls-cert-file and --tls-private-key-file are not provided, a self-signed certificate and key are generated for the public address and saved to the directory specified by --cert-dir.</span><br><span class="line"></span><br><span class="line">--tls-private-key-file string</span><br><span class="line">    File containing the default x509 private key matching --tls-cert-file.</span><br><span class="line">其他client验证apiserver时可以通过签署这两个证书的CA，我们称为`tls-ca`</span><br></pre></td></tr></tbody></table></figure><p></p><h3 id="client证书"><a href="#client证书" class="headerlink" title="client证书"></a>client证书</h3><p>apiserver提供了tls证书，同样也需要验证client的配置，但是client太多了(kubectl,各种restapi调用的), 这些client需要统一用一个CA签发，我们称为<code>client-ca</code>。<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--client-ca-file string</span><br><span class="line">    If set, any request presenting a client certificate signed by one of the authorities in the client-ca-file is authenticated with an identity corresponding to the CommonName of the client certificate.</span><br></pre></td></tr></tbody></table></figure><p></p><p>需要注意的是，在apiserver认证中，通过<code>CN</code>和<code>O</code>来识别用户，开启RBAC的用户要配置<code>CN</code>和<code>O</code>做一些授权：</p><ul><li>CN：Common Name，kube-apiserver 从证书中提取作为请求的用户名 (User Name)；浏览器使用该字段验证网站是否合法；</li><li>O：Organization，kube-apiserver 从证书中提取该字段作为请求用户所属的组 (Group)</li></ul><p>如kube-proxy的证书申请, User为<code>system:kube-proxy</code>, Group为<code>k8s</code><br></p><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">{</span><br><span class="line">  <span class="attr">"CN"</span>: <span class="string">"system:kube-proxy"</span>,</span><br><span class="line">  <span class="attr">"hosts"</span>: [],</span><br><span class="line">  <span class="attr">"key"</span>: {</span><br><span class="line">    <span class="attr">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">    <span class="attr">"size"</span>: <span class="number">2048</span></span><br><span class="line">  },</span><br><span class="line">  <span class="attr">"names"</span>: [</span><br><span class="line">    {</span><br><span class="line">      <span class="attr">"C"</span>: <span class="string">"CN"</span>,</span><br><span class="line">      <span class="attr">"ST"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">      <span class="attr">"L"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">      <span class="attr">"O"</span>: <span class="string">"k8s"</span>,</span><br><span class="line">      <span class="attr">"OU"</span>: <span class="string">"System"</span></span><br><span class="line">    }</span><br><span class="line">  ]</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><h3 id="requestheader证书"><a href="#requestheader证书" class="headerlink" title="requestheader证书"></a>requestheader证书</h3><p>apiserver可以使用HTTP请求头中的指定字段来进行认证，相关配置如下:<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">--requestheader-allowed-names stringSlice</span><br><span class="line">    List of client certificate common names to allow to provide usernames in headers specified by --requestheader-username-headers. If empty, any client certificate validated by the authorities in --requestheader-client-ca-file is allowed.</span><br><span class="line">--requestheader-client-ca-file string</span><br><span class="line">    Root certificate bundle to use to verify client certificates on incoming requests before trusting usernames in headers specified by --requestheader-username-headers. WARNING: generally do not depend on authorization being already done for incoming requests.</span><br><span class="line">--requestheader-extra-headers-prefix strings        </span><br><span class="line">    List of request header prefixes to inspect. X-Remote-Extra- is suggested.</span><br><span class="line">--requestheader-group-headers strings               </span><br><span class="line">    List of request headers to inspect for groups. X-Remote-Group is suggested.</span><br><span class="line">--requestheader-username-headers strings            </span><br><span class="line">    List of request headers to inspect for usernames. X-Remote-User is common.</span><br></pre></td></tr></tbody></table></figure><p></p><p>收到请求时，apiserver会首先认证<code>requsetheader-ca</code>，验证成功并且<code>CN</code>在<code>requestheader-allowed-names</code>（默认全部需求）中，然后通过Http header中的<code>X-Remote-User, X-Remote-Group</code>去得到用户；如果匹配不成功回去验证<code>client-ca</code>。</p><p>如上，<code>requestheader</code>证书与<code>client-ca</code>不能是同一个。</p><h3 id="proxy证书"><a href="#proxy证书" class="headerlink" title="proxy证书"></a>proxy证书</h3><p>k8s提供了丰富的扩展机制，CRD与[API Aggregation][<a href="https://kubernetes.io/zh/docs/tasks/access-kubernetes-api/configure-aggregation-layer/]。" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/tasks/access-kubernetes-api/configure-aggregation-layer/]。</a><br>对于API Aggregation(例如metrics-server提供了metrics.k8s.io api), apiserver接受到请求后经过一系列验证过滤，会将请求转发到扩展API，这里apisever作为代理服务器，需要配置配置证书。<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--proxy-client-cert-file string             </span><br><span class="line">    Client certificate used to prove the identity of the aggregator or kube-apiserver when it must call out during a request. This includes proxying requests to a user api-server and calling out to webhook admission plugins. It is expected that this cert includes a signature from the CA in the --requestheader-client-ca-file flag. That CA is published in the 'extension-apiserver-authentication' configmap in the kube-system namespace. Components recieving calls from kube-aggregator should use that CA to perform their half of the mutual TLS verification.</span><br><span class="line">--proxy-client-key-file string              </span><br><span class="line">    Private key for the client certificate used to prove the identity of the aggregator or kube-apiserver when it must call out during a request. This includes proxying requests to a user api-server and calling out to webhook admission plugins.</span><br></pre></td></tr></tbody></table></figure><p></p><p>需要注意的是对证书需要通过<code>requestheader-ca</code>签发，扩展api会通过requestheader证书去验证，具体流程后面会写一篇，下图为官方提供的流程<br><img src="https://d33wubrfki0l68.cloudfront.net/3c5428678a95c3715894011d8dd4812d2cf229b9/e745c/images/docs/aggregation-api-auth-flow.png" alt="aggregation-api"></p><h3 id="kubelet证书"><a href="#kubelet证书" class="headerlink" title="kubelet证书"></a>kubelet证书</h3><p>对于kubelet，apiserver单独提供了证书配置选项，同时kubelet组件也提供了反向设置的相关选项:<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># API Server</span><br><span class="line">--kubelet-certificate-authority string</span><br><span class="line">    Path to a cert file for the certificate authority.</span><br><span class="line">--kubelet-client-certificate string</span><br><span class="line">    Path to a client cert file for TLS.</span><br><span class="line">--kubelet-client-key string</span><br><span class="line">    Path to a client key file for TLS.</span><br><span class="line"></span><br><span class="line"># kubelet</span><br><span class="line">--client-ca-file string</span><br><span class="line">    If set, any request presenting a client certificate signed by one of the authorities in the client-ca-file is authenticated with an identity corresponding to the CommonName of the client certificate.</span><br><span class="line">--tls-cert-file string </span><br><span class="line">    File containing x509 Certificate used for serving HTTPS (with intermediate certs, if any, concatenated after server cert). If --tls-cert-file and --tls-private-key-file are not provided, a self-signed certificate and key are generated for the public address and saved to the directory passed to --cert-dir.</span><br><span class="line">--tls-private-key-file string</span><br><span class="line">    File containing x509 private key matching --tls-cert-file.</span><br></pre></td></tr></tbody></table></figure><p></p><p>kubelet也是即作为server也作为client, 需要提供tls证书和client-ca, 我们称这个CA为<code>kubelet-ca</code>, 可以是单独的CA。</p><h3 id="etcd证书"><a href="#etcd证书" class="headerlink" title="etcd证书"></a>etcd证书</h3><p>这个也不用多说，用来连接etcd，由<code>etcd-ca</code>签发<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--etcd-certfile string                      SSL certification file used to secure etcd communication.</span><br><span class="line">--etcd-keyfile string                       SSL key file used to secure etcd communication.</span><br></pre></td></tr></tbody></table></figure><p></p><h3 id="serviceaccount证书"><a href="#serviceaccount证书" class="headerlink" title="serviceaccount证书"></a>serviceaccount证书</h3><p>在k8s中，通过<code>JWT</code>认证<code>serviecaccount</code>，同样有两个证书配置:<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># apiserver</span><br><span class="line">--service-account-key-file stringArray # 用于验证sa</span><br><span class="line">    File containing PEM-encoded x509 RSA or ECDSA private or public keys, used to verify ServiceAccount tokens. The specified file can contain multiple keys, and the flag can be specified multiple times with different files. If unspecified, --tls-private-key-file is used. Must be specified when --service-account-signing-key is provided</span><br><span class="line">--service-account-signing-key-file string</span><br><span class="line">    Path to the file that contains the current private key of the service account token issuer. The issuer will sign issued ID tokens with this private key. (Requires the 'TokenRequest' feature gate.)</span><br><span class="line"></span><br><span class="line"># controller-manager</span><br><span class="line">–service-account-private-key-file #用于签署sa</span><br></pre></td></tr></tbody></table></figure><p></p><p>这两个配置描述了对<code>serviceaccount</code>进行签名验证时所使用的证书；可以是单独的生成，我们称为<code>sa-key</code>。</p><h2 id="其他证书"><a href="#其他证书" class="headerlink" title="其他证书"></a>其他证书</h2><p>其他还有<code>oidc</code>证书，用于OpenID认证；<code>ssh</code>证书，用来连接node，目前以及废弃。</p><p>etcd与kubelet证书上面已经提过了，需要双方都配置。</p><p>k8s中也支持证书申请，用户可以创建<code>CertificateSigningRequest</code>来申请证书，需要在controller-manager配置下面的证书，用于签发证书称为<code>sing-ca</code>，多用于webhook的证书配置。<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--cluster-signing-cert-file string          Filename containing a PEM-encoded X509 CA certificate used to issue cluster-scoped certificates (default "/etc/kubernetes/ca/ca.pem")</span><br><span class="line">--cluster-signing-key-file string           Filename containing a PEM-encoded RSA or ECDSA private key used to sign cluster-scoped certificates (default "/etc/kubernetes/ca/ca.key")</span><br></pre></td></tr></tbody></table></figure><p></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>k8s提供了强大的功能，需要考虑到各个场景的安全问题，上面我们梳理了遍目前常用的证书</p><ul><li>tls-ca</li><li>client-ca</li><li>requestheader-ca</li><li>proxy-ca</li><li>kubelet-ca</li><li>etcd-ca</li><li>sa-key</li><li>sign-ca</li></ul><p>上面除了<code>proxy-ca</code>必须使用<code>requestheader-ca</code>签发，其他所有的都可以是单独的CA，可以根据安全性评估是使用一个CA还是多个CA，我们建议下面的CA尽量是独立的</p><ul><li>client-ca</li><li>requestheader-ca</li><li>etcd-ca</li><li>kubelet-ca</li><li>sign-ca</li></ul><p>终于理完了，可以起床啦。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;为了避免广告法，题目还是加个可能吧。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="apiserver" scheme="https://qingwave.github.io/tags/apiserver/"/>
    
      <category term="tls" scheme="https://qingwave.github.io/tags/tls/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes扩展apiserver实现分析</title>
    <link href="https://qingwave.github.io/kube-apiserver-aggretation-api/"/>
    <id>https://qingwave.github.io/kube-apiserver-aggretation-api/</id>
    <published>2020-04-24T07:28:16.000Z</published>
    <updated>2020-04-28T02:13:33.259Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes提供了丰富的扩展功能，实现自定义资源有两种方式<code>CRD</code>与<code>Aggregation API</code>。相对于<code>CRD</code>，扩展API功能更丰富，可以实现单独的存储。今天来聊一聊，k8s是如是实现扩展api的，它与apiserver之间又是如何协作的</p><h2 id="AggregationApiserver介绍"><a href="#AggregationApiserver介绍" class="headerlink" title="AggregationApiserver介绍"></a>AggregationApiserver介绍</h2><p><code>Aggregator</code>类似于一个七层负载均衡，将来自用户的请求拦截转发给其他服务器，并且负责整个 APIServer 的 Discovery 功能。</p><p>通过<code>APIServices</code>对象关联到某个<code>Service</code>来进行请求的转发，其关联的<code>Service</code>类型进一步决定了请求转发形式。<code>Aggregator</code>包括一个<code>GenericAPIServer</code>和维护自身状态的<code>Controller</code>。其中 <code>GenericAPIServer</code>主要处理<code>apiregistration.k8s.io</code>组下的<code>APIService</code>资源请求。</p><p>主要controller包括：</p><ol><li>apiserviceRegistrationController：负责<code>APIServices</code>中资源的注册与删除；</li><li>availableConditionController：维护<code>APIServices</code>的可用状态，包括其引用<code>Service</code>是否可用等；</li><li>autoRegistrationController：用于保持API中存在的一组特定的<code>APIServices</code>；</li><li>crdRegistrationController：负责将<code>CRD GroupVersions</code>自动注册到<code>APIServices</code>中；</li><li>openAPIAggregationController：将<code>APIServices</code>资源的变化同步至提供的<code>OpenAPI</code>文档；</li></ol><p>在 kube-apiserver 中需要增加以下配置来开启 API Aggregation：<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--proxy-client-cert-file=/etc/kubernetes/certs/proxy.crt</span><br><span class="line">--proxy-client-key-file=/etc/kubernetes/certs/proxy.key</span><br><span class="line">--requestheader-client-ca-file=/etc/kubernetes/certs/proxy-ca.crt</span><br><span class="line">--requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class="line">--requestheader-group-headers=X-Remote-Group</span><br><span class="line">--requestheader-username-headers=X-Remote-User</span><br></pre></td></tr></tbody></table></figure><p></p><p>如果 kube-proxy 没有和 API server 运行在同一台主机上，那么需要确保启用了如下 apiserver 标记：<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--enable-aggregator-routing=true</span><br></pre></td></tr></tbody></table></figure><p></p><p>在<a href="./kube-apiserver-start.md">apiserver启动流程</a>中，分析了<code>AggregationApiserver</code>的初始化流程, 需要了解的可以回去看下。</p><h2 id="AggregationApiserver认证流程"><a href="#AggregationApiserver认证流程" class="headerlink" title="AggregationApiserver认证流程"></a>AggregationApiserver认证流程</h2><p>与自定义资源定义（CRD）不同，除标准的 Kubernetes apiserver 外，Aggregation API 还涉及另一个服务器：扩展 apiserver。Kubernetes apiserver 将需要与您的扩展 apiserver 通信，并且您的扩展 apiserver 也需要与 Kubernetes apiserver 通信。为了确保此通信的安全，Kubernetes apiserver 使用 x509 证书向扩展 apiserver 认证。</p><p>AggregationApi的请求链路如下：<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">defaultHandlerChain-&gt;aggregator-&gt;aggregation-apiserver-&gt;aggregator-&gt;user</span><br></pre></td></tr></tbody></table></figure><p></p><p>大致流程如下：</p><ol><li>Kubernetes apiserver：对发出请求的用户身份认证，并对请求的 API 路径执行鉴权。</li><li>Kubernetes apiserver：将请求转发到扩展 apiserver</li><li>扩展 apiserver：认证来自 Kubernetes apiserver 的请求</li><li>扩展 apiserver：对来自原始用户的请求鉴权</li><li>扩展 apiserver：执行对应操作返回</li></ol><p>如图所示：<br><a href="https://d33wubrfki0l68.cloudfront.net/3c5428678a95c3715894011d8dd4812d2cf229b9/e745c/images/docs/aggregation-api-auth-flow.png" target="_blank" rel="noopener">aggregation-apiserver-auth</a></p><p>apiserver与扩展apiserver通过证书认证,</p><ul><li>apiserver配置<code>porxy-client</code>证书(使用requestheader根证书签发)，扩展apiserver配置<code>reqeustheader</code>根证书，如果没配置，会默认从configmap <code>kube-system/extension-apiserver-authentication</code> 去找</li><li>扩展apiserver通过<code>extension-apiserver-authentication</code>获取apiserver的<code>client-ca</code>，生成证书对，apiserver可以使用<code>client-ca</code>验证它</li><li>由于apiserver-&gt;扩展apiserver通过<code>reqeustheader</code>方式认证，apiserver会将接受到的请求经过认证，转换为header，扩展apiserver通过header获取用户，再通过apiserver接口做权限校验。</li></ul><p>有同学有疑问，为什么这里需要做两次认证，两次鉴权。这是由于扩展apiserveer是一个单独的服务器，如果接受非apiserver的请求也是需要做认证鉴权的。那能不能认证是apiserver后就不做鉴权了呢，这得需要apiserver在转发请求时加入鉴权信息就行。</p><h2 id="AggregationApiserver处理流程"><a href="#AggregationApiserver处理流程" class="headerlink" title="AggregationApiserver处理流程"></a>AggregationApiserver处理流程</h2><h3 id="apiserver处理逻辑"><a href="#apiserver处理逻辑" class="headerlink" title="apiserver处理逻辑"></a>apiserver处理逻辑</h3><p>在apiserver认证时，认证接受会将认证信息删除, 可参考前面的[apiserver认证源码分析]</p><p>处理逻辑如下：</p><ol><li>通过<code>context</code>获取user信息</li><li>构造请求，删除reqeustheader信息，通过user重新填充</li><li>通过<code>proxyRoundTripper</code>转发请求</li></ol><p>(kube-apiserver-authentication-code.md)<br>aggregation的<a href="https://github.com/kubernetes/kubernetes/blob/df9b4e92e84849e2b9fdb5b4849c9c4ebfae8040/staging/src/k8s.io/kube-aggregator/pkg/apiserver/handler_proxy.go#L109" target="_blank" rel="noopener">hander</a>的实现：<br></p><figure class="highlight golang"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通过context获取user</span></span><br><span class="line">user, ok := genericapirequest.UserFrom(req.Context())</span><br><span class="line"><span class="keyword">if</span> !ok {</span><br><span class="line">proxyError(w, req, <span class="string">"missing user"</span>, http.StatusInternalServerError)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">  }</span><br><span class="line">  <span class="comment">// 构造请求url,通过apiservice配置的service/namespace随机得到某个endpoint后端</span></span><br><span class="line">  location := &amp;url.URL{}</span><br><span class="line">location.Scheme = <span class="string">"https"</span></span><br><span class="line">rloc, err := r.serviceResolver.ResolveEndpoint(handlingInfo.serviceNamespace, handlingInfo.serviceName, handlingInfo.servicePort)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">klog.Errorf(<span class="string">"error resolving %s/%s: %v"</span>, handlingInfo.serviceNamespace, handlingInfo.serviceName, err)</span><br><span class="line">proxyError(w, req, <span class="string">"service unavailable"</span>, http.StatusServiceUnavailable)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line">location.Host = rloc.Host</span><br><span class="line">location.Path = req.URL.Path</span><br><span class="line">  location.RawQuery = req.URL.Query().Encode()</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// we need to wrap the roundtripper in another roundtripper which will apply the front proxy headers</span></span><br><span class="line">  <span class="comment">// 包裹请求信息，将user信息放到header中</span></span><br><span class="line">proxyRoundTripper, upgrade, err := maybeWrapForConnectionUpgrades(handlingInfo.restConfig, handlingInfo.proxyRoundTripper, req)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">proxyError(w, req, err.Error(), http.StatusInternalServerError)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line">  proxyRoundTripper = transport.NewAuthProxyRoundTripper(user.GetName(), user.GetGroups(), user.GetExtra(), proxyRoundTripper)</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 调用后端</span></span><br><span class="line">  handler := proxy.NewUpgradeAwareHandler(location, proxyRoundTripper, <span class="literal">true</span>, upgrade, &amp;responder{w: w})</span><br><span class="line">handler.ServeHTTP(w, newReq)</span><br></pre></td></tr></tbody></table></figure><p></p><p>根据扩展apiserver找到后端时通过service获取对应endpoint列表，随机选择某个endpoint、<br>实现如下：<br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ResourceLocation returns a URL to which one can send traffic for the specified service.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ResolveEndpoint</span><span class="params">(services listersv1.ServiceLister, endpoints listersv1.EndpointsLister, namespace, id <span class="keyword">string</span>, port <span class="keyword">int32</span>)</span> <span class="params">(*url.URL, error)</span></span> {</span><br><span class="line">svc, err := services.Services(namespace).Get(id)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">svcPort, err := findServicePort(svc, port)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">switch</span> {</span><br><span class="line"><span class="keyword">case</span> svc.Spec.Type == v1.ServiceTypeClusterIP, svc.Spec.Type == v1.ServiceTypeLoadBalancer, svc.Spec.Type == v1.ServiceTypeNodePort:</span><br><span class="line"><span class="comment">// these are fine</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">"unsupported service type %q"</span>, svc.Spec.Type)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">eps, err := endpoints.Endpoints(namespace).Get(svc.Name)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(eps.Subsets) == <span class="number">0</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, errors.NewServiceUnavailable(fmt.Sprintf(<span class="string">"no endpoints available for service %q"</span>, svc.Name))</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// Pick a random Subset to start searching from.</span></span><br><span class="line">ssSeed := rand.Intn(<span class="built_in">len</span>(eps.Subsets))</span><br><span class="line"></span><br><span class="line"><span class="comment">// Find a Subset that has the port.</span></span><br><span class="line"><span class="keyword">for</span> ssi := <span class="number">0</span>; ssi &lt; <span class="built_in">len</span>(eps.Subsets); ssi++ {</span><br><span class="line">ss := &amp;eps.Subsets[(ssSeed+ssi)%<span class="built_in">len</span>(eps.Subsets)]</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(ss.Addresses) == <span class="number">0</span> {</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">}</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> ss.Ports {</span><br><span class="line"><span class="keyword">if</span> ss.Ports[i].Name == svcPort.Name {</span><br><span class="line"><span class="comment">// Pick a random address.</span></span><br><span class="line"><span class="comment">// 核心，随机选择endpoint</span></span><br><span class="line">ip := ss.Addresses[rand.Intn(<span class="built_in">len</span>(ss.Addresses))].IP</span><br><span class="line">port := <span class="keyword">int</span>(ss.Ports[i].Port)</span><br><span class="line"><span class="keyword">return</span> &amp;url.URL{</span><br><span class="line">Scheme: <span class="string">"https"</span>,</span><br><span class="line">Host:   net.JoinHostPort(ip, strconv.Itoa(port)),</span><br><span class="line">}, <span class="literal">nil</span></span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, errors.NewServiceUnavailable(fmt.Sprintf(<span class="string">"no endpoints available for service %q"</span>, id))</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>ProxyRoundTripper创建在<a href="https://github.com/kubernetes/kubernetes/blob/a42e029e6905bee5b9d5489610c4fbe5988eeac6/staging/src/k8s.io/client-go/transport/round_trippers.go#L101" target="_blank" rel="noopener">round_trippers.go</a><br></p><figure class="highlight golang"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewAuthProxyRoundTripper</span><span class="params">(username <span class="keyword">string</span>, groups []<span class="keyword">string</span>, extra <span class="keyword">map</span>[<span class="keyword">string</span>][]<span class="keyword">string</span>, rt http.RoundTripper)</span> <span class="title">http</span>.<span class="title">RoundTripper</span></span> {</span><br><span class="line"><span class="keyword">return</span> &amp;authProxyRoundTripper{</span><br><span class="line">username: username,</span><br><span class="line">groups:   groups,</span><br><span class="line">extra:    extra,</span><br><span class="line">rt:       rt,</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rt *authProxyRoundTripper)</span> <span class="title">RoundTrip</span><span class="params">(req *http.Request)</span> <span class="params">(*http.Response, error)</span></span> {</span><br><span class="line">  req = utilnet.CloneRequest(req)</span><br><span class="line">  <span class="comment">// 包裹user信息</span></span><br><span class="line">SetAuthProxyHeaders(req, rt.username, rt.groups, rt.extra)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> rt.rt.RoundTrip(req)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// SetAuthProxyHeaders stomps the auth proxy header fields.  It mutates its argument.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">SetAuthProxyHeaders</span><span class="params">(req *http.Request, username <span class="keyword">string</span>, groups []<span class="keyword">string</span>, extra <span class="keyword">map</span>[<span class="keyword">string</span>][]<span class="keyword">string</span>)</span></span> {</span><br><span class="line">  <span class="comment">// 清楚原始url的requestheader信息</span></span><br><span class="line">req.Header.Del(<span class="string">"X-Remote-User"</span>)</span><br><span class="line">req.Header.Del(<span class="string">"X-Remote-Group"</span>)</span><br><span class="line"><span class="keyword">for</span> key := <span class="keyword">range</span> req.Header {</span><br><span class="line"><span class="keyword">if</span> strings.HasPrefix(strings.ToLower(key), strings.ToLower(<span class="string">"X-Remote-Extra-"</span>)) {</span><br><span class="line">req.Header.Del(key)</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 通过user重新填充信息</span></span><br><span class="line">req.Header.Set(<span class="string">"X-Remote-User"</span>, username)</span><br><span class="line"><span class="keyword">for</span> _, group := <span class="keyword">range</span> groups {</span><br><span class="line">req.Header.Add(<span class="string">"X-Remote-Group"</span>, group)</span><br><span class="line">}</span><br><span class="line"><span class="keyword">for</span> key, values := <span class="keyword">range</span> extra {</span><br><span class="line"><span class="keyword">for</span> _, value := <span class="keyword">range</span> values {</span><br><span class="line">req.Header.Add(<span class="string">"X-Remote-Extra-"</span>+headerKeyEscape(key), value)</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><h3 id="扩展apiserver处理逻辑"><a href="#扩展apiserver处理逻辑" class="headerlink" title="扩展apiserver处理逻辑"></a>扩展apiserver处理逻辑</h3><p>下以metrics-server为例说明扩展apiserver在收到apiserver请求后的处理</p><p>与apiserver初始化相同，metrics-server也需要初始化生成<code>genericServer</code>, 然后注册apigroup<br><code>pkg/metrics-server/config.go</code><br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c Config)</span> <span class="title">Complete</span><span class="params">()</span> <span class="params">(*MetricsServer, error)</span></span> {</span><br><span class="line">informer, err := c.informer()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line">kubeletClient, err := c.kubeletClient()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line">addressResolver := c.addressResolver()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建scraper，负责抓取监控数据</span></span><br><span class="line">scrape := scraper.NewScraper(informer.Core().V1().Nodes().Lister(), kubeletClient, addressResolver, c.ScrapeTimeout)</span><br><span class="line"></span><br><span class="line">scraper.RegisterScraperMetrics(c.ScrapeTimeout)</span><br><span class="line">RegisterServerMetrics(c.MetricResolution)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 生成genericServer, 包裹有 DefaultBuildHandlerChain</span></span><br><span class="line">genericServer, err := c.Apiserver.Complete(informer).New(<span class="string">"metrics-server"</span>, genericapiserver.NewEmptyDelegate())</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">store := storage.NewStorage()</span><br><span class="line"><span class="comment">// 注册api</span></span><br><span class="line"><span class="keyword">if</span> err := api.Install(store, informer.Core().V1(), genericServer); err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line"><span class="keyword">return</span> &amp;MetricsServer{</span><br><span class="line">GenericAPIServer: genericServer,</span><br><span class="line">storage:          store,</span><br><span class="line">scraper:          scrape,</span><br><span class="line">resolution:       c.MetricResolution,</span><br><span class="line">}, <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>api注册代码，通过<code>Build</code>生成apigroup，调用<code>InstallAPIGroup</code>进行注册<br><code>pkg/api/install.go</code><br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// InstallStorage builds the metrics for the metrics.k8s.io API, and then installs it into the given API metrics-server.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Install</span><span class="params">(metrics MetricsGetter, informers coreinf.Interface, server *genericapiserver.GenericAPIServer)</span> <span class="title">error</span></span> {</span><br><span class="line">info := Build(metrics, informers)</span><br><span class="line"><span class="comment">// 注册apigroup</span></span><br><span class="line"><span class="keyword">return</span> server.InstallAPIGroup(&amp;info)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// Build constructs APIGroupInfo the metrics.k8s.io API group using the given getters.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Build</span><span class="params">(m MetricsGetter, informers coreinf.Interface)</span> <span class="title">genericapiserver</span>.<span class="title">APIGroupInfo</span></span> {</span><br><span class="line">apiGroupInfo := genericapiserver.NewDefaultAPIGroupInfo(metrics.GroupName, Scheme, metav1.ParameterCodec, Codecs)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册metrics相关api</span></span><br><span class="line">node := newNodeMetrics(metrics.Resource(<span class="string">"nodemetrics"</span>), m, informers.Nodes().Lister())</span><br><span class="line">pod := newPodMetrics(metrics.Resource(<span class="string">"podmetrics"</span>), m, informers.Pods().Lister())</span><br><span class="line">metricsServerResources := <span class="keyword">map</span>[<span class="keyword">string</span>]rest.Storage{</span><br><span class="line"><span class="string">"nodes"</span>: node,</span><br><span class="line"><span class="string">"pods"</span>:  pod,</span><br><span class="line">}</span><br><span class="line">apiGroupInfo.VersionedResourcesStorageMap[v1beta1.SchemeGroupVersion.Version] = metricsServerResources</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> apiGroupInfo</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>同apiserver，metrics-server收到请求后会经过<code>DefaultBuildHandlerChain</code></p><ul><li>认证，从apiserver转发来的请求是<code>reqeustheader</code>形式，metrics-server会使用<code>requestheader-ca</code>验证证书</li><li>鉴权，同apiserver一样</li></ul><blockquote><p>注意, 如果apiserver未配置<code>proxy-client</code>证书，metrics-server认证不通过，即使apiserver认证通过，metrics-server也会认为是匿名用户<code>system:anonymous</code></p></blockquote><p>最后，metrics-server执行具体逻辑，返回结果。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>扩容apiserver的创建，处理流程与apiserver完全一样，可以直接调用apiserver的库，扩展apiserver直接处理请求，不需要经过webhook，性能更好，更强大的是完全不使用etcd，替换成时序数据库或者其他数据库。后续可以分析下CRD与扩展apiserver的区别以及使用场景。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kubernetes提供了丰富的扩展功能，实现自定义资源有两种方式&lt;code&gt;CRD&lt;/code&gt;与&lt;code&gt;Aggregation API&lt;/code&gt;。相对于&lt;code&gt;CRD&lt;/code&gt;，扩展API功能更丰富，可以实现单独的存储。今天来聊一聊，k8s是如是实现扩展api的，它与apiserver之间又是如何协作的&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="apiserver" scheme="https://qingwave.github.io/tags/apiserver/"/>
    
  </entry>
  
  <entry>
    <title>kube-apiserver启动流程分析</title>
    <link href="https://qingwave.github.io/kube-apiserver-start/"/>
    <id>https://qingwave.github.io/kube-apiserver-start/</id>
    <published>2020-04-24T07:28:16.000Z</published>
    <updated>2020-04-25T12:32:58.748Z</updated>
    
    <content type="html"><![CDATA[<p>kube-apiserver 共由 3 个组件构成（Aggregator. KubeAPIServer. APIExtensionServer），这些组件依次通过 Delegation 处理请求：</p><ul><li>Aggregator：暴露的功能类似于一个七层负载均衡，将来自用户的请求拦截转发给其他服务器，并且负责整个 APIServer 的 Discovery 功能；也负责处理ApiService，注册对应的扩展api。</li><li>KubeAPIServer ：负责对请求的一些通用处理，认证. 鉴权等，以及处理各个内建资源的 REST 服务；</li><li>APIExtensionServer：主要处理 CustomResourceDefinition（CRD）和 CustomResource（CR）的 REST 请求，也是 Delegation 的最后一环，如果对应 CR 不能被处理的话则会返回 404。</li></ul><h2 id="kube-apiserver启动流程"><a href="#kube-apiserver启动流程" class="headerlink" title="kube-apiserver启动流程"></a>kube-apiserver启动流程</h2><p>Apiserver通过<code>Run</code>方法启动, 主要逻辑为：</p><ol><li>调用<code>CreateServerChain</code>构建服务调用链并判断是否启动非安全的<code>httpserver</code>，<code>httpserver</code>链中包含 apiserver要启动的三个server，以及为每个server注册对应资源的路由；</li><li>调用<code>server.PrepareRun</code>进行服务运行前的准备，该方法主要完成了健康检查. 存活检查和OpenAPI路由的注册工作；</li><li>调用<code>prepared.Run</code>启动server；<figure class="highlight golang"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Run runs the specified APIServer.  This should never exit.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Run</span><span class="params">(completeOptions completedServerRunOptions, stopCh &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>{})</span> <span class="title">error</span></span> {</span><br><span class="line"><span class="comment">// To help debugging, immediately log version</span></span><br><span class="line">klog.Infof(<span class="string">"Version: %+v"</span>, version.Get())</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 创建调用链</span></span><br><span class="line">server, err := CreateServerChain(completeOptions, stopCh)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 进行一些准备工作， 注册一些hander，执行hook等</span></span><br><span class="line">prepared, err := server.PrepareRun()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 开始执行</span></span><br><span class="line"><span class="keyword">return</span> prepared.Run(stopCh)</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></li></ol><p>执行具体的<code>Run</code>方法<br></p><figure class="highlight golang"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Run spawns the secure http server. It only returns if stopCh is closed</span></span><br><span class="line"><span class="comment">// or the secure port cannot be listened on initially.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s preparedGenericAPIServer)</span> <span class="title">Run</span><span class="params">(stopCh &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>{})</span> <span class="title">error</span></span> {</span><br><span class="line">delayedStopCh := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>{})</span><br><span class="line"></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> {</span><br><span class="line"><span class="keyword">defer</span> <span class="built_in">close</span>(delayedStopCh)</span><br><span class="line"></span><br><span class="line">&lt;-stopCh</span><br><span class="line"></span><br><span class="line"><span class="comment">// As soon as shutdown is initiated, /readyz should start returning failure.</span></span><br><span class="line"><span class="comment">// This gives the load balancer a window defined by ShutdownDelayDuration to detect that /readyz is red</span></span><br><span class="line"><span class="comment">// and stop sending traffic to this server.</span></span><br><span class="line"><span class="comment">// 当终止时，关闭readiness</span></span><br><span class="line"><span class="built_in">close</span>(s.readinessStopCh)</span><br><span class="line"></span><br><span class="line">time.Sleep(s.ShutdownDelayDuration)</span><br><span class="line">}()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行非阻塞Run</span></span><br><span class="line"><span class="comment">// close socket after delayed stopCh</span></span><br><span class="line">err := s.NonBlockingRun(delayedStopCh)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">&lt;-stopCh</span><br><span class="line"></span><br><span class="line"><span class="comment">// run shutdown hooks directly. This includes deregistering from the kubernetes endpoint in case of kube-apiserver.</span></span><br><span class="line"><span class="comment">// 关闭前执行一些hook操作</span></span><br><span class="line">err = s.RunPreShutdownHooks()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// wait for the delayed stopCh before closing the handler chain (it rejects everything after Wait has been called).</span></span><br><span class="line">&lt;-delayedStopCh</span><br><span class="line"></span><br><span class="line"><span class="comment">// 等待所有请求执行完</span></span><br><span class="line"><span class="comment">// Wait for all requests to finish, which are bounded by the RequestTimeout variable.</span></span><br><span class="line">s.HandlerChainWaitGroup.Wait()</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>执行<code>NonBlockingRun</code><br><code>k8s.io/kubernetes/staging/src/k8s.io/apiserver/pkg/server/genericapiserver.go:351</code><br></p><figure class="highlight golang"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s preparedGenericAPIServer)</span> <span class="title">NonBlockingRun</span><span class="params">(stopCh &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>{})</span> <span class="title">error</span></span> {</span><br><span class="line">    auditStopCh := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>{})</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 判断是否要启动审计日志</span></span><br><span class="line">    <span class="keyword">if</span> s.AuditBackend != <span class="literal">nil</span> {</span><br><span class="line">        <span class="keyword">if</span> err := s.AuditBackend.Run(auditStopCh); err != <span class="literal">nil</span> {</span><br><span class="line">            <span class="keyword">return</span> fmt.Errorf(<span class="string">"failed to run the audit backend: %v"</span>, err)</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 启动 https server</span></span><br><span class="line">    internalStopCh := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>{})</span><br><span class="line">    <span class="keyword">var</span> stoppedCh &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>{}</span><br><span class="line">    <span class="keyword">if</span> s.SecureServingInfo != <span class="literal">nil</span> &amp;&amp; s.Handler != <span class="literal">nil</span> {</span><br><span class="line">        <span class="keyword">var</span> err error</span><br><span class="line">        stoppedCh, err = s.SecureServingInfo.Serve(s.Handler, s.ShutdownTimeout, internalStopCh)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">            <span class="built_in">close</span>(internalStopCh)</span><br><span class="line">            <span class="built_in">close</span>(auditStopCh)</span><br><span class="line">            <span class="keyword">return</span> err</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> {</span><br><span class="line">        &lt;-stopCh</span><br><span class="line">        <span class="built_in">close</span>(s.readinessStopCh)</span><br><span class="line">        <span class="built_in">close</span>(internalStopCh)</span><br><span class="line">        <span class="keyword">if</span> stoppedCh != <span class="literal">nil</span> {</span><br><span class="line">            &lt;-stoppedCh</span><br><span class="line">        }</span><br><span class="line">        s.HandlerChainWaitGroup.Wait()</span><br><span class="line">        <span class="built_in">close</span>(auditStopCh)</span><br><span class="line">    }()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. 执行 postStartHooks</span></span><br><span class="line">    s.RunPostStartHooks(stopCh)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. 向 systemd 发送 ready 信号</span></span><br><span class="line">    <span class="keyword">if</span> _, err := systemd.SdNotify(<span class="literal">true</span>, <span class="string">"READY=1\n"</span>); err != <span class="literal">nil</span> {</span><br><span class="line">        klog.Errorf(<span class="string">"Unable to send systemd daemon successful start message: %v\n"</span>, err)</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><h2 id="调用链分析"><a href="#调用链分析" class="headerlink" title="调用链分析"></a>调用链分析</h2><p>上一节简单分析了Apiserver的启动流程，通过初始化各种配置，封装调用链，启动Server。这节主要分析调用链。</p><p>初始化阶段, 通过<code>CreateServerChain</code>创建调用链， 代码在<a href="https://github.com/kubernetes/kubernetes/blob/1d057da2f73118893b5cc27c15d59ff03beb271e/cmd/kube-apiserver/app/server.go#L169" target="_blank" rel="noopener">server.go</a><br></p><figure class="highlight golang"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CreateServerChain creates the apiservers connected via delegation.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">CreateServerChain</span><span class="params">(completedOptions completedServerRunOptions, stopCh &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>{})</span> <span class="params">(*aggregatorapiserver.APIAggregator, error)</span></span> {</span><br><span class="line">  <span class="comment">// nodetunneler与node通信，proxy实现代理功能，转发请求给其他apiservice</span></span><br><span class="line">  <span class="comment">// apiserver到cluster的通信可以通过三种方法</span></span><br><span class="line">  <span class="comment">// apiserver到kubelet的endpoint，用于logs功能，exec功能，port-forward功能</span></span><br><span class="line">  <span class="comment">// HTTP连接，即使可以用HTTPS也不做任何其他校验，并不安全</span></span><br><span class="line">  <span class="comment">// ssh tunnel，不推荐使用</span></span><br><span class="line"></span><br><span class="line">  nodeTunneler, proxyTransport, err := CreateNodeDialer(completedOptions)</span><br><span class="line">    <span class="comment">// 1. 为 kubeAPIServer 创建配置</span></span><br><span class="line">    kubeAPIServerConfig, insecureServingInfo, serviceResolver, pluginInitializer, admissionPostStartHook, err :=                                         CreateKubeAPIServerConfig(completedOptions, nodeTunneler, proxyTransport)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 判断是否配置了 APIExtensionsServer，创建 apiExtensionsConfig </span></span><br><span class="line">    apiExtensionsConfig, err := createAPIExtensionsConfig(*kubeAPIServerConfig.GenericConfig, kubeAPIServerConfig.ExtraConfig.VersionedInformers,        pluginInitializer, completedOptions.ServerRunOptions, completedOptions.MasterCount,vc</span><br><span class="line">        serviceResolver, webhook.NewDefaultAuthenticationInfoResolverWrapper(proxyTransport, kubeAPIServerConfig.GenericConfig.LoopbackClientConfig))</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 3. 初始化 APIExtensionsServer, 通过一个空的delegate初始化</span></span><br><span class="line">    apiExtensionsServer, err := createAPIExtensionsServer(apiExtensionsConfig, genericapiserver.NewEmptyDelegate())</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. 初始化 KubeAPIServer</span></span><br><span class="line">    kubeAPIServer, err := CreateKubeAPIServer(kubeAPIServerConfig, apiExtensionsServer.GenericAPIServer, admissionPostStartHook)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 5. 创建 AggregatorConfig</span></span><br><span class="line">    aggregatorConfig, err := createAggregatorConfig(*kubeAPIServerConfig.GenericConfig, completedOptions.ServerRunOptions, kubeAPIServerConfig.          ExtraConfig.VersionedInformers, serviceResolver, proxyTransport, pluginInitializer)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">    }</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 6. 初始化 AggregatorServer</span></span><br><span class="line">    aggregatorServer, err := createAggregatorServer(aggregatorConfig, kubeAPIServer.GenericAPIServer, apiExtensionsServer.Informers)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 7. 判断是否启动非安全端口的 http server</span></span><br><span class="line">    <span class="keyword">if</span> insecureServingInfo != <span class="literal">nil</span> {</span><br><span class="line">        insecureHandlerChain := kubeserver.BuildInsecureHandlerChain(aggregatorServer.GenericAPIServer.UnprotectedHandler(), kubeAPIServerConfig.GenericConfig)</span><br><span class="line">        <span class="keyword">if</span> err := insecureServingInfo.Serve(insecureHandlerChain, kubeAPIServerConfig.GenericConfig.RequestTimeout, stopCh); err != <span class="literal">nil</span> {</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> aggregatorServer, <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>创建过程主要有以下步骤：</p><ol><li>根据配置构造apiserver的配置，调用方法<code>CreateKubeAPIServerConfig</code></li><li>根据配置构造扩展的apiserver的配置，调用方法为<code>createAPIExtensionsConfig</code></li><li>创建server，包括扩展的apiserver和原生的apiserver，调用方法为<code>createAPIExtensionsServer</code>和<code>CreateKubeAPIServer</code>。主要就是将各个handler的路由方法注册到Container中去，完全遵循go-restful的设计模式，即将处理方法注册到Route中去，同一个根路径下的Route注册到WebService中去，WebService注册到Container中，Container负责分发。访问的过程为<code>Container--&gt;WebService--&gt;Route</code></li><li>聚合server的配置和和创建。主要就是将原生的apiserver和扩展的apiserver的访问进行整合，添加后续的一些处理接口。调用方法为<code>createAggregatorConfig</code>和<code>createAggregatorServer</code></li><li>创建完成，返回配置的server信息</li></ol><p>以上几个步骤，最核心的就是apiserver如何创建，即如何按照go-restful的模式，添加路由和相应的处理方法。</p><h3 id="配置初始化"><a href="#配置初始化" class="headerlink" title="配置初始化"></a>配置初始化</h3><p>先看apiserver配置的创建<code>CreateKubeAPIServerConfig-&gt;buildGenericConfig-&gt;genericapiserver.NewConfig</code></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// BuildGenericConfig takes the master server options and produces the genericapiserver.Config associated with it</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">buildGenericConfig</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">s *options.ServerRunOptions,</span></span></span><br><span class="line"><span class="function"><span class="params">proxyTransport *http.Transport,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">genericConfig *genericapiserver.Config,</span></span></span><br><span class="line"><span class="function"><span class="params">versionedInformers clientgoinformers.SharedInformerFactory,</span></span></span><br><span class="line"><span class="function"><span class="params">insecureServingInfo *genericapiserver.DeprecatedInsecureServingInfo,</span></span></span><br><span class="line"><span class="function"><span class="params">serviceResolver aggregatorapiserver.ServiceResolver,</span></span></span><br><span class="line"><span class="function"><span class="params">pluginInitializers []admission.PluginInitializer,</span></span></span><br><span class="line"><span class="function"><span class="params">admissionPostStartHook genericapiserver.PostStartHookFunc,</span></span></span><br><span class="line"><span class="function"><span class="params">storageFactory *serverstorage.DefaultStorageFactory,</span></span></span><br><span class="line"><span class="function"><span class="params">lastErr error,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span> {</span><br><span class="line"><span class="comment">// 创建genericConfig,其中包括DefaultBuildHandlerChain，一系列认证授权的中间件</span></span><br><span class="line">genericConfig = genericapiserver.NewConfig(legacyscheme.Codecs)</span><br><span class="line">genericConfig.MergedResourceConfig = master.DefaultAPIResourceConfigSource()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化各种配置</span></span><br><span class="line"><span class="keyword">if</span> lastErr = s.GenericServerRunOptions.ApplyTo(genericConfig); lastErr != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">genericConfig.OpenAPIConfig = genericapiserver.DefaultOpenAPIConfig(generatedopenapi.GetOpenAPIDefinitions, openapinamer.NewDefinitionNamer(legacyscheme.Scheme, extensionsapiserver.Scheme, aggregatorscheme.Scheme))</span><br><span class="line">genericConfig.OpenAPIConfig.Info.Title = <span class="string">"Kubernetes"</span></span><br><span class="line"><span class="comment">// 长连接请求</span></span><br><span class="line">genericConfig.LongRunningFunc = filters.BasicLongRunningRequestCheck(</span><br><span class="line">sets.NewString(<span class="string">"watch"</span>, <span class="string">"proxy"</span>),</span><br><span class="line">sets.NewString(<span class="string">"attach"</span>, <span class="string">"exec"</span>, <span class="string">"proxy"</span>, <span class="string">"log"</span>, <span class="string">"portforward"</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">kubeVersion := version.Get()</span><br><span class="line">genericConfig.Version = &amp;kubeVersion</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化storageFactory， 用来连接etcd</span></span><br><span class="line">storageFactoryConfig := kubeapiserver.NewStorageFactoryConfig()</span><br><span class="line">storageFactoryConfig.APIResourceConfig = genericConfig.MergedResourceConfig</span><br><span class="line">completedStorageFactoryConfig, err := storageFactoryConfig.Complete(s.Etcd)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">lastErr = err</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line">storageFactory, lastErr = completedStorageFactoryConfig.New()</span><br><span class="line"><span class="keyword">if</span> lastErr != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"><span class="keyword">if</span> genericConfig.EgressSelector != <span class="literal">nil</span> {</span><br><span class="line">storageFactory.StorageConfig.Transport.EgressLookup = genericConfig.EgressSelector.Lookup</span><br><span class="line">}</span><br><span class="line"><span class="keyword">if</span> lastErr = s.Etcd.ApplyWithStorageFactoryTo(storageFactory, genericConfig); lastErr != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use protobufs for self-communication.</span></span><br><span class="line"><span class="comment">// Since not every generic apiserver has to support protobufs, we</span></span><br><span class="line"><span class="comment">// cannot default to it in generic apiserver and need to explicitly</span></span><br><span class="line"><span class="comment">// set it in kube-apiserver.</span></span><br><span class="line"><span class="comment">// 内部使用protobufs通信</span></span><br><span class="line">genericConfig.LoopbackClientConfig.ContentConfig.ContentType = <span class="string">"application/vnd.kubernetes.protobuf"</span></span><br><span class="line"><span class="comment">// Disable compression for self-communication, since we are going to be</span></span><br><span class="line"><span class="comment">// on a fast local network</span></span><br><span class="line">genericConfig.LoopbackClientConfig.DisableCompression = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// clientset初始化</span></span><br><span class="line">kubeClientConfig := genericConfig.LoopbackClientConfig</span><br><span class="line">clientgoExternalClient, err := clientgoclientset.NewForConfig(kubeClientConfig)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">lastErr = fmt.Errorf(<span class="string">"failed to create real external clientset: %v"</span>, err)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line">versionedInformers = clientgoinformers.NewSharedInformerFactory(clientgoExternalClient, <span class="number">10</span>*time.Minute)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化认证实例，支持多种认证方式：requestheader,token, tls等</span></span><br><span class="line">genericConfig.Authentication.Authenticator, genericConfig.OpenAPIConfig.SecurityDefinitions, err = BuildAuthenticator(s, genericConfig.EgressSelector, clientgoExternalClient, versionedInformers)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">lastErr = fmt.Errorf(<span class="string">"invalid authentication config: %v"</span>, err)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化鉴权配置</span></span><br><span class="line">genericConfig.Authorization.Authorizer, genericConfig.RuleResolver, err = BuildAuthorizer(s, genericConfig.EgressSelector, versionedInformers)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">lastErr = fmt.Errorf(<span class="string">"invalid authorization config: %v"</span>, err)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"><span class="keyword">if</span> !sets.NewString(s.Authorization.Modes...).Has(modes.ModeRBAC) {</span><br><span class="line">genericConfig.DisabledPostStartHooks.Insert(rbacrest.PostStartHookName)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化admission webhook的配置</span></span><br><span class="line">admissionConfig := &amp;kubeapiserveradmission.Config{</span><br><span class="line">ExternalInformers:    versionedInformers,</span><br><span class="line">LoopbackClientConfig: genericConfig.LoopbackClientConfig,</span><br><span class="line">CloudConfigFile:      s.CloudProvider.CloudConfigFile,</span><br><span class="line">}</span><br><span class="line">serviceResolver = buildServiceResolver(s.EnableAggregatorRouting, genericConfig.LoopbackClientConfig.Host, versionedInformers)</span><br><span class="line"></span><br><span class="line">authInfoResolverWrapper := webhook.NewDefaultAuthenticationInfoResolverWrapper(proxyTransport, genericConfig.EgressSelector, genericConfig.LoopbackClientConfig)</span><br><span class="line"></span><br><span class="line">lastErr = s.Audit.ApplyTo(</span><br><span class="line">genericConfig,</span><br><span class="line">genericConfig.LoopbackClientConfig,</span><br><span class="line">versionedInformers,</span><br><span class="line">serveroptions.NewProcessInfo(<span class="string">"kube-apiserver"</span>, <span class="string">"kube-system"</span>),</span><br><span class="line">&amp;serveroptions.WebhookOptions{</span><br><span class="line">AuthInfoResolverWrapper: authInfoResolverWrapper,</span><br><span class="line">ServiceResolver:         serviceResolver,</span><br><span class="line">},</span><br><span class="line">)</span><br><span class="line"><span class="keyword">if</span> lastErr != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化注入插件</span></span><br><span class="line">pluginInitializers, admissionPostStartHook, err = admissionConfig.New(proxyTransport, genericConfig.EgressSelector, serviceResolver)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">lastErr = fmt.Errorf(<span class="string">"failed to create admission plugin initializer: %v"</span>, err)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">err = s.Admission.ApplyTo(</span><br><span class="line">genericConfig,</span><br><span class="line">versionedInformers,</span><br><span class="line">kubeClientConfig,</span><br><span class="line">feature.DefaultFeatureGate,</span><br><span class="line">pluginInitializers...)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">lastErr = fmt.Errorf(<span class="string">"failed to initialize admission: %v"</span>, err)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> utilfeature.DefaultFeatureGate.Enabled(genericfeatures.APIPriorityAndFairness) &amp;&amp; s.GenericServerRunOptions.EnablePriorityAndFairness {</span><br><span class="line">genericConfig.FlowControl = BuildPriorityAndFairness(s, clientgoExternalClient, versionedInformers)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3 id="APIExtensionsServer初始化"><a href="#APIExtensionsServer初始化" class="headerlink" title="APIExtensionsServer初始化"></a>APIExtensionsServer初始化</h3><p><code>APIExtensionsServer</code>最先初始化，在调用链的末尾, 处理CR、CRD相关资源.</p><p>其中包含的 controller 以及功能如下所示：</p><ol><li>openapiController：将 crd 资源的变化同步至提供的 OpenAPI 文档，可通过访问 /openapi/v2 进行查看；</li><li>crdController：负责将 crd 信息注册到 apiVersions 和 apiResources 中，两者的信息可通过 $ kubectl api-versions 和 $ kubectl api-resources 查看；</li><li>namingController：检查 crd obj 中是否有命名冲突，可在 crd .status.conditions 中查看；</li><li>establishingController：检查 crd 是否处于正常状态，可在 crd .status.conditions 中查看；</li><li>nonStructuralSchemaController：检查 crd obj 结构是否正常，可在 crd .status.conditions 中查看；</li><li>apiApprovalController：检查 crd 是否遵循 kubernetes API 声明策略，可在 crd .status.conditions 中查看；</li><li>finalizingController：类似于 finalizes 的功能，与 CRs 的删除有关；</li></ol><p><code>createAPIExtensionsServer</code>调用<code>apiextensionsConfig.Complete().New(delegateAPIServer)</code></p><p><code>k8s.io/kubernetes/staging/src/k8s.io/apiextensions-apiserver/pkg/apiserver/apiserver.go:132</code><br></p><figure class="highlight golang"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line">/ New returns a <span class="built_in">new</span> instance of CustomResourceDefinitions from the given config.</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c completedConfig)</span> <span class="title">New</span><span class="params">(delegationTarget genericapiserver.DelegationTarget)</span> <span class="params">(*CustomResourceDefinitions, error)</span></span> {</span><br><span class="line"><span class="comment">// 初始化 genericServer</span></span><br><span class="line">genericServer, err := c.GenericConfig.New(<span class="string">"apiextensions-apiserver"</span>, delegationTarget)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">s := &amp;CustomResourceDefinitions{</span><br><span class="line">GenericAPIServer: genericServer,</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化apigroup, 即需要暴露的api，这里extension apiserver只注册了cr于crd相关的</span></span><br><span class="line">apiResourceConfig := c.GenericConfig.MergedResourceConfig</span><br><span class="line">apiGroupInfo := genericapiserver.NewDefaultAPIGroupInfo(apiextensions.GroupName, Scheme, metav1.ParameterCodec, Codecs)</span><br><span class="line"><span class="keyword">if</span> apiResourceConfig.VersionEnabled(v1beta1.SchemeGroupVersion) {</span><br><span class="line">storage := <span class="keyword">map</span>[<span class="keyword">string</span>]rest.Storage{}</span><br><span class="line"><span class="comment">// customresourcedefinitions</span></span><br><span class="line">customResourceDefintionStorage := customresourcedefinition.NewREST(Scheme, c.GenericConfig.RESTOptionsGetter)</span><br><span class="line">storage[<span class="string">"customresourcedefinitions"</span>] = customResourceDefintionStorage</span><br><span class="line">storage[<span class="string">"customresourcedefinitions/status"</span>] = customresourcedefinition.NewStatusREST(Scheme, customResourceDefintionStorage)</span><br><span class="line"></span><br><span class="line">apiGroupInfo.VersionedResourcesStorageMap[v1beta1.SchemeGroupVersion.Version] = storage</span><br><span class="line">}</span><br><span class="line"><span class="keyword">if</span> apiResourceConfig.VersionEnabled(v1.SchemeGroupVersion) {</span><br><span class="line">storage := <span class="keyword">map</span>[<span class="keyword">string</span>]rest.Storage{}</span><br><span class="line"><span class="comment">// customresourcedefinitions</span></span><br><span class="line">customResourceDefintionStorage := customresourcedefinition.NewREST(Scheme, c.GenericConfig.RESTOptionsGetter)</span><br><span class="line">storage[<span class="string">"customresourcedefinitions"</span>] = customResourceDefintionStorage</span><br><span class="line">storage[<span class="string">"customresourcedefinitions/status"</span>] = customresourcedefinition.NewStatusREST(Scheme, customResourceDefintionStorage)</span><br><span class="line"></span><br><span class="line">apiGroupInfo.VersionedResourcesStorageMap[v1.SchemeGroupVersion.Version] = storage</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册apigroup</span></span><br><span class="line"><span class="keyword">if</span> err := s.GenericAPIServer.InstallAPIGroup(&amp;apiGroupInfo); err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// clientset创建</span></span><br><span class="line">crdClient, err := clientset.NewForConfig(s.GenericAPIServer.LoopbackClientConfig)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="comment">// it's really bad that this is leaking here, but until we can fix the test (which I'm pretty sure isn't even testing what it wants to test),</span></span><br><span class="line"><span class="comment">// we need to be able to move forward</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">"failed to create clientset: %v"</span>, err)</span><br><span class="line">}</span><br><span class="line">s.Informers = externalinformers.NewSharedInformerFactory(crdClient, <span class="number">5</span>*time.Minute)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建各种handler</span></span><br><span class="line">delegateHandler := delegationTarget.UnprotectedHandler()</span><br><span class="line"><span class="keyword">if</span> delegateHandler == <span class="literal">nil</span> {</span><br><span class="line">delegateHandler = http.NotFoundHandler()</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">versionDiscoveryHandler := &amp;versionDiscoveryHandler{</span><br><span class="line">discovery: <span class="keyword">map</span>[schema.GroupVersion]*discovery.APIVersionHandler{},</span><br><span class="line">delegate:  delegateHandler,</span><br><span class="line">}</span><br><span class="line">groupDiscoveryHandler := &amp;groupDiscoveryHandler{</span><br><span class="line">discovery: <span class="keyword">map</span>[<span class="keyword">string</span>]*discovery.APIGroupHandler{},</span><br><span class="line">delegate:  delegateHandler,</span><br><span class="line">}</span><br><span class="line">establishingController := establish.NewEstablishingController(s.Informers.Apiextensions().V1().CustomResourceDefinitions(), crdClient.ApiextensionsV1())</span><br><span class="line">crdHandler, err := NewCustomResourceDefinitionHandler(</span><br><span class="line">versionDiscoveryHandler,</span><br><span class="line">groupDiscoveryHandler,</span><br><span class="line">s.Informers.Apiextensions().V1().CustomResourceDefinitions(),</span><br><span class="line">delegateHandler,</span><br><span class="line">c.ExtraConfig.CRDRESTOptionsGetter,</span><br><span class="line">c.GenericConfig.AdmissionControl,</span><br><span class="line">establishingController,</span><br><span class="line">c.ExtraConfig.ServiceResolver,</span><br><span class="line">c.ExtraConfig.AuthResolverWrapper,</span><br><span class="line">c.ExtraConfig.MasterCount,</span><br><span class="line">s.GenericAPIServer.Authorizer,</span><br><span class="line">c.GenericConfig.RequestTimeout,</span><br><span class="line">time.Duration(c.GenericConfig.MinRequestTimeout)*time.Second,</span><br><span class="line">apiGroupInfo.StaticOpenAPISpec,</span><br><span class="line">c.GenericConfig.MaxRequestBodyBytes,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line">s.GenericAPIServer.Handler.NonGoRestfulMux.Handle(<span class="string">"/apis"</span>, crdHandler)</span><br><span class="line">s.GenericAPIServer.Handler.NonGoRestfulMux.HandlePrefix(<span class="string">"/apis/"</span>, crdHandler)</span><br><span class="line"></span><br><span class="line">discoveryController := NewDiscoveryController(s.Informers.Apiextensions().V1().CustomResourceDefinitions(), versionDiscoveryHandler, groupDiscoveryHandler)</span><br><span class="line">namingController := status.NewNamingConditionController(s.Informers.Apiextensions().V1().CustomResourceDefinitions(), crdClient.ApiextensionsV1())</span><br><span class="line">nonStructuralSchemaController := nonstructuralschema.NewConditionController(s.Informers.Apiextensions().V1().CustomResourceDefinitions(), crdClient.ApiextensionsV1())</span><br><span class="line">apiApprovalController := apiapproval.NewKubernetesAPIApprovalPolicyConformantConditionController(s.Informers.Apiextensions().V1().CustomResourceDefinitions(), crdClient.ApiextensionsV1())</span><br><span class="line">finalizingController := finalizer.NewCRDFinalizer(</span><br><span class="line">s.Informers.Apiextensions().V1().CustomResourceDefinitions(),</span><br><span class="line">crdClient.ApiextensionsV1(),</span><br><span class="line">crdHandler,</span><br><span class="line">)</span><br><span class="line">openapiController := openapicontroller.NewController(s.Informers.Apiextensions().V1().CustomResourceDefinitions())</span><br><span class="line"></span><br><span class="line"><span class="comment">// 加入到启动hook中</span></span><br><span class="line">s.GenericAPIServer.AddPostStartHookOrDie(<span class="string">"start-apiextensions-informers"</span>, <span class="function"><span class="keyword">func</span><span class="params">(context genericapiserver.PostStartHookContext)</span> <span class="title">error</span></span> {</span><br><span class="line">s.Informers.Start(context.StopCh)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">})</span><br><span class="line">s.GenericAPIServer.AddPostStartHookOrDie(<span class="string">"start-apiextensions-controllers"</span>, <span class="function"><span class="keyword">func</span><span class="params">(context genericapiserver.PostStartHookContext)</span> <span class="title">error</span></span> {</span><br><span class="line"><span class="comment">// OpenAPIVersionedService and StaticOpenAPISpec are populated in generic apiserver PrepareRun().</span></span><br><span class="line"><span class="comment">// Together they serve the /openapi/v2 endpoint on a generic apiserver. A generic apiserver may</span></span><br><span class="line"><span class="comment">// choose to not enable OpenAPI by having null openAPIConfig, and thus OpenAPIVersionedService</span></span><br><span class="line"><span class="comment">// and StaticOpenAPISpec are both null. In that case we don't run the CRD OpenAPI controller.</span></span><br><span class="line"><span class="keyword">if</span> s.GenericAPIServer.OpenAPIVersionedService != <span class="literal">nil</span> &amp;&amp; s.GenericAPIServer.StaticOpenAPISpec != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">go</span> openapiController.Run(s.GenericAPIServer.StaticOpenAPISpec, s.GenericAPIServer.OpenAPIVersionedService, context.StopCh)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">go</span> namingController.Run(context.StopCh)</span><br><span class="line"><span class="keyword">go</span> establishingController.Run(context.StopCh)</span><br><span class="line"><span class="keyword">go</span> nonStructuralSchemaController.Run(<span class="number">5</span>, context.StopCh)</span><br><span class="line"><span class="keyword">go</span> apiApprovalController.Run(<span class="number">5</span>, context.StopCh)</span><br><span class="line"><span class="keyword">go</span> finalizingController.Run(<span class="number">5</span>, context.StopCh)</span><br><span class="line"></span><br><span class="line">discoverySyncedCh := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>{})</span><br><span class="line"><span class="keyword">go</span> discoveryController.Run(context.StopCh, discoverySyncedCh)</span><br><span class="line"><span class="keyword">select</span> {</span><br><span class="line"><span class="keyword">case</span> &lt;-context.StopCh:</span><br><span class="line"><span class="keyword">case</span> &lt;-discoverySyncedCh:</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">})</span><br><span class="line"><span class="comment">// we don't want to report healthy until we can handle all CRDs that have already been registered.  Waiting for the informer</span></span><br><span class="line"><span class="comment">// to sync makes sure that the lister will be valid before we begin.  There may still be races for CRDs added after startup,</span></span><br><span class="line"><span class="comment">// but we won't go healthy until we can handle the ones already present.</span></span><br><span class="line">s.GenericAPIServer.AddPostStartHookOrDie(<span class="string">"crd-informer-synced"</span>, <span class="function"><span class="keyword">func</span><span class="params">(context genericapiserver.PostStartHookContext)</span> <span class="title">error</span></span> {</span><br><span class="line"><span class="keyword">return</span> wait.PollImmediateUntil(<span class="number">100</span>*time.Millisecond, <span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="params">(<span class="keyword">bool</span>, error)</span></span> {</span><br><span class="line"><span class="keyword">return</span> s.Informers.Apiextensions().V1().CustomResourceDefinitions().Informer().HasSynced(), <span class="literal">nil</span></span><br><span class="line">}, context.StopCh)</span><br><span class="line">})</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> s, <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p><code>c.GenericConfig.New</code>来初始化<code>genericapiserver</code>,包裹一些默认链，创建handler<br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c completedConfig)</span> <span class="title">New</span><span class="params">(name <span class="keyword">string</span>, delegationTarget DelegationTarget)</span> <span class="params">(*GenericAPIServer, error)</span></span> {</span><br><span class="line"><span class="keyword">if</span> c.Serializer == <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">"Genericapiserver.New() called with config.Serializer == nil"</span>)</span><br><span class="line">}</span><br><span class="line"><span class="keyword">if</span> c.LoopbackClientConfig == <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">"Genericapiserver.New() called with config.LoopbackClientConfig == nil"</span>)</span><br><span class="line">}</span><br><span class="line"><span class="keyword">if</span> c.EquivalentResourceRegistry == <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">"Genericapiserver.New() called with config.EquivalentResourceRegistry == nil"</span>)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 包裹了DefaultBuildHandlerChain</span></span><br><span class="line">handlerChainBuilder := <span class="function"><span class="keyword">func</span><span class="params">(handler http.Handler)</span> <span class="title">http</span>.<span class="title">Handler</span></span> {</span><br><span class="line"><span class="keyword">return</span> c.BuildHandlerChainFunc(handler, c.Config)</span><br><span class="line">}</span><br><span class="line"><span class="comment">// 创建apiserverhandler</span></span><br><span class="line">apiServerHandler := NewAPIServerHandler(name, c.Serializer, handlerChainBuilder, delegationTarget.UnprotectedHandler())</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> s, <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p><code>APIServerHandler</code>包含多种<code>http.Handler</code>类型，包括<code>go-restful</code>以及<code>non-go-restful</code>，以及在以上两者之间选择的<code>Director</code>对象，<code>go-restful</code>用于处理已经注册的handler，<code>non-go-restful用来处理不存在的handler，API URI处理的选择过程为：</code>FullHandlerChain-&gt; Director -&gt;{GoRestfulContainer， NonGoRestfulMux}<code>。</code>NewAPIServerHandler`<br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">func NewAPIServerHandler(name string, s runtime.NegotiatedSerializer, handlerChainBuilder HandlerChainBuilderFn, notFoundHandler http.Handler) *APIServerHandler {</span><br><span class="line">// non-go-restful路由</span><br><span class="line">nonGoRestfulMux := mux.NewPathRecorderMux(name)</span><br><span class="line">if notFoundHandler != nil {</span><br><span class="line">nonGoRestfulMux.NotFoundHandler(notFoundHandler)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">// go-resetful路由</span><br><span class="line">gorestfulContainer := restful.NewContainer()</span><br><span class="line">gorestfulContainer.ServeMux = http.NewServeMux()</span><br><span class="line">gorestfulContainer.Router(restful.CurlyRouter{}) // e.g. for proxy/{kind}/{name}/{*}</span><br><span class="line">gorestfulContainer.RecoverHandler(func(panicReason interface{}, httpWriter http.ResponseWriter) {</span><br><span class="line">logStackOnRecover(s, panicReason, httpWriter)</span><br><span class="line">})</span><br><span class="line">gorestfulContainer.ServiceErrorHandler(func(serviceErr restful.ServiceError, request *restful.Request, response *restful.Response) {</span><br><span class="line">serviceErrorHandler(s, serviceErr, request, response)</span><br><span class="line">})</span><br><span class="line"></span><br><span class="line">// 选择器, 根据path选择是否执行go-restful，注册过的path执行go-restful</span><br><span class="line">director := director{</span><br><span class="line">name:               name,</span><br><span class="line">goRestfulContainer: gorestfulContainer,</span><br><span class="line">nonGoRestfulMux:    nonGoRestfulMux,</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">return &amp;APIServerHandler{</span><br><span class="line">FullHandlerChain:   handlerChainBuilder(director),</span><br><span class="line">GoRestfulContainer: gorestfulContainer,</span><br><span class="line">NonGoRestfulMux:    nonGoRestfulMux,</span><br><span class="line">Director:           director,</span><br><span class="line">}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>以上是<code>APIExtensionsServer</code>的初始化流程，初始化Server, 调用<code>s.GenericAPIServer.InstallAPIGroup</code>注册api。此方法的调用链非常深，主要是为了将需要暴露的<code>API Resource</code>注册到 server 中，以便能通过 http 接口进行 resource 的 REST 操作，其他几种 server 在初始化时也都会执行对应的 <code>InstallAPI</code>方法。</p><h3 id="KubeAPIServer初始化"><a href="#KubeAPIServer初始化" class="headerlink" title="KubeAPIServer初始化"></a>KubeAPIServer初始化</h3><p>KubeAPIServer 主要是提供对 API Resource 的操作请求，为 kubernetes 中众多 API 注册路由信息，暴露 RESTful API 并且对外提供 kubernetes service，使集群中以及集群外的服务都可以通过 RESTful API 操作 kubernetes 中的资源。</p><p>与<code>APIExtensionsServer</code>，<code>KubeAPIServer</code>初始化流程如下</p><ol><li><code>CreateKubeAPIServer</code>调用<code>kubeAPIServerConfig.Complete().New</code>来初始化</li><li><code>New</code>函数创建默认的<code>apigroup</code>(pod,deployment等内部资源), 调用<code>InstallAPIs</code>注册</li><li>启动相关controller, 加入到<code>poststarthook</code></li></ol><h3 id="AggregatorServer初始化"><a href="#AggregatorServer初始化" class="headerlink" title="AggregatorServer初始化"></a>AggregatorServer初始化</h3><p><code>Aggregator</code>通过<code>APIServices</code>对象关联到某个<code>Service</code>来进行请求的转发，其关联的<code>Service</code>类型进一步决定了请求转发形式。<code>Aggregator</code>包括一个<code>GenericAPIServer</code>和维护自身状态的<code>Controller</code>。其中 <code>GenericAPIServer</code>主要处理<code>apiregistration.k8s.io</code>组下的<code>APIService</code>资源请求。</p><p><code>Aggregator</code>除了处理资源请求外还包含几个controller：</p><ol><li>apiserviceRegistrationController：负责<code>APIServices</code>中资源的注册与删除；</li><li>availableConditionController：维护<code>APIServices</code>的可用状态，包括其引用<code>Service</code>是否可用等；</li><li>autoRegistrationController：用于保持API中存在的一组特定的<code>APIServices</code>；</li><li>crdRegistrationController：负责将<code>CRD GroupVersions</code>自动注册到<code>APIServices</code>中；</li><li>openAPIAggregationController：将<code>APIServices</code>资源的变化同步至提供的<code>OpenAPI</code>文档；<br>kubernetes中的一些附加组件，比如metrics-server就是通过Aggregator的方式进行扩展的，实际环境中可以通过使用apiserver-builder工具轻松以Aggregator的扩展方式创建自定义资源。</li></ol><p>初始化AggregatorServer的主要逻辑为：</p><ol><li>调用<code>aggregatorConfig.Complete().NewWithDelegate</code>创建<code>aggregatorServer</code></li><li>初始化<code>crdRegistrationController</code>和<code>autoRegistrationController</code>，<code>crdRegistrationController</code>负责注册CRD，<code>autoRegistrationController</code>负责将 CRD 对应的 APIServices自动注册到apiserver中，CRD 创建后可通过<code>$ kubectl get apiservices</code>查看是否注册到 apiservices中</li><li>将<code>autoRegistrationController</code>和<code>crdRegistrationController</code>加入到PostStartHook中</li></ol><p>首先，初始化配置<code>createAggregatorConfig</code><br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">createAggregatorConfig</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">kubeAPIServerConfig genericapiserver.Config,</span></span></span><br><span class="line"><span class="function"><span class="params">commandOptions *options.ServerRunOptions,</span></span></span><br><span class="line"><span class="function"><span class="params">externalInformers kubeexternalinformers.SharedInformerFactory,</span></span></span><br><span class="line"><span class="function"><span class="params">serviceResolver aggregatorapiserver.ServiceResolver,</span></span></span><br><span class="line"><span class="function"><span class="params">proxyTransport *http.Transport,</span></span></span><br><span class="line"><span class="function"><span class="params">pluginInitializers []admission.PluginInitializer,</span></span></span><br><span class="line"><span class="function"><span class="params">)</span> <span class="params">(*aggregatorapiserver.Config, error)</span></span> {</span><br><span class="line"><span class="comment">// make a shallow copy to let us twiddle a few things</span></span><br><span class="line"><span class="comment">// most of the config actually remains the same.  We only need to mess with a couple items related to the particulars of the aggregator</span></span><br><span class="line">genericConfig := kubeAPIServerConfig</span><br><span class="line">genericConfig.PostStartHooks = <span class="keyword">map</span>[<span class="keyword">string</span>]genericapiserver.PostStartHookConfigEntry{}</span><br><span class="line">genericConfig.RESTOptionsGetter = <span class="literal">nil</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// override genericConfig.AdmissionControl with kube-aggregator's scheme,</span></span><br><span class="line"><span class="comment">// because aggregator apiserver should use its own scheme to convert its own resources.</span></span><br><span class="line"><span class="comment">// 取消admission的配置，aggregator自行处理请求，不需要admissions</span></span><br><span class="line">err := commandOptions.Admission.ApplyTo(</span><br><span class="line">&amp;genericConfig,</span><br><span class="line">externalInformers,</span><br><span class="line">genericConfig.LoopbackClientConfig,</span><br><span class="line">feature.DefaultFeatureGate,</span><br><span class="line">pluginInitializers...)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// copy the etcd options so we don't mutate originals.</span></span><br><span class="line">etcdOptions := *commandOptions.Etcd</span><br><span class="line">etcdOptions.StorageConfig.Paging = utilfeature.DefaultFeatureGate.Enabled(features.APIListChunking)</span><br><span class="line">etcdOptions.StorageConfig.Codec = aggregatorscheme.Codecs.LegacyCodec(v1beta1.SchemeGroupVersion, v1.SchemeGroupVersion)</span><br><span class="line">etcdOptions.StorageConfig.EncodeVersioner = runtime.NewMultiGroupVersioner(v1beta1.SchemeGroupVersion, schema.GroupKind{Group: v1beta1.GroupName})</span><br><span class="line">genericConfig.RESTOptionsGetter = &amp;genericoptions.SimpleRestOptionsFactory{Options: etcdOptions}</span><br><span class="line"></span><br><span class="line"><span class="comment">// override MergedResourceConfig with aggregator defaults and registry</span></span><br><span class="line"><span class="keyword">if</span> err := commandOptions.APIEnablement.ApplyTo(</span><br><span class="line">&amp;genericConfig,</span><br><span class="line">aggregatorapiserver.DefaultAPIResourceConfigSource(),</span><br><span class="line">aggregatorscheme.Scheme); err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 配置proxy证书，用于apiserver与扩展服务的通信，使用requestheader证书签发</span></span><br><span class="line"><span class="keyword">var</span> certBytes, keyBytes []<span class="keyword">byte</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(commandOptions.ProxyClientCertFile) &gt; <span class="number">0</span> &amp;&amp; <span class="built_in">len</span>(commandOptions.ProxyClientKeyFile) &gt; <span class="number">0</span> {</span><br><span class="line">certBytes, err = ioutil.ReadFile(commandOptions.ProxyClientCertFile)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line">keyBytes, err = ioutil.ReadFile(commandOptions.ProxyClientKeyFile)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">aggregatorConfig := &amp;aggregatorapiserver.Config{</span><br><span class="line">GenericConfig: &amp;genericapiserver.RecommendedConfig{</span><br><span class="line">Config:                genericConfig,</span><br><span class="line">SharedInformerFactory: externalInformers,</span><br><span class="line">},</span><br><span class="line">ExtraConfig: aggregatorapiserver.ExtraConfig{</span><br><span class="line">ProxyClientCert: certBytes,</span><br><span class="line">ProxyClientKey:  keyBytes,</span><br><span class="line">ServiceResolver: serviceResolver,</span><br><span class="line"><span class="comment">// 代理请求的具体实现</span></span><br><span class="line">ProxyTransport:  proxyTransport,</span><br><span class="line">},</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// we need to clear the poststarthooks so we don't add them multiple times to all the servers (that fails)</span></span><br><span class="line"><span class="comment">// 加入PostStartHook</span></span><br><span class="line">aggregatorConfig.GenericConfig.PostStartHooks = <span class="keyword">map</span>[<span class="keyword">string</span>]genericapiserver.PostStartHookConfigEntry{}</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> aggregatorConfig, <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p><code>createAggregatorServer</code>初始化<code>Aggregator</code><br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">createAggregatorServer</span><span class="params">(aggregatorConfig *aggregatorapiserver.Config, delegateAPIServer genericapiserver.DelegationTarget, apiExtensionInformers apiextensionsinformers.SharedInformerFactory)</span> <span class="params">(*aggregatorapiserver.APIAggregator, error)</span></span> {</span><br><span class="line"><span class="comment">// 初始化配置，与前面流程相同</span></span><br><span class="line">aggregatorServer, err := aggregatorConfig.Complete().NewWithDelegate(delegateAPIServer)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建auto-registration controller</span></span><br><span class="line">apiRegistrationClient, err := apiregistrationclient.NewForConfig(aggregatorConfig.GenericConfig.LoopbackClientConfig)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line">autoRegistrationController := autoregister.NewAutoRegisterController(aggregatorServer.APIRegistrationInformers.Apiregistration().V1().APIServices(), apiRegistrationClient)</span><br><span class="line">apiServices := apiServicesToRegister(delegateAPIServer, autoRegistrationController)</span><br><span class="line">crdRegistrationController := crdregistration.NewCRDRegistrationController(</span><br><span class="line">apiExtensionInformers.Apiextensions().V1().CustomResourceDefinitions(),</span><br><span class="line">autoRegistrationController)</span><br><span class="line"></span><br><span class="line">err = aggregatorServer.GenericAPIServer.AddPostStartHook(<span class="string">"kube-apiserver-autoregistration"</span>, <span class="function"><span class="keyword">func</span><span class="params">(context genericapiserver.PostStartHookContext)</span> <span class="title">error</span></span> {</span><br><span class="line"><span class="comment">// 启动controller</span></span><br><span class="line"><span class="keyword">go</span> crdRegistrationController.Run(<span class="number">5</span>, context.StopCh)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> {</span><br><span class="line"><span class="comment">// let the CRD controller process the initial set of CRDs before starting the autoregistration controller.</span></span><br><span class="line"><span class="comment">// this prevents the autoregistration controller's initial sync from deleting APIServices for CRDs that still exist.</span></span><br><span class="line"><span class="comment">// we only need to do this if CRDs are enabled on this server.  We can't use discovery because we are the source for discovery.</span></span><br><span class="line"><span class="keyword">if</span> aggregatorConfig.GenericConfig.MergedResourceConfig.AnyVersionForGroupEnabled(<span class="string">"apiextensions.k8s.io"</span>) {</span><br><span class="line">crdRegistrationController.WaitForInitialSync()</span><br><span class="line">}</span><br><span class="line">autoRegistrationController.Run(<span class="number">5</span>, context.StopCh)</span><br><span class="line">}()</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">})</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">err = aggregatorServer.GenericAPIServer.AddBootSequenceHealthChecks(</span><br><span class="line">makeAPIServiceAvailableHealthCheck(</span><br><span class="line"><span class="string">"autoregister-completion"</span>,</span><br><span class="line">apiServices,</span><br><span class="line">aggregatorServer.APIRegistrationInformers.Apiregistration().V1().APIServices(),</span><br><span class="line">),</span><br><span class="line">)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> aggregatorServer, <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>至此，启动步骤以前分析完了，三个组件的流量大体时一样的，通过<code>Complete().New()</code>初始化配置，创建所需的controller, 调用<code>InstallAPIGroup</code>注册<code>apigroup</code>。</p><h2 id="请求分析"><a href="#请求分析" class="headerlink" title="请求分析"></a>请求分析</h2><p>上面我们分析了apiserver的调用链，大体如下<br><code>DefaultHandlerChain-&gt;{handler/crdhandler/proxy}-&gt;admission-&gt;validation-&gt;etcd</code></p><ol><li>请求进入时，会经过<code>defaultchain</code>做一些认证鉴权工作</li><li>然后通过<code>route</code>执行对应的handler，如果为aggration api, 将直接转发请求到对应service</li><li>handler处理完，经过admission与validation，做一些修改和检查，用户在这部分可以自定义webhook</li><li>最后存入etcd</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文大体对apiserver的启动流程，以及初始化过程做了分析，由于apiserver实现复杂，中间一些细节没涉及到，还需要对着代码研究研究。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] <a href="https://juejin.im/post/5c934e5a5188252d7c216981" target="_blank" rel="noopener">https://juejin.im/post/5c934e5a5188252d7c216981</a><br>[2] <a href="https://blog.tianfeiyu.com/2020/02/24/kube_apiserver/" target="_blank" rel="noopener">https://blog.tianfeiyu.com/2020/02/24/kube_apiserver/</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;kube-apiserver 共由 3 个组件构成（Aggregator. KubeAPIServer. APIExtensionServer），这些组件依次通过 Delegation 处理请求：&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="apiserver" scheme="https://qingwave.github.io/tags/apiserver/"/>
    
  </entry>
  
  <entry>
    <title>kube-apiserver鉴权源码分析</title>
    <link href="https://qingwave.github.io/kube-apiserver-authorization-code/"/>
    <id>https://qingwave.github.io/kube-apiserver-authorization-code/</id>
    <published>2020-04-23T08:54:14.000Z</published>
    <updated>2020-04-25T07:01:42.755Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>kube-apiserver中与权限相关的主要有三种机制，即认证、鉴权和准入控制。上节讲到<a href="./kube-apiserver-authentication-code.md">认证流程</a>。</p><p>认证与授权很容易混淆：</p><ul><li>认证(Authentication), 负责检查你是谁，识别user</li><li>授权(Authorization), 你能做什么，是否允许User对资源的操作</li><li>审计(Audit), 负责记录操作信息，方便后续审查</li></ul><p>本文主要分析apiserver的rbac授权流程。</p><h2 id="认证流程分析"><a href="#认证流程分析" class="headerlink" title="认证流程分析"></a>认证流程分析</h2><p>权限相关代码从<code>k8s.io/apiserver/pkg/server/config.go</code>中<code>DefaultBuildHandlerChain</code>函数开始执行</p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DefaultBuildHandlerChain</span><span class="params">(apiHandler http.Handler, c *Config)</span> <span class="title">http</span>.<span class="title">Handler</span></span> {</span><br><span class="line">handler := genericapifilters.WithAuthorization(apiHandler, c.Authorization.Authorizer, c.Serializer)</span><br><span class="line">handler = genericfilters.WithMaxInFlightLimit(handler, c.MaxRequestsInFlight, c.MaxMutatingRequestsInFlight, c.LongRunningFunc)</span><br><span class="line">handler = genericapifilters.WithImpersonation(handler, c.Authorization.Authorizer, c.Serializer)</span><br><span class="line">handler = genericapifilters.WithAudit(handler, c.AuditBackend, c.AuditPolicyChecker, c.LongRunningFunc)</span><br><span class="line">failedHandler := genericapifilters.Unauthorized(c.Serializer, c.Authentication.SupportsBasicAuth)</span><br><span class="line">failedHandler = genericapifilters.WithFailedAuthenticationAudit(failedHandler, c.AuditBackend, c.AuditPolicyChecker)</span><br><span class="line">handler = genericapifilters.WithAuthentication(handler, c.Authentication.Authenticator, failedHandler, c.Authentication.APIAudiences)</span><br><span class="line">handler = genericfilters.WithCORS(handler, c.CorsAllowedOriginList, <span class="literal">nil</span>, <span class="literal">nil</span>, <span class="literal">nil</span>, <span class="string">"true"</span>)</span><br><span class="line">handler = genericfilters.WithTimeoutForNonLongRunningRequests(handler, c.LongRunningFunc, c.RequestTimeout)</span><br><span class="line">handler = genericfilters.WithWaitGroup(handler, c.LongRunningFunc, c.HandlerChainWaitGroup)</span><br><span class="line">handler = genericapifilters.WithRequestInfo(handler, c.RequestInfoResolver)</span><br><span class="line">handler = genericfilters.WithPanicRecovery(handler)</span><br><span class="line"><span class="keyword">return</span> handler</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p><code>DefaultBuildHandlerChain</code>中包含了多种filter（如认证，链接数检验，RBAC权限检验等），授权步骤在<code>WithAuthorization</code>中，如下：</p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// WithAuthorizationCheck passes all authorized requests on to handler, and returns a forbidden error otherwise.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithAuthorization</span><span class="params">(handler http.Handler, a authorizer.Authorizer, s runtime.NegotiatedSerializer)</span> <span class="title">http</span>.<span class="title">Handler</span></span> {</span><br><span class="line"><span class="comment">// 检查是否需要权限校验</span></span><br><span class="line"><span class="keyword">if</span> a == <span class="literal">nil</span> {</span><br><span class="line">klog.Warningf(<span class="string">"Authorization is disabled"</span>)</span><br><span class="line"><span class="keyword">return</span> handler</span><br><span class="line">}</span><br><span class="line"><span class="keyword">return</span> http.HandlerFunc(<span class="function"><span class="keyword">func</span><span class="params">(w http.ResponseWriter, req *http.Request)</span></span> {</span><br><span class="line">ctx := req.Context()</span><br><span class="line"><span class="comment">// 用作审计</span></span><br><span class="line">ae := request.AuditEventFrom(ctx)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取Attribute, 通过reqeust获取到请求的user, resource, verb, 是否为namespace级别的等</span></span><br><span class="line">attributes, err := GetAuthorizerAttributes(ctx)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">responsewriters.InternalError(w, req, err)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"><span class="comment">// 执行认证流程</span></span><br><span class="line">authorized, reason, err := a.Authorize(ctx, attributes)</span><br><span class="line"><span class="comment">// an authorizer like RBAC could encounter evaluation errors and still allow the request, so authorizer decision is checked before error here.</span></span><br><span class="line"><span class="keyword">if</span> authorized == authorizer.DecisionAllow {</span><br><span class="line">audit.LogAnnotation(ae, decisionAnnotationKey, decisionAllow)</span><br><span class="line">audit.LogAnnotation(ae, reasonAnnotationKey, reason)</span><br><span class="line"><span class="comment">// 校验成功，记录信息，转到下一个handler</span></span><br><span class="line">handler.ServeHTTP(w, req)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">audit.LogAnnotation(ae, reasonAnnotationKey, reasonError)</span><br><span class="line">responsewriters.InternalError(w, req, err)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 校验失败返回403，注意认证失败返回的是401</span></span><br><span class="line">klog.V(<span class="number">4</span>).Infof(<span class="string">"Forbidden: %#v, Reason: %q"</span>, req.RequestURI, reason)</span><br><span class="line">audit.LogAnnotation(ae, decisionAnnotationKey, decisionForbid)</span><br><span class="line">audit.LogAnnotation(ae, reasonAnnotationKey, reason)</span><br><span class="line">responsewriters.Forbidden(ctx, attributes, w, req, reason, s)</span><br><span class="line">})</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>授权流程比较清晰，从request获取请求信息，进行鉴权，成功进入后续handler，失败返回403。</p><p><code>Authorize</code>接口有多种实现，通过在apiserver配置<code>--authorization-mode</code>选择鉴权模式，包括：</p><ul><li>ABAC</li><li>RBAC</li><li>Node, 用于kubelet鉴权exec/logs等</li><li>AlwaysAllow</li><li>AlwaysDeny</li><li>Webhook， 用于扩展权限，用户可实现Webhook与其他权限系统集成</li></ul><p>如果选择<code>AlwaysAllow</code>,即不做鉴权, 开启后强制不允许匿名用户<br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ApplyAuthorization will conditionally modify the authentication options based on the authorization options</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(o *BuiltInAuthenticationOptions)</span> <span class="title">ApplyAuthorization</span><span class="params">(authorization *BuiltInAuthorizationOptions)</span></span> {</span><br><span class="line"><span class="keyword">if</span> o == <span class="literal">nil</span> || authorization == <span class="literal">nil</span> || o.Anonymous == <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// authorization ModeAlwaysAllow cannot be combined with AnonymousAuth.</span></span><br><span class="line"><span class="comment">// in such a case the AnonymousAuth is stomped to false and you get a message</span></span><br><span class="line"><span class="keyword">if</span> o.Anonymous.Allow &amp;&amp; sets.NewString(authorization.Modes...).Has(authzmodes.ModeAlwaysAllow) {</span><br><span class="line">klog.Warningf(<span class="string">"AnonymousAuth is not allowed with the AlwaysAllow authorizer. Resetting AnonymousAuth to false. You should use a different authorizer"</span>)</span><br><span class="line">o.Anonymous.Allow = <span class="literal">false</span></span><br><span class="line">}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><h2 id="rbac鉴权"><a href="#rbac鉴权" class="headerlink" title="rbac鉴权"></a>rbac鉴权</h2><p>rbac是常用的鉴权方式，实现<code>Authorize</code>接口, 代码在<a href="https://github.com/kubernetes/kubernetes/blob/92eb072989eba22236d034b56cc2bf159dfb4915/plugin/pkg/auth/authorizer/rbac/rbac.go#L75" target="_blank" rel="noopener">rbac.go</a><br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *RBACAuthorizer)</span> <span class="title">Authorize</span><span class="params">(ctx context.Context, requestAttributes authorizer.Attributes)</span> <span class="params">(authorizer.Decision, <span class="keyword">string</span>, error)</span></span> {</span><br><span class="line">ruleCheckingVisitor := &amp;authorizingVisitor{requestAttributes: requestAttributes}</span><br><span class="line"><span class="comment">// 调用VisitRulesFor来检查是否用权限</span></span><br><span class="line">r.authorizationRuleResolver.VisitRulesFor(requestAttributes.GetUser(), requestAttributes.GetNamespace(), ruleCheckingVisitor.visit)</span><br><span class="line"><span class="keyword">if</span> ruleCheckingVisitor.allowed {</span><br><span class="line"><span class="comment">// 成功直接返回</span></span><br><span class="line"><span class="keyword">return</span> authorizer.DecisionAllow, ruleCheckingVisitor.reason, <span class="literal">nil</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// 失败，打印日志返回失败原因</span></span><br><span class="line"><span class="comment">// Build a detailed log of the denial.</span></span><br><span class="line"><span class="comment">// Make the whole block conditional so we don't do a lot of string-building we won't use.</span></span><br><span class="line"><span class="keyword">if</span> klog.V(<span class="number">5</span>) {</span><br><span class="line"><span class="keyword">var</span> operation <span class="keyword">string</span></span><br><span class="line"><span class="keyword">if</span> requestAttributes.IsResourceRequest() {</span><br><span class="line">b := &amp;bytes.Buffer{}</span><br><span class="line">b.WriteString(<span class="string">`"`</span>)</span><br><span class="line">b.WriteString(requestAttributes.GetVerb())</span><br><span class="line">b.WriteString(<span class="string">`" resource "`</span>)</span><br><span class="line">b.WriteString(requestAttributes.GetResource())</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(requestAttributes.GetAPIGroup()) &gt; <span class="number">0</span> {</span><br><span class="line">b.WriteString(<span class="string">`.`</span>)</span><br><span class="line">b.WriteString(requestAttributes.GetAPIGroup())</span><br><span class="line">}</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(requestAttributes.GetSubresource()) &gt; <span class="number">0</span> {</span><br><span class="line">b.WriteString(<span class="string">`/`</span>)</span><br><span class="line">b.WriteString(requestAttributes.GetSubresource())</span><br><span class="line">}</span><br><span class="line">b.WriteString(<span class="string">`"`</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(requestAttributes.GetName()) &gt; <span class="number">0</span> {</span><br><span class="line">b.WriteString(<span class="string">` named "`</span>)</span><br><span class="line">b.WriteString(requestAttributes.GetName())</span><br><span class="line">b.WriteString(<span class="string">`"`</span>)</span><br><span class="line">}</span><br><span class="line">operation = b.String()</span><br><span class="line">} <span class="keyword">else</span> {</span><br><span class="line">operation = fmt.Sprintf(<span class="string">"%q nonResourceURL %q"</span>, requestAttributes.GetVerb(), requestAttributes.GetPath())</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> scope <span class="keyword">string</span></span><br><span class="line"><span class="keyword">if</span> ns := requestAttributes.GetNamespace(); <span class="built_in">len</span>(ns) &gt; <span class="number">0</span> {</span><br><span class="line">scope = fmt.Sprintf(<span class="string">"in namespace %q"</span>, ns)</span><br><span class="line">} <span class="keyword">else</span> {</span><br><span class="line">scope = <span class="string">"cluster-wide"</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">klog.Infof(<span class="string">"RBAC DENY: user %q groups %q cannot %s %s"</span>, requestAttributes.GetUser().GetName(), requestAttributes.GetUser().GetGroups(), operation, scope)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">reason := <span class="string">""</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(ruleCheckingVisitor.errors) &gt; <span class="number">0</span> {</span><br><span class="line">reason = fmt.Sprintf(<span class="string">"RBAC: %v"</span>, utilerrors.NewAggregate(ruleCheckingVisitor.errors))</span><br><span class="line">}</span><br><span class="line"><span class="keyword">return</span> authorizer.DecisionNoOpinion, reason, <span class="literal">nil</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p><code>Authorize</code>调用了<code>VisitRulesFor</code>来处理具体鉴权操作, 代码在<a href="https://github.com/kubernetes/kubernetes/blob/81e9f21f832f88422f1ccf5b8aa90de7cf822132/pkg/registry/rbac/validation/rule.go#L178" target="_blank" rel="noopener">rule.go</a><br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *DefaultRuleResolver)</span> <span class="title">VisitRulesFor</span><span class="params">(user user.Info, namespace <span class="keyword">string</span>, visitor <span class="keyword">func</span>(source fmt.Stringer, rule *rbacv1.PolicyRule, err error)</span> <span class="title">bool</span>)</span> {</span><br><span class="line"><span class="comment">// 获取所有clusterrolebinding</span></span><br><span class="line"><span class="keyword">if</span> clusterRoleBindings, err := r.clusterRoleBindingLister.ListClusterRoleBindings(); err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">if</span> !visitor(<span class="literal">nil</span>, <span class="literal">nil</span>, err) {</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line">} <span class="keyword">else</span> {</span><br><span class="line">sourceDescriber := &amp;clusterRoleBindingDescriber{}</span><br><span class="line"><span class="comment">// 遍历clusterrolebing</span></span><br><span class="line"><span class="keyword">for</span> _, clusterRoleBinding := <span class="keyword">range</span> clusterRoleBindings {</span><br><span class="line"><span class="comment">// 检查是否有对应的user</span></span><br><span class="line">subjectIndex, applies := appliesTo(user, clusterRoleBinding.Subjects, <span class="string">""</span>)</span><br><span class="line"><span class="keyword">if</span> !applies {</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">}</span><br><span class="line"><span class="comment">// 如果user存在于subject, 获取对应的rules即clusterrole</span></span><br><span class="line">rules, err := r.GetRoleReferenceRules(clusterRoleBinding.RoleRef, <span class="string">""</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">if</span> !visitor(<span class="literal">nil</span>, <span class="literal">nil</span>, err) {</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">}</span><br><span class="line">sourceDescriber.binding = clusterRoleBinding</span><br><span class="line">sourceDescriber.subject = &amp;clusterRoleBinding.Subjects[subjectIndex]</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> rules {</span><br><span class="line"><span class="comment">// 调用visitor判断是否需要进入下一步鉴权</span></span><br><span class="line"><span class="keyword">if</span> !visitor(sourceDescriber, &amp;rules[i], <span class="literal">nil</span>) {</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// clusterrole遍历完还没有鉴权成功，接着遍历所在namespace的role，流程同上</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(namespace) &gt; <span class="number">0</span> {</span><br><span class="line"><span class="keyword">if</span> roleBindings, err := r.roleBindingLister.ListRoleBindings(namespace); err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">if</span> !visitor(<span class="literal">nil</span>, <span class="literal">nil</span>, err) {</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line">} <span class="keyword">else</span> {</span><br><span class="line">sourceDescriber := &amp;roleBindingDescriber{}</span><br><span class="line"><span class="keyword">for</span> _, roleBinding := <span class="keyword">range</span> roleBindings {</span><br><span class="line">subjectIndex, applies := appliesTo(user, roleBinding.Subjects, namespace)</span><br><span class="line"><span class="keyword">if</span> !applies {</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">}</span><br><span class="line">rules, err := r.GetRoleReferenceRules(roleBinding.RoleRef, namespace)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line"><span class="keyword">if</span> !visitor(<span class="literal">nil</span>, <span class="literal">nil</span>, err) {</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">}</span><br><span class="line">sourceDescriber.binding = roleBinding</span><br><span class="line">sourceDescriber.subject = &amp;roleBinding.Subjects[subjectIndex]</span><br><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> rules {</span><br><span class="line"><span class="keyword">if</span> !visitor(sourceDescriber, &amp;rules[i], <span class="literal">nil</span>) {</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p><code>visit</code>函数, 用来判断是否认证成功，成功返回<code>false</code>, 不需要进行下一步鉴权<br></p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v *authorizingVisitor)</span> <span class="title">visit</span><span class="params">(source fmt.Stringer, rule *rbacv1.PolicyRule, err error)</span> <span class="title">bool</span></span> {</span><br><span class="line"><span class="keyword">if</span> rule != <span class="literal">nil</span> &amp;&amp; RuleAllows(v.requestAttributes, rule) {</span><br><span class="line"><span class="comment">// allowed用来表示是否认证成功</span></span><br><span class="line">v.allowed = <span class="literal">true</span></span><br><span class="line">v.reason = fmt.Sprintf(<span class="string">"RBAC: allowed by %s"</span>, source.String())</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">}</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> {</span><br><span class="line">v.errors = <span class="built_in">append</span>(v.errors, err)</span><br><span class="line">}</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>rbac的鉴权流程如下:</p><ol><li>通过<code>Request</code>获取<code>Attribute</code>包括用户，资源和对应的操作</li><li><code>Authorize</code>调用<code>VisitRulesFor</code>进行具体的鉴权</li><li>获取所有的ClusterRoleBindings，并对其进行遍历操作</li><li>根据请求User信息，判断该是否被绑定在该ClusterRoleBinding中</li><li>若在将通过函数<code>GetRoleReferenceRules()</code>获取绑定的Role所控制的访问的资源</li><li>将Role所控制的访问的资源，与从API请求中提取出的资源进行比对，若比对成功，即为API请求的调用者有权访问相关资源</li><li>遍历ClusterRoleBinding中，都没有获得鉴权成功的操作，将会判断提取出的信息中是否包括了namespace的信息，若包括了，将会获取该namespace下的所有RoleBindings，类似ClusterRoleBindings</li><li>若在遍历了所有CluterRoleBindings，及该namespace下的所有RoleBingdings之后，仍没有对资源比对成功，则可判断该API请求的调用者没有权限访问相关资源, 鉴权失败</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文结合RBAC分析了Kubernetes的鉴权流程，整体这部分比较代码清晰。RBAC是Kubernetes比较推荐的鉴权方式，了解完整个流程后，居然所有请求都会先遍历一遍ClusterRoleBindings，这样实现起来比较简单，但随着规模和用户的扩大，这部分是否会有性能问题，需不需要实现能够快速鉴权的方式。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;kube-apiserver中与权限相关的主要有三种机制，即认证、鉴权和准入控制。上节讲到&lt;a href=&quot;./kube-apiserver-authentication-code.md&quot;&gt;认证流程&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="rbac" scheme="https://qingwave.github.io/tags/rbac/"/>
    
  </entry>
  
  <entry>
    <title>多端口服务的Ingress IP-hash问题</title>
    <link href="https://qingwave.github.io/ingress-ip-hash/"/>
    <id>https://qingwave.github.io/ingress-ip-hash/</id>
    <published>2020-04-15T07:47:09.000Z</published>
    <updated>2020-04-25T03:24:29.432Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>业务反馈使用Ingress的ip-hash, 同一个服务开启了http和websocket分别是两个端口, 但是配置ip-hash后, 同一个client的请求http和websocket不在同一个后端.</p><h2 id="探究"><a href="#探究" class="headerlink" title="探究"></a>探究</h2><p>根据业务Ingress配置,配置如下实例:<br></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/cors-allow-origin:</span> <span class="string">'*'</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/enable-cors:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/proxy-body-size:</span> <span class="number">200</span><span class="string">m</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/proxy-read-timeout:</span> <span class="string">"300"</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/upstream-hash-by:</span> <span class="string">$binary_remote_addr</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">hellogo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  rules:</span></span><br><span class="line"><span class="attr">  - host:</span> <span class="string">hellogo.d.xiaomi.net</span></span><br><span class="line"><span class="attr">    http:</span></span><br><span class="line"><span class="attr">      paths:</span></span><br><span class="line"><span class="attr">      - backend:</span></span><br><span class="line"><span class="attr">          serviceName:</span> <span class="string">hellogo</span> <span class="comment">#http1, 8080</span></span><br><span class="line"><span class="attr">          servicePort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">        path:</span> <span class="string">/8080</span></span><br><span class="line"><span class="attr">      - backend:</span></span><br><span class="line"><span class="attr">          serviceName:</span> <span class="string">hellogo</span> <span class="comment">#http2, 9090</span></span><br><span class="line"><span class="attr">          servicePort:</span> <span class="number">9090</span></span><br><span class="line"><span class="attr">        path:</span> <span class="string">/9090</span></span><br><span class="line"><span class="attr">      - backend:</span></span><br><span class="line"><span class="attr">          serviceName:</span> <span class="string">hellogo</span> <span class="comment">#websocket, 8081</span></span><br><span class="line"><span class="attr">          servicePort:</span> <span class="number">8081</span></span><br><span class="line"><span class="attr">        path:</span> <span class="string">/ws</span></span><br></pre></td></tr></tbody></table></figure><p></p><p>创建多个副本<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get po -l app=hellogo</span><br><span class="line">NAME                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">hellogo-699f997454-b5vs4   1/1     Running   0          66m</span><br><span class="line">hellogo-699f997454-hm924   1/1     Running   0          66m</span><br><span class="line">hellogo-699f997454-mfbqv   1/1     Running   0          66m</span><br><span class="line">hellogo-699f997454-qdrwn   1/1     Running   0          66m</span><br><span class="line">hellogo-699f997454-srh9b   1/1     Running   0          66m</span><br><span class="line">hellogo-699f997454-wlwfh   1/1     Running   0          66m</span><br></pre></td></tr></tbody></table></figure><p></p><p>测试http 8080端口, 请求到pod hellogo-699f997454-qdrwn<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ curl http://hellogo.d.xiaomi.net/8080</span><br><span class="line">hello 8080!</span><br><span class="line">host hellogo.d.xiaomi.net</span><br><span class="line">remoteaddr 10.46.23.1:15340</span><br><span class="line">realip 10.232.41.102</span><br><span class="line">hostname hellogo-699f997454-qdrwn </span><br><span class="line"></span><br><span class="line">$ curl http://hellogo.d.xiaomi.net/8080</span><br><span class="line">hello 8080!</span><br><span class="line">host hellogo.d.xiaomi.net</span><br><span class="line">remoteaddr 10.46.23.1:15866</span><br><span class="line">realip 10.232.41.102</span><br><span class="line">hostname hellogo-699f997454-qdrwn</span><br></pre></td></tr></tbody></table></figure><p></p><p>测试http 8080端口, 请求到pod hellogo-699f997454-b5vs4<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ curl http://hellogo.d.xiaomi.net/9090</span><br><span class="line">hello 9090!</span><br><span class="line">host hellogo.d.xiaomi.net</span><br><span class="line">remoteaddr 10.38.200.195:23706</span><br><span class="line">realip 10.232.41.102</span><br><span class="line">hostname hellogo-699f997454-b5vs4</span><br><span class="line"></span><br><span class="line">$ curl http://hellogo.d.xiaomi.net/9090</span><br><span class="line">hello 9090!</span><br><span class="line">host hellogo.d.xiaomi.net</span><br><span class="line">remoteaddr 10.38.200.195:23706</span><br><span class="line">realip 10.232.41.102</span><br><span class="line">hostname hellogo-699f997454-b5vs4</span><br></pre></td></tr></tbody></table></figure><p></p><p>猜想是由于获取的nginx server列表顺序不一致导致的, 但是看源码ip list是直接从endpoint获取的, 进入nginx-ingress查看<br></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="built_in">exec</span> -it -n kube-system nginx-ingress-controller-m496n sh</span><br><span class="line"><span class="comment"># dbg工具查看nginx后端列表</span></span><br><span class="line">/etc/nginx $ /dbg backends list | grep hellogo</span><br><span class="line">default-hellogo-8080</span><br><span class="line">default-hellogo-8081</span><br><span class="line">default-hellogo-9090</span><br><span class="line"><span class="comment"># 8080端口的列表</span></span><br><span class="line">/etc/nginx $ /dbg backends get default-hellogo-8080</span><br><span class="line">{</span><br><span class="line">  <span class="string">"endpoints"</span>: [</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"address"</span>: <span class="string">"10.46.12.107"</span>,</span><br><span class="line">      <span class="string">"port"</span>: <span class="string">"8080"</span></span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"address"</span>: <span class="string">"10.46.12.108"</span>,</span><br><span class="line">      <span class="string">"port"</span>: <span class="string">"8080"</span></span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"address"</span>: <span class="string">"10.46.12.109"</span>,</span><br><span class="line">      <span class="string">"port"</span>: <span class="string">"8080"</span></span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"address"</span>: <span class="string">"10.46.23.23"</span>,</span><br><span class="line">      <span class="string">"port"</span>: <span class="string">"8080"</span></span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"address"</span>: <span class="string">"10.46.23.25"</span>,</span><br><span class="line">      <span class="string">"port"</span>: <span class="string">"8080"</span></span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"address"</span>: <span class="string">"10.46.23.29"</span>,</span><br><span class="line">      <span class="string">"port"</span>: <span class="string">"8080"</span></span><br><span class="line">    }</span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"name"</span>: <span class="string">"default-hellogo-8080"</span>,</span><br><span class="line">  <span class="string">"noServer"</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="string">"port"</span>: 8080,</span><br><span class="line">  ...</span><br><span class="line">}</span><br><span class="line"><span class="comment"># 9090端口的列表</span></span><br><span class="line">/etc/nginx $ /dbg backends get default-hellogo-9090</span><br><span class="line">{</span><br><span class="line">  <span class="string">"endpoints"</span>: [</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"address"</span>: <span class="string">"10.46.12.107"</span>,</span><br><span class="line">      <span class="string">"port"</span>: <span class="string">"9090"</span></span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"address"</span>: <span class="string">"10.46.12.108"</span>,</span><br><span class="line">      <span class="string">"port"</span>: <span class="string">"9090"</span></span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"address"</span>: <span class="string">"10.46.12.109"</span>,</span><br><span class="line">      <span class="string">"port"</span>: <span class="string">"9090"</span></span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"address"</span>: <span class="string">"10.46.23.23"</span>,</span><br><span class="line">      <span class="string">"port"</span>: <span class="string">"9090"</span></span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"address"</span>: <span class="string">"10.46.23.25"</span>,</span><br><span class="line">      <span class="string">"port"</span>: <span class="string">"9090"</span></span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">      <span class="string">"address"</span>: <span class="string">"10.46.23.29"</span>,</span><br><span class="line">      <span class="string">"port"</span>: <span class="string">"9090"</span></span><br><span class="line">    }</span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"name"</span>: <span class="string">"default-hellogo-9090"</span>,</span><br><span class="line">  <span class="string">"noServer"</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="string">"port"</span>: 9090,</span><br><span class="line">  ...</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p><p>对比发现两个端口的列表是一样的,只能看看代码.</p><p>ip-hash代码在<a href="https://github.com/kubernetes/ingress-nginx/blob/master/rootfs/etc/nginx/lua/balancer/chash.lua" target="_blank" rel="noopener">https://github.com/kubernetes/ingress-nginx/blob/master/rootfs/etc/nginx/lua/balancer/chash.lua</a><br></p><figure class="highlight lua"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> _M.new<span class="params">(self, backend)</span></span></span><br><span class="line">  <span class="keyword">local</span> nodes = util.get_nodes(backend.endpoints)</span><br><span class="line">  <span class="keyword">local</span> o = {</span><br><span class="line">    instance = self.factory:new(nodes),  <span class="comment">--获取后端pod ip列表</span></span><br><span class="line">    hash_by = backend[<span class="string">"upstreamHashByConfig"</span>][<span class="string">"upstream-hash-by"</span>],</span><br><span class="line">    traffic_shaping_policy = backend.trafficShapingPolicy,</span><br><span class="line">    alternative_backends = backend.alternativeBackends,</span><br><span class="line">  }</span><br><span class="line">  <span class="built_in">setmetatable</span>(o, self)</span><br><span class="line">  self.<span class="built_in">__index</span> = self</span><br><span class="line">  <span class="keyword">return</span> o</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> _M.balance<span class="params">(self)</span></span></span><br><span class="line">  <span class="keyword">local</span> key = util.lua_ngx_var(self.hash_by) <span class="comment">--获取需要hash的变量</span></span><br><span class="line">  <span class="keyword">return</span> self.instance:<span class="built_in">find</span>(key)  <span class="comment">--计算hash值</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> _M</span><br></pre></td></tr></tbody></table></figure><p></p><p>关键是在<code>get_nodes</code>函数,位于<a href="https://github.com/kubernetes/ingress-nginx/blob/master/rootfs/etc/nginx/lua/util.lua" target="_blank" rel="noopener">https://github.com/kubernetes/ingress-nginx/blob/master/rootfs/etc/nginx/lua/util.lua</a><br></p><figure class="highlight lua"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> _M.get_nodes<span class="params">(endpoints)</span></span></span><br><span class="line">  <span class="keyword">local</span> nodes = {}</span><br><span class="line">  <span class="keyword">local</span> weight = <span class="number">1</span> <span class="comment">--所有后端weight相同都为1</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> _, endpoint <span class="keyword">in</span> <span class="built_in">pairs</span>(endpoints) <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">local</span> endpoint_string = endpoint.address .. <span class="string">":"</span> .. endpoint.port <span class="comment">--endpoint为ip+port</span></span><br><span class="line">    nodes[endpoint_string] = weight</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> nodes</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></tbody></table></figure><p></p><p>通过代码可以看到在<code>ingress-nginx</code>中,实际的后端(upstream)是包含端口的,通过hash计算得到的值也不一样。</p><h2 id="解决建议"><a href="#解决建议" class="headerlink" title="解决建议"></a>解决建议</h2><p>首先确认系统的架构是不是合理，不同的端口提供不同的服务，一般是相互独立的。<br>如果确实有类似需求：</p><ul><li>通过同一个端口提供服务，使用path来区分不同功能</li><li>修改代码，也比较简单</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;业务反馈使用Ingress的ip-hash, 同一个服务开启了http和websocket分别是两个端口, 但是配置ip-hash后, 同一个client的请求http和websocket不在同一个后端.&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="ingress" scheme="https://qingwave.github.io/tags/ingress/"/>
    
      <category term="nginx" scheme="https://qingwave.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>如何做一个优雅的Pod</title>
    <link href="https://qingwave.github.io/pod-graceful-lifecycle/"/>
    <id>https://qingwave.github.io/pod-graceful-lifecycle/</id>
    <published>2020-04-11T07:54:47.000Z</published>
    <updated>2020-04-15T07:40:30.479Z</updated>
    
    <content type="html"><![CDATA[<p>没有人不想优雅的活着，在这喧闹的生活中过得优雅从容并不容易。但在k8s的世界中，如何做个优雅的Pod还是有套路可循的。</p><h2 id="Pod的生命周期"><a href="#Pod的生命周期" class="headerlink" title="Pod的生命周期"></a>Pod的生命周期</h2><p>在优雅之前，我们先谈谈Pod的一生，大体分为以下几个阶段</p><ol><li>创建，通过kubectl或者api创建pod, apiserver收到请求后存储到etcd</li><li>调度，scheduler检测到pod创建后，通过预选优选为pod选取合适的人家(node)</li><li>启动，kubelet检测到有pod调度到当前节点，开始启动pod</li><li>终止，不同的pod有不同的谢幕方式，有的正常运行结束没有restart就completed，有的被kill就入土为安了，有的被驱逐换种方式重新开始</li></ol><p>今天我们主要讨论3-4阶段，前面部分更多是deployment/daemonset这些pod的父母所决定的。</p><h2 id="优雅的启动"><a href="#优雅的启动" class="headerlink" title="优雅的启动"></a>优雅的启动</h2><h3 id="init-container"><a href="#init-container" class="headerlink" title="init container"></a>init container</h3><p>通常pod有一些初始化操作，创建文件夹，初始化磁盘，检查某些依赖服务是不是正常，这些操作放在代码中会污染代码，写在启动命令中不方便管理，出问题也不方便排查，更优雅的方式是使用k8s的[init container][1]。</p><p><strong>理解 Init 容器</strong><br>Pod 可以包含多个容器，应用运行在这些容器里面，同时 Pod 也可以有一个或多个先于应用容器启动的 Init 容器。</p><p>Init 容器与普通的容器非常像，除了如下两点：</p><ul><li>它们总是运行到完成。</li><li>每个都必须在下一个启动之前成功完成。<br>如果 Pod 的 Init 容器失败，Kubernetes 会不断地重启该 Pod，直到 Init 容器成功为止。然而，如果 Pod 对应的 restartPolicy 值为 Never，它不会重新启动。</li></ul><p>如果为一个 Pod 指定了多个 Init 容器，这些容器会按顺序逐个运行。每个 Init 容器必须运行成功，下一个才能够运行。当所有的 Init 容器运行完成时，Kubernetes 才会为 Pod 初始化应用容器并像平常一样运行。</p><p><strong>Init 容器能做什么？</strong><br>因为 Init 容器具有与应用容器分离的单独镜像，其启动相关代码具有如下优势：</p><ul><li>Init 容器可以包含一些安装过程中应用容器中不存在的实用工具或个性化代码。例如，没有必要仅为了在安装过程中使用类似 sed、 awk、 python 或 dig 这样的工具而去FROM 一个镜像来生成一个新的镜像。</li><li>Init 容器可以安全地运行这些工具，避免这些工具导致应用镜像的安全性降低。<br>应用镜像的创建者和部署者可以各自独立工作，而没有必要联合构建一个单独的应用镜像。<br>Init 容器能以不同于Pod内应用容器的文件系统视图运行。因此，Init容器可具有访问 Secrets 的权限，而应用容器不能够访问。</li><li>由于 Init 容器必须在应用容器启动之前运行完成，因此 Init 容器提供了一种机制来阻塞或延迟应用容器的启动，直到满足了一组先决条件。一旦前置条件满足，Pod内的所有的应用容器会并行启动。</li></ul><p><strong>示例</strong><br>下面的例子定义了一个具有 2 个 Init 容器的简单 Pod。 第一个等待 myservice 启动，第二个等待 mydb 启动。 一旦这两个 Init容器 都启动完成，Pod 将启动spec区域中的应用容器。<br></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">myapp-pod</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">myapp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">myapp-container</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">busybox:1.28</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'echo The app is running! &amp;&amp; sleep 3600'</span><span class="string">]</span></span><br><span class="line"><span class="attr">  initContainers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">init-myservice</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">busybox:1.28</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">"until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done"</span><span class="string">]</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">init-mydb</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">busybox:1.28</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">"until nslookup mydb.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for mydb; sleep 2; done"</span><span class="string">]</span></span><br></pre></td></tr></tbody></table></figure><p></p><h3 id="readinessProbe"><a href="#readinessProbe" class="headerlink" title="readinessProbe"></a>readinessProbe</h3><p>pod启动后，如果直接加入endpoint，有可能服务还没初始化完成，端口没有就绪，这时候接收流量肯定无法正常处理。如果能判断pod是否ready就好了，当当当，readiness来了，可以通过http，tcp以及执行命令的方式来检查服务情况，检查成功后再将pod状态设置为ready,ready后才会加入到endpoint中。</p><p>下为一个readiness探测，5秒执行一次命令，执行成功则pod变为ready<br></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">readinessProbe:</span></span><br><span class="line"><span class="attr">  exec:</span></span><br><span class="line"><span class="attr">    command:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">cat</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/tmp/healthy</span></span><br><span class="line"><span class="attr">  initialDelaySeconds:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">  periodSeconds:</span> <span class="number">5</span></span><br></pre></td></tr></tbody></table></figure><p></p><blockquote><p><strong>注</strong></p><ul><li>http, tcp探针是kubelet执行的，所以无法探测容器中localhost的端口，也无法解析service</li><li>exec则在容器内执行的</li></ul></blockquote><h3 id="ReadinessGates"><a href="#ReadinessGates" class="headerlink" title="ReadinessGates"></a>ReadinessGates</h3><p>ReadinessProbe机制可能无法满足某些复杂应用对容器内服务可用状态的判断，所以kubernetes从1.11版本开始引入了<code>Pod Ready++</code>特性对Readiness探测机制进行扩展，在1.14版本时达到GA稳定版本，称其为<code>Pod Readiness Gates</code>。</p><p>通过Pod Readiness Gates机制，用户可以将自定义的ReadinessProbe探测方式设置在Pod上，辅助kubernetes设置Pod何时达到服务可用状态Ready，为了使自定义的ReadinessProbe生效，用户需要提供一个外部的控制器Controller来设置相应的Condition状态。Pod的Readiness Gates在pod定义中的ReadinessGates字段进行设置，</p><p>如下示例设置了一个类型为<code>www.example.com/feature-1</code>的新Readiness Gates：<br></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  readinessGates:</span></span><br><span class="line"><span class="attr">    - conditionType:</span> <span class="string">"www.example.com/feature-1"</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line"><span class="attr">  conditions:</span></span><br><span class="line"><span class="attr">    - type:</span> <span class="string">Ready</span>  <span class="comment"># kubernetes系统内置的名为Ready的Condition</span></span><br><span class="line"><span class="attr">      status:</span> <span class="string">"True"</span></span><br><span class="line"><span class="attr">      lastProbeTime:</span> <span class="literal">null</span></span><br><span class="line"><span class="attr">      lastTransitionTime:</span> <span class="number">2018</span><span class="bullet">-01</span><span class="bullet">-01</span><span class="attr">T00:00:00Z</span></span><br><span class="line"><span class="attr">    - type:</span> <span class="string">"www.example.com/feature-1"</span>   <span class="comment"># 用户定义的Condition</span></span><br><span class="line"><span class="attr">      status:</span> <span class="string">"False"</span></span><br><span class="line"><span class="attr">      lastProbeTime:</span> <span class="literal">null</span></span><br><span class="line"><span class="attr">      lastTransitionTime:</span> <span class="number">2018</span><span class="bullet">-01</span><span class="bullet">-01</span><span class="attr">T00:00:00Z</span></span><br><span class="line"><span class="attr">  containerStatuses:</span></span><br><span class="line"><span class="attr">    - containerID:</span> <span class="attr">docker://abcd...</span></span><br><span class="line"><span class="attr">      ready:</span> <span class="literal">true</span></span><br></pre></td></tr></tbody></table></figure><p></p><p>新增的自定义Condition的状态status将由用户自定义的外部控制器设置，默认值为False，kubernetes将在判断全部readinessGates条件都为True时，才设置pod为服务可用状态（Ready或True）。</p><h3 id="poststart"><a href="#poststart" class="headerlink" title="poststart"></a>poststart</h3><p>另外也可以通过<code>poststart</code>设置hook操作，做一些额外工作。k8s在容器创建后立即发送 postStart 事件。然而，postStart 处理函数的调用不保证早于容器的入口点（entrypoint） 的执行。postStart 处理函数与容器的代码是异步执行的，但 Kubernetes 的容器管理逻辑会一直阻塞等待 postStart 处理函数执行完毕。只有 postStart 处理函数执行完毕，容器的状态才会变成<code>RUNNING</code>。</p><h2 id="优雅的运行"><a href="#优雅的运行" class="headerlink" title="优雅的运行"></a>优雅的运行</h2><h3 id="livenessProbe"><a href="#livenessProbe" class="headerlink" title="livenessProbe"></a>livenessProbe</h3><p>同readinessProbe探针，livenessProbe是用来检查pod运行状态是否正常，如果探测失败，pod被kill掉，重启启动pod。</p><h3 id="restartpolicy"><a href="#restartpolicy" class="headerlink" title="restartpolicy"></a>restartpolicy</h3><p>如果pod运行时意外退出(程序故障)，kubelet会根据restart policy来判断是否重启pod，可能的值为 Always、OnFailure 和 Never。默认为 Always，如果容器退出会再再启动，pod启动次数加1。</p><h2 id="优雅的结束"><a href="#优雅的结束" class="headerlink" title="优雅的结束"></a>优雅的结束</h2><p>首先谈下pod的删除流程：</p><ol><li>用户发送命令删除 Pod，使用的是默认的宽限期（grace period 30秒）</li><li>apiserver中的 Pod 会随着宽限期规定的时间进行更新，过了这个时间 Pod 就会被认为已”dead”</li><li>当使用客户端命令查询 Pod 状态时，Pod 显示为 “Terminating”</li><li>（和第 3 步同步进行）当 Kubelet 看到 Pod 由于步骤 2 中设置的时间而被标记为 terminating 状态时，它就开始执行关闭 Pod 流程<ul><li>如果 Pod 定义了 preStop 钩子，就在 Pod 内部调用它。如果宽限期结束了，但是 preStop 钩子还在运行，那么就用小的（2 秒）扩展宽限期调用步骤 2。</li><li>给 Pod 内的进程发送 <code>TERM</code> 信号(即<code>kill</code>, <code>kill -15</code>)。请注意，并不是所有 Pod 中的容器都会同时收到 TERM 信号，如果它们关闭的顺序很重要，则每个容器可能都需要一个 preStop 钩子。</li></ul></li><li>（和第 3 步同步进行）从服务的<code>endpoint</code>列表中删除 Pod，Pod 也不再被视为副本控制器的运行状态的 Pod 集的一部分。因为负载均衡器（如服务代理）会将其从轮换中删除，所以缓慢关闭的 Pod 无法继续为流量提供服务。</li><li>当宽限期到期时，仍在 Pod 中运行的所有进程都会被<code>SIGKILL</code>(即<code>kill -9</code>)信号杀死。</li></ol><h3 id="捕捉SIGTERM"><a href="#捕捉SIGTERM" class="headerlink" title="捕捉SIGTERM"></a>捕捉SIGTERM</h3><p>如果pod没有捕捉<code>SIGTERM</code>信号就直接退出，有些请求还没处理完，这势必影响服务质量，所以需要优雅退出，很多库都提供了类似的功能，当接受到退出信号时，清理空闲链接，等待当前请求处理完后再退出。如果善后工作较长，比较适当增加<code>terminationGracePeriodSeconds</code>的时间。</p><h3 id="prestop"><a href="#prestop" class="headerlink" title="prestop"></a>prestop</h3><p>另外也可以通过<code>prestop</code>设置hook操作，做一些额外的清理工作，<br></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">lifecycle-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">lifecycle-demo-container</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">    lifecycle:</span></span><br><span class="line"><span class="attr">      preStop:</span></span><br><span class="line"><span class="attr">        exec:</span></span><br><span class="line"><span class="attr">          command:</span> <span class="string">["/bin/sh","-c","nginx</span> <span class="bullet">-s</span> <span class="string">quit;</span> <span class="string">while</span> <span class="string">killall</span> <span class="bullet">-0</span> <span class="string">nginx;</span> <span class="string">do</span> <span class="string">sleep</span> <span class="number">1</span><span class="string">;</span> <span class="string">done"]</span></span><br></pre></td></tr></tbody></table></figure><p></p><p>命令 preStop 负责优雅地终止 nginx 服务。当因为失效而导致容器终止时，这一处理方式很有用。</p><blockquote><p><strong>注</strong><br>  Kubernetes 只有在 Pod 结束（Terminated） 的时候才会发送 preStop 事件，这意味着在 Pod 完成（Completed） 时 preStop 的事件处理逻辑不会被触发。</p></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>优雅就不要怕麻烦，来我们总结下优雅的秘诀：</p><ol><li>需要初始化的操作使用initcontainer来做</li><li>就绪检查，探活检查少不了,必要时也可以配置ReadinessGates</li><li>优雅退出要处理<code>SIGTERM</code></li><li>需要时也可以设置下poststart, prestop</li><li>其他的，设置limit/reqeust也是必须的</li></ol><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>[1] <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/init-containers/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/concepts/workloads/pods/init-containers/</a><br>[2] <a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;没有人不想优雅的活着，在这喧闹的生活中过得优雅从容并不容易。但在k8s的世界中，如何做个优雅的Pod还是有套路可循的。&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>nginx ingress controller 最后的倔强: admission webhook</title>
    <link href="https://qingwave.github.io/ingress-nginx-controller-admission-webhook/"/>
    <id>https://qingwave.github.io/ingress-nginx-controller-admission-webhook/</id>
    <published>2020-04-03T10:48:04.000Z</published>
    <updated>2020-04-07T07:57:26.869Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>k8s中大多使用nginx-ingress-controller来实现ingress, 但是脆弱的nginx-controller通过ingress解析出nginx配置, 对于某些annotation会reload nignx配置失败, 然后controller就卡死了, 不断重启, 除非删除对应的ingress.</p><h3 id="问题复现"><a href="#问题复现" class="headerlink" title="问题复现"></a>问题复现</h3><p>创建有问题的<code>ingress</code></p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/auth-tls-pass-certificate-to-upstream:</span> <span class="string">"false"</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/auth-tls-verify-client:</span> <span class="string">optional</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/auth-tls-verify-depth:</span> <span class="string">"1"</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/configuration-snippet:</span> <span class="string">|</span></span><br><span class="line"><span class="string">      proxy_set_header Host $targethost;</span></span><br><span class="line"><span class="string">      proxy_buffering     off;</span></span><br><span class="line"><span class="string">      proxy_pass          http://$targetbackend;</span></span><br><span class="line"><span class="string">      proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;</span></span><br><span class="line"><span class="string">      proxy_redirect      off;</span></span><br><span class="line"><span class="string">      proxy_set_header    X-SSL-Client-Verify $ssl_client_verify;</span></span><br><span class="line"><span class="string">      proxy_set_header    X-SSL-Client-DN $ssl_client_s_dn;</span></span><br><span class="line"><span class="string">      proxy_set_header    X-Real-IP       $remote_addr;</span></span><br><span class="line"><span class="string">      proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;</span></span><br><span class="line"><span class="string"></span><span class="attr">  creationTimestamp:</span> <span class="string">"2020-03-23T04:57:22Z"</span></span><br><span class="line"><span class="attr">  generation:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">example-ingress</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  resourceVersion:</span> <span class="string">"57681168"</span></span><br><span class="line"><span class="attr">  selfLink:</span> <span class="string">/apis/extensions/v1beta1/namespaces/kube-system/ingresses/example-ingress</span></span><br><span class="line"><span class="attr">  uid:</span> <span class="string">c7f66385-6cc2-11ea-b6a8-246e96d4b538</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  rules:</span></span><br><span class="line"><span class="attr">  - host:</span> <span class="string">example.com</span></span><br><span class="line"><span class="attr">    http:</span></span><br><span class="line"><span class="attr">      paths:</span></span><br><span class="line"><span class="attr">      - backend:</span></span><br><span class="line"><span class="attr">          serviceName:</span> <span class="string">example-svc</span></span><br><span class="line"><span class="attr">          servicePort:</span> <span class="number">8008</span></span><br><span class="line"><span class="attr">        path:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">  tls:</span></span><br><span class="line"><span class="attr">  - hosts:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">example.com</span></span><br><span class="line"><span class="attr">    secretName:</span> <span class="string">example-tls</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line"><span class="attr">  loadBalancer:</span> <span class="string">{}</span></span><br></pre></td></tr></tbody></table></figure><p>查看<code>nginx-ingress-controller</code>状态全部为<code>CrashLoopBackOff</code></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get po -n kube-system -owide |grep ingress</span></span><br><span class="line">nginx-ingress-controller-ftfbg                        1/2     CrashLoopBackOff   6          8m27s</span><br><span class="line">nginx-ingress-controller-hp4pf                        1/2     CrashLoopBackOff   11         24m  </span><br><span class="line">nginx-ingress-controller-qlb4l                        1/2     CrashLoopBackOff   11         24m</span><br></pre></td></tr></tbody></table></figure><p>查看<code>nginx-ingress-controller</code>日志, 显示reload失败<code>"proxy_pass" directive is duplicate in /tmp/nginx-cfg911768424:822</code></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">W0403 10:26:14.716246       1 queue.go:130] requeuing kube-system/nginx-ingress-controller-4txfk, err </span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">Error: <span class="built_in">exit</span> status 1</span><br><span class="line">2020/04/03 10:26:14 [notice] 137<span class="comment">#137: ModSecurity-nginx v1.0.0</span></span><br><span class="line">2020/04/03 10:26:14 [warn] 137<span class="comment">#137: duplicate value "error" in /tmp/nginx-cfg911768424:815</span></span><br><span class="line">nginx: [warn] duplicate value <span class="string">"error"</span> <span class="keyword">in</span> /tmp/nginx-cfg911768424:815</span><br><span class="line">2020/04/03 10:26:14 [warn] 137<span class="comment">#137: duplicate value "timeout" in /tmp/nginx-cfg911768424:815</span></span><br><span class="line">nginx: [warn] duplicate value <span class="string">"timeout"</span> <span class="keyword">in</span> /tmp/nginx-cfg911768424:815</span><br><span class="line">2020/04/03 10:26:14 [emerg] 137<span class="comment">#137: "proxy_pass" directive is duplicate in /tmp/nginx-cfg911768424:822</span></span><br><span class="line">nginx: [emerg] <span class="string">"proxy_pass"</span> directive is duplicate <span class="keyword">in</span> /tmp/nginx-cfg911768424:822</span><br><span class="line">nginx: configuration file /tmp/nginx-cfg911768424 <span class="built_in">test</span> failed</span><br><span class="line"></span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">W0403 10:26:16.998897       1 nginx_status.go:207] unexpected error obtaining nginx status info: unexpected error scraping nginx status page: unexpected error scraping nginx : Get http://0.0.0.0:18080/nginx_status: dial tcp 0.0.0.0:18080: connect: connection refused</span><br><span class="line">I0403 10:26:17.526801       1 main.go:167] Received SIGTERM, shutting down</span><br><span class="line">I0403 10:26:17.526827       1 nginx.go:364] Shutting down controller queues</span><br><span class="line">I0403 10:26:17.526845       1 status.go:200] updating status of Ingress rules (remove)</span><br><span class="line">I0403 10:26:17.537511       1 status.go:219] removing address from ingress status ([])</span><br><span class="line">I0403 10:26:17.537593       1 nginx.go:372] Stopping NGINX process</span><br><span class="line">2020/04/03 10:26:17 [notice] 141<span class="comment">#141: signal process started</span></span><br><span class="line">I0403 10:26:20.547669       1 nginx.go:385] NGINX process has stopped</span><br><span class="line">I0403 10:26:20.547692       1 main.go:175] Handled quit, awaiting Pod deletion</span><br><span class="line">I0403 10:26:30.547824       1 main.go:178] Exiting with 0</span><br></pre></td></tr></tbody></table></figure><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>创建一个有问题的ingress, 会影响所有新创建的ingress规则, 又一个集群级别的Bug诞生了.那么有没有办法, 提前检验ingress配置, 有问题就不去reload. 那验证步骤肯定要在请求到达nginx-controller之前来做, 是不是想到了<a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/extensible-admission-controllers/" target="_blank" rel="noopener">k8s-admission-webhook</a>, 可以在apiserver持久化对象前拦截请求, 去实现自定义的验证规则. 好在新版本的nginx-ingress-controller(v0.25.0+)已经实现了相关的功能, 只需开启对应配置就行.</p><h3 id="ApiServer配置"><a href="#ApiServer配置" class="headerlink" title="ApiServer配置"></a>ApiServer配置</h3><p>Apiserver开启webhook相关配置, 必须包含<code>MutatingAdmissionWebhook</code>与<code>ValidatingAdmissionWebhook</code><br></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--admission-control=MutatingAdmissionWebhook,ValidatingAdmissionWebhook</span><br></pre></td></tr></tbody></table></figure><p></p><h3 id="创建webhook相关配置"><a href="#创建webhook相关配置" class="headerlink" title="创建webhook相关配置"></a>创建webhook相关配置</h3><p>启用ValidatingAdmissionWebhook必须使用https, 需要配置对应证书</p><ul><li><p>手动生成:</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl req -x509 -newkey rsa:2048 -keyout certificate.pem -out key.pem -days 365 -nodes -subj <span class="string">"/CN=ingress-validation-webhook.ingress-nginx.svc"</span></span><br></pre></td></tr></tbody></table></figure></li><li><p>CertificateSigningRequest<br>通过k8s <code>CertificateSigningRequest</code>来创建(controller-manager需要开启<code>--cluster-signing-cert-file</code>与<code>--cluster-signing-key-file</code>)<br>可通过如下脚本创建, namespace与service替换成自己的</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">SERVICE_NAME=ingress-nginx</span><br><span class="line">NAMESPACE=ingress-nginx</span><br><span class="line"></span><br><span class="line">TEMP_DIRECTORY=$(mktemp -d)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"creating certs in directory <span class="variable">${TEMP_DIRECTORY}</span>"</span></span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; <span class="variable">${TEMP_DIRECTORY}</span>/csr.conf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[ v3_req ]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation, digitalSignature, keyEncipherment</span><br><span class="line">extendedKeyUsage = serverAuth</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = <span class="variable">${SERVICE_NAME}</span></span><br><span class="line">DNS.2 = <span class="variable">${SERVICE_NAME}</span>.<span class="variable">${NAMESPACE}</span></span><br><span class="line">DNS.3 = <span class="variable">${SERVICE_NAME}</span>.<span class="variable">${NAMESPACE}</span>.svc</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">openssl genrsa -out <span class="variable">${TEMP_DIRECTORY}</span>/server-key.pem 2048</span><br><span class="line">openssl req -new -key <span class="variable">${TEMP_DIRECTORY}</span>/server-key.pem \</span><br><span class="line">    -subj <span class="string">"/CN=<span class="variable">${SERVICE_NAME}</span>.<span class="variable">${NAMESPACE}</span>.svc"</span> \</span><br><span class="line">    -out <span class="variable">${TEMP_DIRECTORY}</span>/server.csr \</span><br><span class="line">    -config <span class="variable">${TEMP_DIRECTORY}</span>/csr.conf</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF | kubectl create -f -</span><br><span class="line">apiVersion: certificates.k8s.io/v1beta1</span><br><span class="line">kind: CertificateSigningRequest</span><br><span class="line">metadata:</span><br><span class="line">  name: <span class="variable">${SERVICE_NAME}</span>.<span class="variable">${NAMESPACE}</span>.svc</span><br><span class="line">spec:</span><br><span class="line">  request: $(cat <span class="variable">${TEMP_DIRECTORY}</span>/server.csr | base64 | tr -d <span class="string">'\n'</span>)</span><br><span class="line">  usages:</span><br><span class="line">  - digital signature</span><br><span class="line">  - key encipherment</span><br><span class="line">  - server auth</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl certificate approve <span class="variable">${SERVICE_NAME}</span>.<span class="variable">${NAMESPACE}</span>.svc</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> $(seq 10); <span class="keyword">do</span></span><br><span class="line">    SERVER_CERT=$(kubectl get csr <span class="variable">${SERVICE_NAME}</span>.<span class="variable">${NAMESPACE}</span>.svc -o jsonpath=<span class="string">'{.status.certificate}'</span>)</span><br><span class="line">    <span class="keyword">if</span> [[ <span class="variable">${SERVER_CERT}</span> != <span class="string">''</span> ]]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">break</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    sleep 1</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">${SERVER_CERT}</span> == <span class="string">''</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"ERROR: After approving csr <span class="variable">${SERVICE_NAME}</span>.<span class="variable">${NAMESPACE}</span>.svc, the signed certificate did not appear on the resource. Giving up after 10 attempts."</span> &gt;&amp;2</span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">${SERVER_CERT}</span> | openssl base64 -d -A -out <span class="variable">${TEMP_DIRECTORY}</span>/server-cert.pem</span><br><span class="line"></span><br><span class="line">kubectl create secret generic ingress-nginx.svc \</span><br><span class="line">    --from-file=key.pem=<span class="variable">${TEMP_DIRECTORY}</span>/server-key.pem \</span><br><span class="line">    --from-file=cert.pem=<span class="variable">${TEMP_DIRECTORY}</span>/server-cert.pem \</span><br><span class="line">    -n <span class="variable">${NAMESPACE}</span></span><br></pre></td></tr></tbody></table></figure></li></ul><h3 id="配置ingress-controller"><a href="#配置ingress-controller" class="headerlink" title="配置ingress controller"></a>配置ingress controller</h3><p>ingress controller需要启用如下参数, 挂载需要的tls证书</p><table><thead><tr><th>flag</th><th>description</th><th>example usage</th></tr></thead><tbody><tr><td><code>--validating-webhook</code></td><td>admission webhook的地址</td><td><code>:8080</code></td></tr><tr><td><code>--validating-webhook-certificate</code></td><td>webhook证书</td><td><code>/usr/local/certificates/validating-webhook.pem</code></td></tr><tr><td><code>--validating-webhook-key</code></td><td>webhook私钥</td><td><code>/usr/local/certificates/validating-webhook-key.pem</code></td></tr></tbody></table><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>更新后, 创建有问题的ingress则会拦截, 符合预期</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f ing.yaml</span></span><br><span class="line">Error from server: error when creating <span class="string">"ing.yaml"</span>: admission webhook <span class="string">"validate.nginx.ingress.kubernetes.io"</span> denied the request: </span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">Error: <span class="built_in">exit</span> status 1</span><br><span class="line">2020/04/02 10:26:04 [emerg] 331<span class="comment">#331: directive "proxy_pass" is not terminated by ";" in /tmp/nginx-cfg461116913:2165</span></span><br><span class="line">nginx: [emerg] directive <span class="string">"proxy_pass"</span> is not terminated by <span class="string">";"</span> <span class="keyword">in</span> /tmp/nginx-cfg461116913:2165</span><br><span class="line">nginx: configuration file /tmp/nginx-cfg461116913 <span class="built_in">test</span> failed</span><br></pre></td></tr></tbody></table></figure><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><ul><li><a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/extensible-admission-controllers/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/reference/access-authn-authz/extensible-admission-controllers/</a></li><li><a href="https://kubernetes.github.io/ingress-nginx/deploy/validating-webhook/" target="_blank" rel="noopener">https://kubernetes.github.io/ingress-nginx/deploy/validating-webhook/</a></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;k8s中大多使用nginx-ingress-controller来实现ingress, 但是脆弱的nginx-controller通过ingress解析出nginx配置, 对于某些annotation会reload nignx配置失败, 然后controller就卡死了, 不断重启, 除非删除对应的ingress.&lt;/p&gt;
    
    </summary>
    
      <category term="cloud" scheme="https://qingwave.github.io/categories/cloud/"/>
    
    
      <category term="k8s" scheme="https://qingwave.github.io/tags/k8s/"/>
    
      <category term="ingress" scheme="https://qingwave.github.io/tags/ingress/"/>
    
  </entry>
  
</feed>
